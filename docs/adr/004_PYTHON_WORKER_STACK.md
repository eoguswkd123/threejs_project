# ADR-004: Python Worker ê¸°ìˆ  ìŠ¤íƒ

> **Version**: 0.0.4
> **Last Updated**: 2025-12-12

## ìƒíƒœ ë° ì˜ì‚¬ê²°ì • ì •ë³´

**ìƒíƒœ**: ìŠ¹ì¸ (Approved) | **ì‘ì„±ì¼**: 2025-12-04

| ì—­í•           | ë‹´ë‹¹ì                                                                                                                                    |
| ------------- | ----------------------------------------------------------------------------------------------------------------------------------------- |
| **ì‘ì„±ì**    | Claude Opus 4.5                                                                                                                           |
| **ê²€í† ì**    | Backend Architect (95ì ), DevOps Architect (94ì ), Quality Engineer (97ì ), Security Engineer (94ì ), System Architect (94ì ) - ì „ì› ìŠ¹ì¸ |
| **ìŠ¹ì¸ì**    | í”„ë¡œì íŠ¸ Owner                                                                                                                            |
| **ê²°ì •ì¼**    | 2025-12-10                                                                                                                                |
| **ëŒ€ì²´ ë¬¸ì„œ** | -                                                                                                                                         |
| **ëŒ€ì²´ ì‚¬ìœ ** | -                                                                                                                                         |

### ì˜ì‚¬ê²°ì • ë™ì¸ (Decision Drivers)

| ìœ í˜•         | ë‚´ìš©                                                       |
| ------------ | ---------------------------------------------------------- |
| **ê¸°ìˆ ì **   | GIL ìš°íšŒ í•„ìš”, CPU-bound ì‘ì—… ìµœì í™”, ML ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜ì„± |
| **ë¹„ì¦ˆë‹ˆìŠ¤** | í‚¤ì˜¤ìŠ¤í¬ ì„œë¹„ìŠ¤ 99.5% ê°€ìš©ì„±, DXF < 5ì´ˆ / PDF < 30ì´ˆ SLA   |
| **íŒ€/ì¡°ì§**  | 2-3ëª… ì†Œê·œëª¨ íŒ€, ìš´ì˜ ë³µì¡ë„ ìµœì†Œí™” í•„ìš”                   |

> **ìƒíƒœ ì •ì˜**: Draft â†’ In Review â†’ Approved / Superseded / Deprecated

### ì „ë¬¸ê°€ ê²€í†  ê²°ê³¼ (2025-12-10, v0.0.3)

| ì „ë¬¸ê°€            | 1ì°¨ | 2ì°¨ | 3ì°¨ | 4ì°¨ | 5ì°¨ | 6ì°¨ | 7ì°¨ | 8ì°¨ | 9ì°¨    | ë³€í™” | íŒì •    | ì£¼ìš” í”¼ë“œë°±                                                         |
| ----------------- | --- | --- | --- | --- | --- | --- | --- | --- | ------ | ---- | ------- | ------------------------------------------------------------------- |
| Backend Architect | 78  | 86  | 91  | 88  | 81  | 92  | 95  | 94  | **94** | Â±0   | âœ… ìŠ¹ì¸ | MEDIUM 3ê±´ ìœ ì§€ (SQLAlchemy ì˜ˆì™¸/Pool ê³ ê°ˆ/Outbox - êµ¬í˜„ ë‹¨ê³„ í•´ê²°) |
| DevOps Architect  | 82  | 88  | 91  | 88  | 77  | 86  | 94  | 91  | **93** | +2   | âœ… ìŠ¹ì¸ | v0.0.9 ìˆ˜ì •ì‚¬í•­ ì™„ë²½ ê²€ì¦, CRITICAL 0ê±´                             |
| Quality Engineer  | 84  | 92  | 91  | 91  | 84  | 95  | 97  | 92  | **92** | Â±0   | âœ… ìŠ¹ì¸ | ì‹¤ì¸¡ ë°ì´í„° Phase 3B í›„, í…ŒìŠ¤íŠ¸ ì²´ê³„ ìš°ìˆ˜                           |
| Security Engineer | 32  | 72  | 78  | 86  | 78  | 96  | 94  | 92  | **93** | +1   | âœ… ìŠ¹ì¸ | ë³´ì•ˆ ì„¤ê³„ ì¼ê´€ì„± ì¬í™•ì¸, MEDIUM 2ê±´ Phase 4 ì˜ˆì •                    |
| System Architect  | -   | -   | 78  | 78  | 78  | 92  | 94  | 95  | **96** | +1   | âœ… ìŠ¹ì¸ | HA 99.95% ì´ˆê³¼ ë‹¬ì„±, ë¡¤ë°± ì „ëµ ìš°ìˆ˜                                 |

**ì¢…í•© ì ìˆ˜**: 69 â†’ 84.5 â†’ 85.8 â†’ 86.2 â†’ 79.6 â†’ 92.2 â†’ 94.8 â†’ 92.8 â†’ **93.6/100** (9ì°¨)

> âœ… **9ì°¨ ê²€í†  ì™„ë£Œ** (2025-12-10): **ì „ì› ìŠ¹ì¸ ìœ ì§€** (5ëª…/5ëª…). 8ì°¨ ëŒ€ë¹„ +0.8ì  ìƒìŠ¹. DevOps(+2), Security(+1), System(+1) ê°œì„ . ì”ì—¬ MEDIUM ì´ìŠˆëŠ” êµ¬í˜„ ë‹¨ê³„(Phase 3B/4) í•´ê²° ì˜ˆì •. í”„ë¡œë•ì…˜ ë°°í¬ ìŠ¹ì¸ ê¸°ì¤€ ì¶©ì¡±.

---

## ëª©ì°¨

1. [í•µì‹¬ ì§ˆë¬¸](#1-í•µì‹¬-ì§ˆë¬¸)
2. [ë¬¸ì„œ ë²”ìœ„](#2-ë¬¸ì„œ-ë²”ìœ„)
3. [í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸](#3-í”„ë¡œì íŠ¸-ì»¨í…ìŠ¤íŠ¸)
    - 3.1 SLA ë„ì¶œ ê·¼ê±°
4. [í‰ê°€ ê¸°ì¤€](#4-í‰ê°€-ê¸°ì¤€)
5. [ê²°ì • ì˜ì—­ë³„ ë¶„ì„](#5-ê²°ì •-ì˜ì—­ë³„-ë¶„ì„)
    - 5.1 Python ë²„ì „ ì„ íƒ
    - 5.2 Task Queue Framework
    - 5.3 í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
    - 5.4 ê°œë°œ í™˜ê²½ ë„êµ¬
    - 5.5 Worker ì‹¤í–‰ ëª¨ë¸
    - 5.6 Docker ì»¨í…Œì´ë„ˆí™”
    - 5.7 ëª¨ë‹ˆí„°ë§ ë„êµ¬
    - 5.8 ë³´ì•ˆ ì„¤ê³„
    - 5.9 ë°°í¬ ì „ëµ
    - 5.10 CI/CD íŒŒì´í”„ë¼ì¸
    - 5.11 ë¡œê·¸ ì§‘ê³„ ë° ë¶„ì‚° íŠ¸ë ˆì´ì‹±
    - 5.12 GitOps ì›Œí¬í”Œë¡œìš°
    - 5.13 Service Mesh í†µí•© ì „ëµ
6. [ì„±ëŠ¥ ë² ì´ìŠ¤ë¼ì¸](#6-ì„±ëŠ¥-ë² ì´ìŠ¤ë¼ì¸)
7. [ì „ë¬¸ê°€ ë¶„ì„ ì¢…í•©](#7-ì „ë¬¸ê°€-ë¶„ì„-ì¢…í•©)
8. [ê¶Œì¥ ê¸°ìˆ  ìŠ¤íƒ ì¢…í•©](#8-ê¶Œì¥-ê¸°ìˆ -ìŠ¤íƒ-ì¢…í•©)
9. [ê²°ê³¼](#9-ê²°ê³¼)
    - 9.1 í™•ì¥ì„± ì„ê³„ê°’ ë° ë³‘ëª©ì  ë¶„ì„
    - 9.2 Incident Response Runbook
    - 9.3 HA(High Availability) ì „ëµ
10. [ì¬ê²€í†  ì¡°ê±´](#10-ì¬ê²€í† -ì¡°ê±´)
11. [ì°¸ì¡°](#11-ì°¸ì¡°)
12. [Changelog (ë³€ê²½ ì´ë ¥)](#12-changelog-ë³€ê²½-ì´ë ¥)

---

## 1. í•µì‹¬ ì§ˆë¬¸

> **"Python Workerë¥¼ ì–´ë–»ê²Œ êµ¬ì„±í•´ì•¼ ì•ˆì •ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ CAD ë³€í™˜ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆëŠ”ê°€?"**

### Executive Summary (1ë¶„ ìš”ì•½)

| í•­ëª©             | ë‚´ìš©                                                                            |
| ---------------- | ------------------------------------------------------------------------------- |
| **ì§ˆë¬¸**         | Python Workerì˜ ìµœì  ê¸°ìˆ  ìŠ¤íƒì€?                                               |
| **ë‹µë³€**         | Python 3.12 + Celery + prefork pool + Worker ë¶„ë¦¬ (DXF/PDF)                     |
| **í•µì‹¬ ê·¼ê±°**    | ì„±ëŠ¥ (3.12 ëˆ„ì  15-65% í–¥ìƒ), ì•ˆì •ì„± (prefork GIL ìš°íšŒ), í™•ì¥ì„± (ë…ë¦½ ìŠ¤ì¼€ì¼ë§) |
| **íŠ¸ë ˆì´ë“œì˜¤í”„** | ë³µì¡ë„ ì¦ê°€ (2ê°œ Worker ê´€ë¦¬) vs ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„± í™•ë³´                             |

### ìµœì¢… ê²°ì • (ìŠ¹ì¸ë¨)

| í•­ëª©             | ë‚´ìš©                                                                            |
| ---------------- | ------------------------------------------------------------------------------- |
| **ê²°ì •**         | Python 3.12 + Celery + prefork pool + Worker ë¶„ë¦¬ (DXF/PDF)                     |
| **í•µì‹¬ ê·¼ê±°**    | ì„±ëŠ¥ (3.12 ëˆ„ì  15-65% í–¥ìƒ), ì•ˆì •ì„± (prefork GIL ìš°íšŒ), í™•ì¥ì„± (ë…ë¦½ ìŠ¤ì¼€ì¼ë§) |
| **íŠ¸ë ˆì´ë“œì˜¤í”„** | ë³µì¡ë„ ì¦ê°€ (2ê°œ Worker ê´€ë¦¬) vs ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„± í™•ë³´                             |
| **ìƒì„¸**         | [ì„¹ì…˜ 8. ê¶Œì¥ ê¸°ìˆ  ìŠ¤íƒ ì¢…í•©](#8-ê¶Œì¥-ê¸°ìˆ -ìŠ¤íƒ-ì¢…í•©) ì°¸ì¡°                      |

**ê¸°ìˆ  ìŠ¤íƒ ìƒì„¸:**

| ì»´í¬ë„ŒíŠ¸          | ì„ íƒ                 | ë²„ì „    | ì„ ì • ê·¼ê±°                                |
| ----------------- | -------------------- | ------- | ---------------------------------------- |
| **Python**        | 3.12                 | 3.12.x  | ëˆ„ì  15-65% ì„±ëŠ¥ í–¥ìƒ, ì•ˆì •ì  ML ì§€ì›    |
| **Task Queue**    | Celery               | >=5.5.0 | ì—…ê³„ í‘œì¤€, RabbitMQ ë„¤ì´í‹°ë¸Œ ì§€ì›        |
| **Worker Pool**   | prefork              | -       | CPU-bound ì‘ì—…, GIL ìš°íšŒ í•„ìˆ˜            |
| **íŒ¨í‚¤ì§€ ê´€ë¦¬**   | uv                   | >=0.9.0 | 10-100x ë¹ ë¦„, pip/poetry/pyenv í†µí•© ëŒ€ì²´ |
| **ì½”ë“œ í’ˆì§ˆ**     | Ruff                 | >=0.8.0 | 10-100x ë¹ ë¦„, ì˜¬ì¸ì› (linter+formatter)  |
| **Type Checker**  | mypy                 | >=1.8.0 | í”„ë¡œë•ì…˜ ì•ˆì •ì„±, ì—„ê²©í•œ íƒ€ì… ê²€ì‚¬        |
| **í…ŒìŠ¤íŠ¸**        | pytest               | >=7.4.0 | ì‚¬ì‹¤ìƒ í‘œì¤€, pytest-celery í†µí•©          |
| **ëª¨ë‹ˆí„°ë§**      | Prometheus + Grafana | latest  | ë©”íŠ¸ë¦­ ìˆ˜ì§‘ + ì‹œê°í™”, Celery í†µí•©        |
| **Task ëª¨ë‹ˆí„°ë§** | Flower               | >=2.0   | Celery ì „ìš© ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ              |

---

## 2. ë¬¸ì„œ ë²”ìœ„

**ì´ ë¬¸ì„œê°€ ë‹¤ë£¨ëŠ” ë‚´ìš©:**

- Python Worker ê¸°ìˆ  ìŠ¤íƒ ì„ íƒ (Python ë²„ì „, Task Queue, ë¼ì´ë¸ŒëŸ¬ë¦¬)
- ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì„ íƒ (Prometheus, Grafana, Flower)
- Worker ì‹¤í–‰ ëª¨ë¸ ë° Docker ì»¨í…Œì´ë„ˆí™” ì „ëµ

**ì´ ë¬¸ì„œê°€ ë‹¤ë£¨ì§€ ì•ŠëŠ” ë‚´ìš©:**
| í•­ëª© | ë‹¤ë£¨ëŠ” ìœ„ì¹˜ |
|------|------------|
| ì„¤ì • ì˜ˆì‹œ ë° êµ¬í˜„ ì½”ë“œ | `cad-worker/README.md` (Phase 3B êµ¬í˜„ ì‹œ) |
| ë³´ì•ˆ ì„¤ì • (ì‹œí¬ë¦¿, ì¸ì¦, ë„¤íŠ¸ì›Œí¬) | `cad-worker/README.md` (Phase 3B êµ¬í˜„ ì‹œ) |
| í…ŒìŠ¤íŠ¸ ì „ëµ ë° ì‹¤í–‰ ë°©ë²• | `cad-worker/README.md` (Phase 3B êµ¬í˜„ ì‹œ) |
| ë°°í¬ ìš´ì˜ ê°€ì´ë“œ | `cad-worker/docs/DEPLOYMENT.md` (Phase 3C ì´í›„) |
| Backend â†” Worker ì¸í„°í˜ì´ìŠ¤ | ADR-001 í™•ì • í›„ ë³„ë„ ë¬¸ì„œ |

---

## 3. í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸

### ì±…ì„ ê²½ê³„ (ADR-001 ì°¸ì¡°)

| ì»´í¬ë„ŒíŠ¸                  | ì±…ì„ ë²”ìœ„                                       | ê´€ë ¨ ADR          |
| ------------------------- | ----------------------------------------------- | ----------------- |
| **Backend (Spring Boot)** | API ê²Œì´íŠ¸ì›¨ì´, ì¸ì¦/ì¸ê°€, Task ìƒì„±, ìƒíƒœ ì¡°íšŒ | ADR-001           |
| **Python Worker**         | íŒŒì¼ ë³€í™˜ (DXFâ†’glTF, PDFâ†’glTF), ML ì¶”ë¡          | ë³¸ ë¬¸ì„œ (ADR-004) |
| **RabbitMQ**              | Task ë©”ì‹œì§€ ì „ë‹¬, DLQ ê´€ë¦¬                      | ADR-003           |

**ì¸í„°í˜ì´ìŠ¤ ê³„ì•½**:

- Backend â†’ Worker: RabbitMQ ë©”ì‹œì§€ (Appendix A.1 ì°¸ì¡°)
- Worker â†’ Backend: HTTP Callback + PostgreSQL ìƒíƒœ ì—…ë°ì´íŠ¸
- ê³µìœ  ìŠ¤í† ë¦¬ì§€: MinIO (Pre-signed URL êµí™˜)

> **ì°¸ê³ **: Backend ê¸°ìˆ  ìŠ¤íƒ ì„¸ë¶€ì‚¬í•­ì€ [ADR-001](./001_BACKEND_STACK.md)ì„ ì°¸ì¡°í•˜ì„¸ìš”.

### ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           PYTHON WORKER SYSTEM                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  RabbitMQ   â”‚      â”‚  RabbitMQ   â”‚      â”‚        PYTHON WORKERS       â”‚   â”‚
â”‚  â”‚   Exchange  â”‚â”€â”€â”€â”€â”€â–¶â”‚   Queues    â”‚â”€â”€â”€â”€â”€â–¶â”‚                             â”‚   â”‚
â”‚  â”‚   (tasks)   â”‚      â”‚             â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚ dxf_queue   â”‚      â”‚  â”‚   DXF   â”‚  â”‚   PDF   â”‚   â”‚   â”‚
â”‚                       â”‚ pdf_queue   â”‚      â”‚  â”‚ Worker  â”‚  â”‚ Worker  â”‚   â”‚   â”‚
â”‚                       â”‚ dxf_dlq     â”‚      â”‚  â”‚  (CPU)  â”‚  â”‚  (GPU)  â”‚   â”‚   â”‚
â”‚                       â”‚ pdf_dlq     â”‚      â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚       â”‚            â”‚        â”‚   â”‚
â”‚                                            â””â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                    â”‚            â”‚            â”‚
â”‚                                                    â–¼            â–¼            â”‚
â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                       â”‚ PostgreSQL  â”‚â—€â”€â”€â”€â”€â”€â”‚         MinIO / S3          â”‚   â”‚
â”‚                       â”‚  (ìƒíƒœ)     â”‚      â”‚      (íŒŒì¼ ì €ì¥ì†Œ)          â”‚   â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Worker ì—­í•  ì •ì˜

| Worker         | ì—­í•               | ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸                      | ì˜ˆìƒ ì‹œê°„ |
| -------------- | ----------------- | ------------------------------------ | --------- |
| **DXF Worker** | ë²¡í„° ë„ë©´ ë³€í™˜    | DXF â†’ ezdxf íŒŒì‹± â†’ 2Dâ†’3D ì••ì¶œ â†’ glTF | ~2ì´ˆ      |
| **PDF Worker** | ML ê¸°ë°˜ ë„ë©´ ë¶„ì„ | PDF â†’ PyMuPDF â†’ OpenCV â†’ YOLO â†’ glTF | ~18ì´ˆ     |

### ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­

| í•­ëª©          | ê°’                    | ë¹„ê³                   |
| ------------- | --------------------- | --------------------- |
| íŒŒì¼ í¬ê¸°     | ìµœëŒ€ 500MB            | ëŒ€ìš©ëŸ‰ ê±´ì¶• ë„ë©´      |
| ë™ì‹œ ì²˜ë¦¬     | 10-50ê±´               | í‚¤ì˜¤ìŠ¤í¬ ë‹¤ìˆ˜ ë°°í¬    |
| ì²˜ë¦¬ ì‹œê°„ SLA | DXF < 5ì´ˆ, PDF < 30ì´ˆ | ì‚¬ìš©ì ëŒ€ê¸° í—ˆìš© ë²”ìœ„ |
| ê°€ìš©ì„±        | 99.5%                 | í‚¤ì˜¤ìŠ¤í¬ ì„œë¹„ìŠ¤       |
| ë©”ëª¨ë¦¬ ì‚¬ìš©   | Workerë‹¹ 8-16GB       | ML ëª¨ë¸ ë¡œë”© ê³ ë ¤     |

### 3.1 SLA ë„ì¶œ ê·¼ê±°

> **ğŸ“Œ SLA ì„¤ì • ë°°ê²½**
>
> | SLA í•­ëª©          | ê°’     | ë„ì¶œ ê·¼ê±°                                                                                                              |
> | ----------------- | ------ | ---------------------------------------------------------------------------------------------------------------------- |
> | **DXF ì²˜ë¦¬ ì‹œê°„** | < 5ì´ˆ  | UX ì—°êµ¬ ê¸°ì¤€: ì‚¬ìš©ìê°€ "ì¦‰ê°ì "ìœ¼ë¡œ ëŠë¼ëŠ” ì‘ë‹µ ì‹œê°„ < 1ì´ˆ, "ëŒ€ê¸° ê°€ëŠ¥" < 10ì´ˆ. DXFëŠ” ë‹¨ìˆœ ë²¡í„° ë³€í™˜ìœ¼ë¡œ 5ì´ˆ ì´ë‚´ ëª©í‘œ |
> | **PDF ì²˜ë¦¬ ì‹œê°„** | < 30ì´ˆ | ML ì¶”ë¡ (YOLO) + ë²¡í„° ì¶”ì¶œ í¬í•¨. 30ì´ˆëŠ” "ì§„í–‰ í‘œì‹œ í•„ìš”" êµ¬ê°„ì´ë‚˜ í‚¤ì˜¤ìŠ¤í¬ ì‚¬ìš©ì ëŒ€ê¸° í—ˆìš© ë²”ìœ„ ë‚´                     |
> | **ê°€ìš©ì„±**        | 99.5%  | í‚¤ì˜¤ìŠ¤í¬ ìš´ì˜ ì‹œê°„ ê¸°ì¤€ (ì›” 22ì¼ Ã— 12ì‹œê°„). 99.5% = ì›”ê°„ ë‹¤ìš´íƒ€ì„ ~1.32ì‹œê°„ í—ˆìš©                                       |
> | **íŒŒì¼ í¬ê¸°**     | 500MB  | ê±´ì¶•/ì„¤ë¹„ CAD ë„ë©´ ìƒìœ„ 95í¼ì„¼íƒ€ì¼ ê¸°ì¤€. ëŒ€ë¶€ë¶„ 100MB ì´í•˜, ë³µì¡í•œ ì„¤ë¹„ë„ë©´ ìµœëŒ€ 500MB                                 |
>
> **ì°¸ê³  ë¬¸í—Œ**:
>
> - Nielsen Norman Group: [Response Time Limits](https://www.nngroup.com/articles/response-times-3-important-limits/)
> - í‚¤ì˜¤ìŠ¤í¬ UX ê°€ì´ë“œë¼ì¸: ëŒ€ê¸° ì‹œê°„ 30ì´ˆ ì´ˆê³¼ ì‹œ ì´íƒˆë¥  ê¸‰ì¦

---

## 4. í‰ê°€ ê¸°ì¤€

### ê°€ì¤‘ì¹˜ ê¸°ë°˜ í‰ê°€ í”„ë ˆì„ì›Œí¬

| ê¸°ì¤€          | ê°€ì¤‘ì¹˜ | ì„¤ëª…                                          |
| ------------- | ------ | --------------------------------------------- |
| **ì„±ëŠ¥**      | 25%    | ì²˜ë¦¬ ì†ë„, ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„±, GIL ìš°íšŒ ëŠ¥ë ¥       |
| **ì•ˆì •ì„±**    | 25%    | í”„ë¡œë•ì…˜ ê²€ì¦, ì—ëŸ¬ ì²˜ë¦¬, ì¥ì•  ê²©ë¦¬, LTS ì§€ì› |
| **ìƒíƒœê³„**    | 20%    | ì»¤ë®¤ë‹ˆí‹° í™œì„±ë„, ë¬¸ì„œí™” ìˆ˜ì¤€, ìœ ì§€ë³´ìˆ˜ ìƒíƒœ   |
| **í†µí•©ì„±**    | 15%    | RabbitMQ/Spring Boot í˜¸í™˜, ê¸°ì¡´ ìŠ¤íƒ ì—°ê³„     |
| **íŒ€ ì í•©ì„±** | 15%    | í•™ìŠµ ê³¡ì„ , ìš´ì˜ ë³µì¡ë„, 2-3ëª… íŒ€ ê·œëª¨ ì í•©ì„±  |
| **í•©ê³„**      | 100%   |                                               |

### í‰ê°€ ì²™ë„

| ì ìˆ˜             | ì˜ë¯¸      |
| ---------------- | --------- |
| â­â­â­â­â­ (5ì ) | ë§¤ìš° ìš°ìˆ˜ |
| â­â­â­â­ (4ì )   | ìš°ìˆ˜      |
| â­â­â­ (3ì )     | ë³´í†µ      |
| â­â­ (2ì )       | ë¯¸í¡      |
| â­ (1ì )         | ë§¤ìš° ë¯¸í¡ |

---

## 5. ê²°ì • ì˜ì—­ë³„ ë¶„ì„

### 5.1 Python ë²„ì „ ì„ íƒ

> **âš ï¸ ì ìˆ˜ ì²´ê³„ ì•ˆë‚´**
>
> | êµ¬ë¶„                 | ì„¹ì…˜ 5.1 (ë³¸ ì„¹ì…˜)                                    | ì„¹ì…˜ 6 (ì „ë¬¸ê°€ ë¶„ì„ ì¢…í•©)                           |
> | -------------------- | ----------------------------------------------------- | --------------------------------------------------- |
> | **ëª©ì **             | Python ë²„ì „ ê°„ ë¹„êµ                                   | ì „ì²´ ê¸°ìˆ  ìŠ¤íƒ íš¡ë‹¨ ë¹„êµ                            |
> | **í‰ê°€ ê¸°ì¤€**        | 6ê°œ (ì„±ëŠ¥, í˜¸í™˜ì„±, MLìƒíƒœê³„, ì—ëŸ¬ë©”ì‹œì§€, Docker, LTS) | 5ê°œ ê°€ì¤‘ì¹˜ (ì„±ëŠ¥, ì•ˆì •ì„±, ìƒíƒœê³„, í†µí•©ì„±, íŒ€ì í•©ì„±) |
> | **Python 3.12 ì ìˆ˜** | 97ì                                                   | 95ì                                                 |
> | **ì ìˆ˜ ì°¨ì´ ì´ìœ **   | ë²„ì „ íŠ¹í™” ê¸°ì¤€ ì ìš©                                   | ì „ì²´ ìŠ¤íƒ ì¼ê´€ ê¸°ì¤€ ì ìš©                            |
>
> ë™ì¼ ê¸°ìˆ ì´ ë‹¤ë¥¸ ì ìˆ˜ë¥¼ ë°›ëŠ” ê²ƒì€ í‰ê°€ ëª©ì ê³¼ ê¸°ì¤€ì´ ë‹¤ë¥´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

| ê¸°ì¤€                  | Python 3.11                    | Python 3.12                      | Python 3.13            |
| --------------------- | ------------------------------ | -------------------------------- | ---------------------- |
| **ì„±ëŠ¥**              | â­â­â­â­â­ +10-60% (3.10 ëŒ€ë¹„) | â­â­â­â­â­ +5% (3.11 ëŒ€ë¹„)       | â­â­â­â­ ê°œì„  ì¤‘       |
| **ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜ì„±** | â­â­â­â­â­ ìµœê³                 | â­â­â­â­â­ ìš°ìˆ˜ (ì„±ìˆ™)           | â­â­â­â­ ëŒ€ë¶€ë¶„ í˜¸í™˜   |
| **ML ìƒíƒœê³„**         | â­â­â­â­â­ PyTorch ì™„ì „ ì§€ì›   | â­â­â­â­â­ PyTorch 2.x ì™„ì „ ì§€ì› | â­â­â­â­ ì§„í–‰ ì¤‘       |
| **ì—ëŸ¬ ë©”ì‹œì§€**       | â­â­â­â­â­ í–¥ìƒë¨              | â­â­â­â­â­ í–¥ìƒë¨                | â­â­â­â­â­ ì¶”ê°€ ê°œì„    |
| **Docker ì´ë¯¸ì§€**     | â­â­â­â­â­ ì•ˆì •ì               | â­â­â­â­â­ ì•ˆì •ì  (ì¶©ë¶„íˆ ì„±ìˆ™)  | â­â­â­â­ ë¹„êµì  ìƒˆë¡œì›€ |
| **LTS ì§€ì›**          | 2027-10                        | 2028-10                          | 2029-10                |
| **ì¢…í•©**              | 92ì                            | **97ì **                         | 90ì                    |

**ğŸ“Œ Python LTS ì •ì±… ì°¸ê³ **

Pythonì€ ê³µì‹ "LTS" ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ, **ëª¨ë“  minor ë²„ì „ì´ ë™ì¼í•˜ê²Œ 5ë…„ê°„ ì§€ì›**ë©ë‹ˆë‹¤.

- **Full Support**: 1.5ë…„ (3.13ë¶€í„° 2ë…„) - ë²„ê·¸ ìˆ˜ì • + ë³´ì•ˆ íŒ¨ì¹˜
- **Security Only**: 3.5ë…„ (3.13ë¶€í„° 3ë…„) - ë³´ì•ˆ íŒ¨ì¹˜ë§Œ
- Spring Bootì™€ ë‹¬ë¦¬ LTS/non-LTS êµ¬ë¶„ ì—†ì´ **ëª¨ë“  ë²„ì „ ë™ì¼ ëŒ€ìš°**
- ì°¸ê³ : [Python ë²„ì „ ì§€ì› ì •ì±…](https://devguide.python.org/versions/)

#### ê¶Œì¥: Python 3.12

**ì„ ì • ê·¼ê±°**:

1. **ì„±ëŠ¥ í–¥ìƒ ëˆ„ì **: 3.11ì˜ Faster CPython ì´ì  + 3.12ì˜ ì¶”ê°€ ìµœì í™”
    - 3.11 ëŒ€ë¹„ ì•½ 5% ì¶”ê°€ ì„±ëŠ¥ í–¥ìƒ ([Python 3.12 Release Notes](https://docs.python.org/3/whatsnew/3.12.html))
    - ì¸ë¼ì´ë‹ ìµœì í™” ë° comprehension ì„±ëŠ¥ ê°œì„ 
    - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ê°€ ìµœì í™”

2. **í–¥ìƒëœ ì—ëŸ¬ ë©”ì‹œì§€**: 3.11ì—ì„œ ë„ì…ëœ ê¸°ëŠ¥ ìœ ì§€ ë° ê°œì„ 

    ```python
    # Python 3.12 - ë” ì •í™•í•œ ì—ëŸ¬ ìœ„ì¹˜
    TypeError: 'NoneType' object is not subscriptable
        data["key"]
        ~~~~^^^^^^^
    ```

3. **íƒ€ì… íŒíŠ¸ ê°œì„ **:
    - `type` ë¬¸ ë„ì…ìœ¼ë¡œ íƒ€ì… ë³„ì¹­ ì •ì˜ ê°„ì†Œí™”
    - ì œë„¤ë¦­ ë¬¸ë²• ê°œì„  (`class MyClass[T]:`)
    - `typing` ëª¨ë“ˆ ì˜ì¡´ì„± ê°ì†Œ

4. **ML ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜ì„±**: PyTorch 2.x, TensorFlow 2.x, Ultralytics (YOLO) ì™„ì „ ì§€ì›
    - 2024ë…„ ì´í›„ ì£¼ìš” ML ë¼ì´ë¸ŒëŸ¬ë¦¬ 3.12 ì§€ì› ì•ˆì •í™” ì™„ë£Œ

5. **f-string ê°œì„ **: ì¤‘ì²© ì¸ìš© ë° í‘œí˜„ì‹ ììœ ë„ ì¦ê°€

    ```python
    # Python 3.12 - ì¤‘ì²© f-string ê°€ëŠ¥
    result = f"Value: {data["key"]}"  # ì´ì œ ê°€ëŠ¥
    ```

6. **Exception Groups**: ì—¬ëŸ¬ ì˜ˆì™¸ ë™ì‹œ ì²˜ë¦¬ (3.11ì—ì„œ ë„ì…, 3.12ì—ì„œ ì•ˆì •í™”)
    ```python
    try:
        async with asyncio.TaskGroup() as tg:
            tg.create_task(process_dxf())
            tg.create_task(process_pdf())
    except* ValueError as eg:
        handle_value_errors(eg.exceptions)
    ```

**ğŸ“‹ Python ë²„ì „ ì„ íƒ ê°€ì´ë“œë¼ì¸**

| í”„ë¡œì íŠ¸ ì¡°ê±´             | ê¶Œì¥ ë²„ì „               | ì´ìœ                                        |
| ------------------------- | ----------------------- | ------------------------------------------ |
| ì‹ ê·œ í”„ë¡œì íŠ¸, ìˆ˜ëª… < 2ë…„ | **3.12**                | ìƒíƒœê³„ ì„±ìˆ™, 1ë…„ ë” ê¸´ ì§€ì› ê¸°ê°„           |
| ì‹ ê·œ í”„ë¡œì íŠ¸, ìˆ˜ëª… â‰¥ 2ë…„ | **3.12**                | 2028-10ê¹Œì§€ ì§€ì›, ë§ˆì´ê·¸ë ˆì´ì…˜ ë¹„ìš© ìµœì†Œí™” |
| 2027ë…„ ì´í›„ ì‹œì‘ í”„ë¡œì íŠ¸ | **3.13 ê²€í† **           | ìƒíƒœê³„ ì„±ìˆ™ í›„ ì „í™˜                        |
| ê¸°ì¡´ 3.11 í”„ë¡œì íŠ¸        | **ìœ ì§€ ë˜ëŠ” 3.12 ì „í™˜** | ì „í™˜ ë¹„ìš© ëŒ€ë¹„ ì´ì  í‰ê°€ í•„ìš”              |

> **5ì  ì°¨ì´(97 vs 92) ë¶„ì„**: 3.12ëŠ” LTS 1ë…„ ì¶”ê°€(+0.30) + Docker ì´ë¯¸ì§€ ì•ˆì •í™”(+0.15) + íƒ€ì…íŒíŠ¸ ê°œì„ (+0.10).
> 2025ë…„ ì‹œì ì—ì„œ 3.12 ìƒíƒœê³„ê°€ ì¶©ë¶„íˆ ì„±ìˆ™í•˜ì—¬ ì‹ ê·œ í”„ë¡œì íŠ¸ì— ê¶Œì¥.

---

### 5.2 Task Queue Framework

| ê¸°ì¤€              | Celery                             | Dramatiq                  | RQ (Redis Queue)     |
| ----------------- | ---------------------------------- | ------------------------- | -------------------- |
| **RabbitMQ ì§€ì›** | â­â­â­â­â­ ë„¤ì´í‹°ë¸Œ                | â­â­â­â­â­ ë„¤ì´í‹°ë¸Œ       | âŒ Redis ì „ìš©        |
| **ìƒíƒœê³„**        | â­â­â­â­â­ ë§¤ìš° í’ë¶€               | â­â­â­ ì„±ì¥ ì¤‘            | â­â­â­ ê¸°ë³¸ì         |
| **ë¬¸ì„œí™”**        | â­â­â­â­â­ í’ë¶€                    | â­â­â­â­ ì–‘í˜¸             | â­â­â­ ê¸°ë³¸          |
| **ëª¨ë‹ˆí„°ë§**      | â­â­â­â­â­ Flower                  | â­â­â­ ê¸°ë³¸               | â­â­â­ rq-dashboard  |
| **ì¬ì‹œë„/DLQ**    | â­â­â­â­â­ ë‚´ì¥                    | â­â­â­â­â­ ë‚´ì¥           | â­â­â­ ê¸°ë³¸          |
| **Worker Pool**   | â­â­â­â­â­ prefork/gevent/eventlet | â­â­â­â­ gevent/threading | â­â­â­ fork          |
| **Spring í†µí•©**   | â­â­â­â­ AMQP ê³µìœ                  | â­â­â­â­ AMQP ê³µìœ         | âŒ Redis ì „ìš©        |
| **í•™ìŠµ ê³¡ì„ **     | â­â­â­ ë³µì¡                        | â­â­â­â­ ë‹¨ìˆœ             | â­â­â­â­â­ ë§¤ìš° ë‹¨ìˆœ |
| **ì»¤ë®¤ë‹ˆí‹°**      | â­â­â­â­â­ ë§¤ìš° í™œë°œ               | â­â­â­ í™œë°œ               | â­â­â­ í™œë°œ          |
| **ì¢…í•©**          | **90ì **                           | 80ì                       | 65ì                  |

#### ê¶Œì¥: Celery

**ì„ ì • ê·¼ê±°**:

1. **RabbitMQ ë„¤ì´í‹°ë¸Œ ì§€ì›**: ADR-003ì—ì„œ RabbitMQ í™•ì •, AMQP í”„ë¡œí† ì½œ ì™„ë²½ ì§€ì›
2. **ì—…ê³„ í‘œì¤€**: 10ë…„+ ì—­ì‚¬, í’ë¶€í•œ ë¬¸ì„œì™€ ì»¤ë®¤ë‹ˆí‹°
3. **Flower ëª¨ë‹ˆí„°ë§**: ì‹¤ì‹œê°„ Worker ìƒíƒœ, ì‘ì—… í ëª¨ë‹ˆí„°ë§ UI
4. **ìœ ì—°í•œ Worker Pool**: CPU-bound(prefork), I/O-bound(gevent) ì„ íƒ ê°€ëŠ¥
5. **Spring Boot í˜¸í™˜**: Java Backendì™€ ë™ì¼ RabbitMQ ì¸ìŠ¤í„´ìŠ¤ ê³µìœ 

**Dramatiq ëŒ€ì•ˆ ê³ ë ¤ ì‹œì **:

- Celeryì˜ ë³µì¡ì„±ì´ ë¬¸ì œê°€ ë  ë•Œ
- ë” ë‹¨ìˆœí•œ API ì„ í˜¸ ì‹œ
- ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ê°€ ë” ì¤‘ìš”í•  ë•Œ

---

### 5.3 í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬

#### DXF ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬

| ë¼ì´ë¸ŒëŸ¬ë¦¬ | ì„±ëŠ¥       | ê¸°ëŠ¥                     | ìœ ì§€ë³´ìˆ˜        | ì„ íƒ    |
| ---------- | ---------- | ------------------------ | --------------- | ------- |
| **ezdxf**  | â­â­â­â­â­ | â­â­â­â­â­ ì „ì²´ DXF ì§€ì› | â­â­â­â­â­ í™œë°œ | âœ… ê¶Œì¥ |
| dxfgrabber | â­â­â­â­   | â­â­â­ ì½ê¸° ì „ìš©         | â­â­ ì¤‘ë‹¨ë¨     | âŒ      |

**ezdxf ì„ ì • ê·¼ê±°**:

- DXF R12 ~ R2018 ì „ì²´ ë²„ì „ ì§€ì›
- LINE, ARC, CIRCLE, POLYLINE, LWPOLYLINE ë“± ëª¨ë“  ì—”í‹°í‹° íŒŒì‹±
- í™œë°œí•œ ìœ ì§€ë³´ìˆ˜ (GitHub 4.7k+ stars)
- ë²¡í„° ë³€í™˜ì— ìµœì í™”ëœ API

#### PDF ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬

| ë¼ì´ë¸ŒëŸ¬ë¦¬         | ì„±ëŠ¥       | CAD ë„ë©´ ì í•©ì„±           | ëŒ€ìš©ëŸ‰ ì²˜ë¦¬                   | ì„ íƒ    |
| ------------------ | ---------- | ------------------------- | ----------------------------- | ------- |
| **PyMuPDF (fitz)** | â­â­â­â­â­ | â­â­â­â­â­ ë²¡í„° ì¶”ì¶œ ìš°ìˆ˜ | â­â­â­â­â­ í˜ì´ì§€ë³„ ìˆœì°¨ ì²˜ë¦¬ | âœ… ê¶Œì¥ |
| pdfplumber         | â­â­â­     | â­â­â­â­ í‘œ ì¶”ì¶œ íŠ¹í™”     | â­â­â­ ë©”ëª¨ë¦¬ ì‚¬ìš© ë†’ìŒ       | âŒ      |
| pypdf              | â­â­â­â­   | â­â­â­ í…ìŠ¤íŠ¸ ì¶”ì¶œ íŠ¹í™”   | â­â­â­â­ ì–‘í˜¸                 | âŒ      |

**PyMuPDF ì„ ì • ê·¼ê±°**:

- ê³ í•´ìƒë„ ì´ë¯¸ì§€ ë Œë”ë§ (300+ DPI)
- ë²¡í„° ì •ë³´ ì§ì ‘ ì¶”ì¶œ ê°€ëŠ¥
- 500MB íŒŒì¼ í˜ì´ì§€ë³„ ìˆœì°¨ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
- C ê¸°ë°˜ìœ¼ë¡œ ë¹ ë¥¸ ì„±ëŠ¥

#### 3D ì¶œë ¥ ë¼ì´ë¸ŒëŸ¬ë¦¬

| ë¼ì´ë¸ŒëŸ¬ë¦¬    | glTF ì§€ì›                     | ì‚¬ìš© í¸ì˜ì„± | ì„ íƒ    |
| ------------- | ----------------------------- | ----------- | ------- |
| **pygltflib** | â­â­â­â­â­ glTF 2.0 ì™„ì „ ì§€ì› | â­â­â­â­    | âœ… ê¶Œì¥ |
| trimesh       | â­â­â­â­ ë³€í™˜ í•„ìš”            | â­â­â­â­â­  | ëŒ€ì•ˆ    |

**pygltflib ì„ ì • ê·¼ê±°**:

- glTF 2.0 / glb ë„¤ì´í‹°ë¸Œ ì§€ì›
- Three.js ì§ì ‘ ë¡œë“œ ê°€ëŠ¥
- ë¨¸í‹°ë¦¬ì–¼, í…ìŠ¤ì²˜ ì§€ì›

#### ML ì¶”ë¡  ë¼ì´ë¸ŒëŸ¬ë¦¬

| ì»´í¬ë„ŒíŠ¸                   | ë¼ì´ë¸ŒëŸ¬ë¦¬                     | ìš©ë„           |
| -------------------------- | ------------------------------ | -------------- |
| **ML Framework**           | PyTorch >=2.1.0                | ë”¥ëŸ¬ë‹ ê¸°ë°˜    |
| **Object Detection**       | ultralytics (YOLOv8) >=8.0.0   | ë„ë©´ ìš”ì†Œ íƒì§€ |
| **Inference Acceleration** | onnxruntime >=1.16.0           | ONNX ëª¨ë¸ ì¶”ë¡  |
| **Image Processing**       | opencv-python-headless >=4.9.0 | ì „ì²˜ë¦¬         |

---

### 5.4 ê°œë°œ í™˜ê²½ ë„êµ¬

#### IDE / ì½”ë“œ ì—ë””í„°

| ë„êµ¬        | íƒ€ì…        | Python íŠ¹í™”          | ë©”ëª¨ë¦¬           | ì‹œì‘ ì‹œê°„       | ê°€ê²©   | ì„ íƒ    |
| ----------- | ----------- | -------------------- | ---------------- | --------------- | ------ | ------- |
| **VS Code** | ì—ë””í„°+í™•ì¥ | â­â­â­â­ í™•ì¥ í•„ìš”   | â­â­â­â­â­ ~40MB | â­â­â­â­â­ ì¦‰ì‹œ | ë¬´ë£Œ   | âœ… ê¶Œì¥ |
| PyCharm Pro | ì „ìš© IDE    | â­â­â­â­â­ ì¦‰ì‹œ ì‚¬ìš© | â­â­â­ ~400MB    | â­â­â­ 3-5ë¶„    | $89/ë…„ | ëŒ€ì•ˆ    |
| PyCharm CE  | ì „ìš© IDE    | â­â­â­â­â­ ì¦‰ì‹œ ì‚¬ìš© | â­â­â­ ~400MB    | â­â­â­ 3-5ë¶„    | ë¬´ë£Œ   | ëŒ€ì•ˆ    |

**VS Code ì„ ì • ê·¼ê±°**:

- ê°€ë³ê³  ë¹ ë¥¸ ì‹œì‘ (ë©”ëª¨ë¦¬ ~40MB, ì¦‰ì‹œ ì‹œì‘)
- Python í™•ì¥ + Pylanceë¡œ PyCharm ìˆ˜ì¤€ IntelliSense
- Ruff í™•ì¥ìœ¼ë¡œ í†µí•© ë¦°íŒ…/í¬ë§¤íŒ…
- Docker, Git, Remote SSH í†µí•© ìš°ìˆ˜
- ë¬´ë£Œ + ì˜¤í”ˆì†ŒìŠ¤

**PyCharm ê³ ë ¤ ì‹œì **:

- Django/Flask ì „ë¬¸ ì›¹ ê°œë°œ (Pro ë²„ì „)
- ëŒ€ê·œëª¨ Python í”„ë¡œì íŠ¸ ë¦¬íŒ©í† ë§
- ë””ë²„ê¹… ë° í”„ë¡œíŒŒì¼ë§ ì§‘ì¤‘ í•„ìš” ì‹œ

---

#### íŒ¨í‚¤ì§€ ê´€ë¦¬

| ë„êµ¬                   | ì†ë„               | ì¬í˜„ì„±     | Docker í˜¸í™˜ | í•™ìŠµ ê³¡ì„   | ì„ íƒ                |
| ---------------------- | ------------------ | ---------- | ----------- | ---------- | ------------------- |
| **uv**                 | â­â­â­â­â­ 10-100x | â­â­â­â­â­ | â­â­â­â­â­  | â­â­â­â­   | âœ… ê¶Œì¥             |
| pip-tools              | â­â­â­â­â­         | â­â­â­â­â­ | â­â­â­â­â­  | â­â­â­â­â­ | ì•ˆì •ì„± ì¤‘ì‹œ ì‹œ ëŒ€ì•ˆ |
| Poetry                 | â­â­â­             | â­â­â­â­â­ | â­â­â­â­    | â­â­â­     | ëŒ€ì•ˆ                |
| pip + requirements.txt | â­â­â­â­â­         | â­â­â­     | â­â­â­â­â­  | â­â­â­â­â­ | âŒ                  |

**uv ì„ ì • ê·¼ê±°** (2024ë…„ 2ì›” ì¶œì‹œ, [Astral](https://astral.sh), í˜„ì¬ v0.9.x ì•ˆì •í™”):

- Rust ê¸°ë°˜ìœ¼ë¡œ pip ëŒ€ë¹„ **10-100ë°° ë¹ ë¦„**
- pip, pip-tools, pipx, poetry, pyenv, virtualenv **í†µí•© ëŒ€ì²´**
- `uv venv` ìƒì„± 80ë°° ë¹ ë¦„
- Ruffì™€ ê°™ì€ Astral íŒ€ ê°œë°œ
- Docker ë¹Œë“œ ì‹œê°„ ëŒ€í­ ë‹¨ì¶•

**uv ì‚¬ìš© ì˜ˆì‹œ**:

```bash
# uv ì„¤ì¹˜
curl -LsSf https://astral.sh/uv/install.sh | sh

# ê°€ìƒí™˜ê²½ ìƒì„± (80x ë¹ ë¦„)
uv venv

# ì˜ì¡´ì„± ì„¤ì¹˜ (10-100x ë¹ ë¦„)
uv pip install -r requirements.txt

# í”„ë¡œì íŠ¸ ê´€ë¦¬ (poetry/pdm ëŒ€ì²´)
uv init
uv add celery ezdxf PyMuPDF
uv sync
```

**pip-tools vs uv ì„ íƒ ê¸°ì¤€**:

- **uv**: ì‹ ê·œ í”„ë¡œì íŠ¸, ë¹ ë¥¸ ë¹Œë“œ ì¤‘ì‹œ, ìµœì‹  ë„êµ¬ ì„ í˜¸
- **pip-tools**: ê¸°ì¡´ í”„ë¡œì íŠ¸, ì•ˆì •ì„± ì¤‘ì‹œ, ë³´ìˆ˜ì  í™˜ê²½

**pip-tools ì‚¬ìš© ì˜ˆì‹œ** (ë ˆê±°ì‹œ/ì•ˆì •ì„± ì¤‘ì‹œ):

```bash
# requirements.in (ì¶”ìƒì  ì˜ì¡´ì„±)
celery[rabbitmq]>=5.5.0
ezdxf>=1.3.0
PyMuPDF>=1.24.0

# ì»´íŒŒì¼
pip-compile requirements.in -o requirements.txt

# ì„¤ì¹˜
pip install -r requirements.txt
```

#### ì½”ë“œ í’ˆì§ˆ ë„êµ¬

| ë„êµ¬                   | ì†ë„               | ê¸°ëŠ¥              | ì„¤ì • ë³µì¡ë„     | ì„ íƒ    |
| ---------------------- | ------------------ | ----------------- | --------------- | ------- |
| **Ruff**               | â­â­â­â­â­ 10-100x | â­â­â­â­â­ ì˜¬ì¸ì› | â­â­â­â­â­ ë‹¨ìˆœ | âœ… ê¶Œì¥ |
| Black + Flake8 + isort | â­â­â­             | â­â­â­â­â­        | â­â­â­ ë³µì¡     | ë ˆê±°ì‹œ  |

**Ruff ì„ ì • ê·¼ê±°**:

- Rust ê¸°ë°˜ìœ¼ë¡œ 10-100ë°° ë¹ ë¦„
- Linting + Formatting í†µí•©
- Black, isort, Flake8 ê·œì¹™ í˜¸í™˜
- ë‹¨ì¼ ë„êµ¬ë¡œ ì„¤ì • ê°„ì†Œí™”

**ruff.toml ì˜ˆì‹œ**:

```toml
[tool.ruff]
line-length = 88
target-version = "py312"

[tool.ruff.lint]
select = ["E", "F", "I", "N", "W", "UP"]
ignore = ["E501"]

[tool.ruff.format]
quote-style = "double"
```

#### Type Checker

| ë„êµ¬     | ì—„ê²©ì„±     | ì„±ëŠ¥       | IDE í†µí•©                | ì„ íƒ    |
| -------- | ---------- | ---------- | ----------------------- | ------- |
| **mypy** | â­â­â­â­â­ | â­â­â­â­   | â­â­â­â­â­              | âœ… ê¶Œì¥ |
| Pyright  | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ VS Code ìµœì  | ëŒ€ì•ˆ    |

**mypy ì„ ì • ê·¼ê±°**:

- í”„ë¡œë•ì…˜ ì•ˆì •ì„± ê²€ì¦ë¨
- ì ì§„ì  íƒ€ì… ê²€ì‚¬ ì§€ì›
- Celery, PyTorch íƒ€ì… ìŠ¤í… ì§€ì›

#### PostgreSQL íŠ¸ëœì­ì…˜ ê²©ë¦¬ ìˆ˜ì¤€ (8ì°¨ ê²€í†  ì¶”ê°€)

> **Backend Architect ê¶Œì¥ì‚¬í•­**: ë°ì´í„° ì¼ê´€ì„±ê³¼ ë™ì‹œì„± íŠ¸ë ˆì´ë“œì˜¤í”„ ëª…ì‹œ

**ê²©ë¦¬ ìˆ˜ì¤€ ì„ íƒ**:

| ê²©ë¦¬ ìˆ˜ì¤€          | Dirty Read | Non-Repeatable Read | Phantom Read | ì„±ëŠ¥       | ì‚¬ìš© ì‚¬ë¡€          |
| ------------------ | ---------- | ------------------- | ------------ | ---------- | ------------------ |
| READ UNCOMMITTED   | ê°€ëŠ¥       | ê°€ëŠ¥                | ê°€ëŠ¥         | â­â­â­â­â­ | âŒ ì‚¬ìš© ê¸ˆì§€       |
| **READ COMMITTED** | ë¶ˆê°€       | ê°€ëŠ¥                | ê°€ëŠ¥         | â­â­â­â­   | âœ… **ê¸°ë³¸ê°’ ê¶Œì¥** |
| REPEATABLE READ    | ë¶ˆê°€       | ë¶ˆê°€                | ê°€ëŠ¥         | â­â­â­     | ë©±ë“±ì„± ì—°ì‚°        |
| SERIALIZABLE       | ë¶ˆê°€       | ë¶ˆê°€                | ë¶ˆê°€         | â­â­       | ê¸ˆìœµ ê±°ë˜          |

**Worker ì‘ì—…ë³„ ê¶Œì¥ ì„¤ì •**:

```python
# config/database.py
import os
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# Worker í™˜ê²½ ë³€ìˆ˜
WORKERS_PER_POD = int(os.getenv("WORKERS_PER_POD", 4))

# ê¸°ë³¸ ì„¤ì •: READ COMMITTED (PostgreSQL ê¸°ë³¸ê°’)
# CRITICAL: Worker ìˆ˜ ê³ ë ¤í•œ Pool í¬ê¸° (8ì°¨ ê²€í†  ë°˜ì˜)
engine = create_engine(
    DATABASE_URL,
    isolation_level="READ COMMITTED",
    pool_size=WORKERS_PER_POD * 2,      # Workerë‹¹ 2ê°œ ì—°ê²° (ê¸°ë³¸ 8)
    max_overflow=WORKERS_PER_POD,        # ì¶”ê°€ ì˜¤ë²„í”Œë¡œìš° (ê¸°ë³¸ 4)
    pool_pre_ping=True,
    pool_recycle=3600,                   # 1ì‹œê°„ë§ˆë‹¤ ì¬ìƒì„± (PG idle timeout ëŒ€ì‘)
    pool_timeout=30,                     # 30ì´ˆ ëŒ€ê¸° í›„ ì‹¤íŒ¨
    pool_use_lifo=True,                  # ìµœê·¼ ì‚¬ìš© ì»¤ë„¥ì…˜ ì¬ì‚¬ìš©
    connect_args={
        "connect_timeout": 10,
        "options": "-c statement_timeout=60000"  # 60ì´ˆ ì¿¼ë¦¬ íƒ€ì„ì•„ì›ƒ
    }
)

# ë©±ë“±ì„± ì—°ì‚°ìš© ì„¸ì…˜ (ìƒíƒœ í™•ì¸ í›„ ì—…ë°ì´íŠ¸)
# CRITICAL: REPEATABLE READ â†’ SERIALIZABLE (8ì°¨ ê²€í†  ë°˜ì˜)
def get_idempotent_session():
    """ë©±ë“±ì„± ì—°ì‚°ìš© ì„¸ì…˜ - SERIALIZABLE ê²©ë¦¬ ìˆ˜ì¤€ + FOR UPDATE ê¶Œì¥"""
    Session = sessionmaker(bind=engine)
    session = Session()
    # REPEATABLE READëŠ” Write Skew ë°©ì§€ ë¶ˆê°€, SERIALIZABLE í•„ìˆ˜
    session.connection(execution_options={"isolation_level": "SERIALIZABLE"})
    return session

# ì‚¬ìš© ì˜ˆì‹œ (FOR UPDATEì™€ í•¨ê»˜)
def update_file_status_idempotent(file_id: str, new_status: str):
    """ë©±ë“±ì„± ë³´ì¥ ìƒíƒœ ì—…ë°ì´íŠ¸ - FOR UPDATE ì ê¸ˆ í•„ìˆ˜"""
    with get_idempotent_session() as session:
        file = session.query(File).with_for_update(nowait=True).get(file_id)
        if file and file.status != new_status:
            file.status = new_status
            session.commit()

# ì¼ë°˜ ì‘ì—…ìš© ì„¸ì…˜
def get_session():
    """ëŒ€ë¶€ë¶„ì˜ Worker ì‘ì—…ì— ì í•©"""
    Session = sessionmaker(bind=engine)
    return Session()
```

**Celery Taskì—ì„œì˜ ì‚¬ìš©**:

```python
# tasks/process_dxf.py
@celery.task(bind=True)
def process_dxf(self, file_id: str):
    # ì¼ë°˜ ì‘ì—…: READ COMMITTED
    with get_session() as session:
        file = session.query(File).get(file_id)
        # ... ì²˜ë¦¬ ë¡œì§

@celery.task(bind=True)
def update_file_status(self, file_id: str, new_status: str):
    # ë©±ë“±ì„± ë³´ì¥: REPEATABLE READ
    with get_idempotent_session() as session:
        file = session.query(File).get(file_id)
        if file.status != new_status:  # ì¼ê´€ëœ ì½ê¸° ë³´ì¥
            file.status = new_status
            session.commit()
```

---

### 5.5 Worker ì‹¤í–‰ ëª¨ë¸

#### Worker Pool ì„ íƒ

| Pool        | CPU-bound  | I/O-bound  | GIL ìš°íšŒ         | ë©”ëª¨ë¦¬          | ì„ íƒ       |
| ----------- | ---------- | ---------- | ---------------- | --------------- | ---------- |
| **prefork** | â­â­â­â­â­ | â­â­â­     | âœ… í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ | â­â­â­ ë†’ìŒ     | âœ… DXF/PDF |
| gevent      | â­â­       | â­â­â­â­â­ | âŒ               | â­â­â­â­â­ ë‚®ìŒ | I/O ì‘ì—…ìš© |
| eventlet    | â­â­       | â­â­â­â­â­ | âŒ               | â­â­â­â­â­ ë‚®ìŒ | I/O ì‘ì—…ìš© |

**prefork ì„ ì • ê·¼ê±°**:

- DXF íŒŒì‹±, PDF ë Œë”ë§, ML ì¶”ë¡  ëª¨ë‘ CPU-bound
- GIL(Global Interpreter Lock) ìš°íšŒë¡œ ì§„ì •í•œ ë³‘ë ¬ ì²˜ë¦¬
- í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ë¡œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€

#### Worker ë¶„ë¦¬ ì „ëµ

| ì „ëµ                      | ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ | í™•ì¥ì„±     | ìš´ì˜ ë³µì¡ë„     | ì„ íƒ     |
| ------------------------- | ----------- | ---------- | --------------- | -------- |
| **íƒ€ì…ë³„ ë¶„ë¦¬ (DXF/PDF)** | â­â­â­â­â­  | â­â­â­â­â­ | â­â­â­ ì¤‘ê°„     | âœ… ê¶Œì¥  |
| ë‹¨ì¼ Worker               | â­â­â­      | â­â­â­     | â­â­â­â­â­ ë‹¨ìˆœ | MVP í•œì • |
| ìš°ì„ ìˆœìœ„ë³„ ë¶„ë¦¬           | â­â­â­â­    | â­â­â­â­   | â­â­ ë³µì¡       | ëŒ€ì•ˆ     |

**íƒ€ì…ë³„ ë¶„ë¦¬ ì„ ì • ê·¼ê±°**:

1. **ë¦¬ì†ŒìŠ¤ ìµœì í™”**:
    - DXF: CPU 4 vCPU, 8GB RAM
    - PDF: CPU 4 vCPU, 16GB RAM + GPU (T4/A10)

2. **ë…ë¦½ ìŠ¤ì¼€ì¼ë§**:
    - DXF 80% íŠ¸ë˜í”½ â†’ CPU Worker ìŠ¤ì¼€ì¼ ì—…
    - PDF ì¦ê°€ â†’ GPU Workerë§Œ ì¶”ê°€

3. **ì¥ì•  ê²©ë¦¬**:
    - PDF ML ì˜¤ë¥˜ â†’ DXF ì²˜ë¦¬ ì˜í–¥ ì—†ìŒ

#### Task ìƒíƒœ ì „ì´ ëª¨ë¸

```mermaid
stateDiagram-v2
    [*] --> PENDING: Task ìƒì„±
    PENDING --> RUNNING: Worker ìˆ˜ì‹ 
    RUNNING --> SUCCESS: ì²˜ë¦¬ ì™„ë£Œ
    RUNNING --> RETRY: ì¬ì‹œë„ ê°€ëŠ¥ ì˜¤ë¥˜
    RUNNING --> FAILURE: ì¬ì‹œë„ ë¶ˆê°€ ì˜¤ë¥˜
    RETRY --> RUNNING: ì¬ì‹œë„ (max 3íšŒ)
    RETRY --> FAILURE: ì¬ì‹œë„ ì´ˆê³¼
    FAILURE --> DLQ: Dead Letter Queue ì´ë™
    DLQ --> REPROCESSING: ìë™/ìˆ˜ë™ ì¬ì²˜ë¦¬ ì‹œì‘
    REPROCESSING --> PENDING: ì¬ì²˜ë¦¬ íì‰
    SUCCESS --> [*]
    DLQ --> [*]: ìˆ˜ë™ ì‚­ì œ/ë§Œë£Œ
```

**ìƒíƒœë³„ ì•¡ì…˜**:

| ìƒíƒœ         | ì•¡ì…˜                             | ì•Œë¦¼        |
| ------------ | -------------------------------- | ----------- |
| PENDING      | í ëŒ€ê¸°                          | -           |
| RUNNING      | ì²˜ë¦¬ ì¤‘, ë¡œê¹…                    | -           |
| SUCCESS      | ê²°ê³¼ ì €ì¥, ì½œë°±                  | ì„ íƒì       |
| RETRY        | ì¬ì‹œë„ ì¹´ìš´í„° ì¦ê°€, ë°±ì˜¤í”„ ëŒ€ê¸°  | 3íšŒ ì´ˆê³¼ ì‹œ |
| FAILURE      | DLQ ì´ë™, ì—ëŸ¬ ë¡œê¹…              | âœ… ì¦‰ì‹œ     |
| DLQ          | ê´€ë¦¬ì ê²€í†  ëŒ€ê¸°                 | âœ… ì¦‰ì‹œ     |
| REPROCESSING | ì›ìì  ìƒíƒœ ì „ì´, ì›ë³¸ í ì¬íˆ¬ì… | ë¡œê·¸ ê¸°ë¡   |

#### DLQ(Dead Letter Queue) ì²˜ë¦¬ ì „ëµ

**DLQ ë¼ìš°íŒ… ì¡°ê±´**:

- ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ (max_retries=3)
- Non-retryable ì˜ˆì™¸ (ValidationError, PermissionDenied)
- ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼ (task_time_limit=300ì´ˆ)

**DLQ ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­**:

| ë©”íŠ¸ë¦­                   | ì„¤ëª…                         | ì•Œë¦¼ ì„ê³„ê°’ |
| ------------------------ | ---------------------------- | ----------- |
| `dlq_depth`              | DLQ í ë©”ì‹œì§€ ìˆ˜             | > 10ê±´      |
| `dlq_oldest_message_age` | ê°€ì¥ ì˜¤ë˜ëœ ë©”ì‹œì§€ ëŒ€ê¸° ì‹œê°„ | > 1ì‹œê°„     |

**ìˆ˜ë™ ì¬ì²˜ë¦¬ ì ˆì°¨**:

1. Flower UIì—ì„œ DLQ ë©”ì‹œì§€ í™•ì¸
2. ì‹¤íŒ¨ ì›ì¸ ë¶„ì„ (ë¡œê·¸ í™•ì¸)
3. ì›ì¸ í•´ê²° í›„ CLIë¡œ ì¬ì²˜ë¦¬:
    ```bash
    celery -A worker call tasks.reprocess_dlq --args='["task_id"]'
    ```
4. 24ì‹œê°„ í›„ ìë™ ì‚­ì œ ì •ì±… ì ìš©

**DLQ ìë™ ì¬ì²˜ë¦¬ ì •ì±…**:

| ì—ëŸ¬ ì½”ë“œ          | ì¬ì²˜ë¦¬ ì •ì±…                | ì¬ì‹œë„ íšŸìˆ˜ | ëŒ€ê¸° ì‹œê°„ |
| ------------------ | -------------------------- | ----------- | --------- |
| `STORAGE_ERROR`    | ìë™ ì¬ì‹œë„                | 1íšŒ         | 5ë¶„ í›„    |
| `NETWORK_ERROR`    | ìë™ ì¬ì‹œë„                | 1íšŒ         | 5ë¶„ í›„    |
| `TIMEOUT_ERROR`    | ìë™ ì¬ì‹œë„                | 1íšŒ         | 10ë¶„ í›„   |
| `VALIDATION_ERROR` | ì¦‰ì‹œ ì‚­ì œ ë˜ëŠ” ê´€ë¦¬ì ì•Œë¦¼ | 0íšŒ         | -         |
| `PARSING_ERROR`    | ê´€ë¦¬ì ì•Œë¦¼                | 0íšŒ         | -         |
| 24ì‹œê°„ ê²½ê³¼        | ìë™ ì‚­ì œ                  | -           | -         |

**Celery Beat ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •**:

```python
# celeryconfig.py
from celery.schedules import crontab

beat_schedule = {
    # ë§¤ 1ì‹œê°„ë§ˆë‹¤ DLQ ìŠ¤ìº” ë° ìë™ ì¬ì²˜ë¦¬
    'process-dlq-messages': {
        'task': 'tasks.scan_and_reprocess_dlq',
        'schedule': crontab(minute=0),  # ë§¤ì‹œ ì •ê°
        'options': {'queue': 'maintenance'}
    },
    # ë§¤ì¼ ìì • 24ì‹œê°„ ê²½ê³¼ ë©”ì‹œì§€ ì •ë¦¬
    'cleanup-old-dlq': {
        'task': 'tasks.cleanup_expired_dlq',
        'schedule': crontab(hour=0, minute=0),
        'options': {'queue': 'maintenance'}
    },
}
```

**ìë™ ì¬ì²˜ë¦¬ Task êµ¬í˜„**:

```python
# tasks/dlq_processor.py
from celery import shared_task
from datetime import datetime, timedelta

RETRYABLE_ERRORS = {'STORAGE_ERROR', 'NETWORK_ERROR', 'TIMEOUT_ERROR'}
MAX_AGE_HOURS = 24

@shared_task
def scan_and_reprocess_dlq():
    """DLQ ë©”ì‹œì§€ ìŠ¤ìº” ë° ì¡°ê±´ë¶€ ì¬ì²˜ë¦¬"""
    for queue in ['dxf_dlq', 'pdf_dlq']:
        messages = get_dlq_messages(queue)
        for msg in messages:
            if msg.error_code in RETRYABLE_ERRORS and msg.reprocess_count < 1:
                # ì¬ì²˜ë¦¬ ê°€ëŠ¥í•œ ì—ëŸ¬: ì¬ì‹œë„
                requeue_message(msg, original_queue=queue.replace('_dlq', '_queue'))
                increment_reprocess_count(msg.task_id)
                log.info("dlq_reprocessed", task_id=msg.task_id, error=msg.error_code)
            elif msg.error_code == 'VALIDATION_ERROR':
                # ê²€ì¦ ì˜¤ë¥˜: ì¦‰ì‹œ ì‚­ì œ
                delete_dlq_message(msg)
                log.info("dlq_deleted", task_id=msg.task_id, reason="validation_error")

@shared_task
def cleanup_expired_dlq():
    """24ì‹œê°„ ê²½ê³¼ DLQ ë©”ì‹œì§€ ì •ë¦¬"""
    cutoff = datetime.utcnow() - timedelta(hours=MAX_AGE_HOURS)
    for queue in ['dxf_dlq', 'pdf_dlq']:
        deleted = delete_messages_older_than(queue, cutoff)
        log.info("dlq_cleanup", queue=queue, deleted_count=deleted)
```

#### ë©±ë“±ì„± ë³´ì¥ ë©”ì»¤ë‹ˆì¦˜ (4ì°¨ ê²€í†  ì¶”ê°€)

> **ğŸ“Œ Backend Architect ê¶Œì¥ì‚¬í•­ ë°˜ì˜** (2025-12-08)

**ë¬¸ì œì **: ë„¤íŠ¸ì›Œí¬ ì¥ì•  ì‹œ Taskê°€ ì¤‘ë³µ ì‹¤í–‰ë˜ì–´ ë™ì¼ íŒŒì¼ì´ ì—¬ëŸ¬ ë²ˆ ë³€í™˜ë  ìˆ˜ ìˆìŒ

**ë©±ë“±ì„± ë³´ì¥ ì²´í¬ë¦¬ìŠ¤íŠ¸**:

| ë‹¨ê³„                | ê²€ì¦ í•­ëª©         | êµ¬í˜„ ë°©ì•ˆ                                     |
| ------------------- | ----------------- | --------------------------------------------- |
| 1. ì¤‘ë³µ ì‹¤í–‰ ê²€ì‚¬   | Task ID ê¸°ë°˜      | DBì—ì„œ `task_id` + `status` ì¡°íšŒ              |
| 2. ì›ìì  ìƒíƒœ ì „ì´ | PENDING â†’ RUNNING | `SELECT ... FOR UPDATE`                       |
| 3. ê²°ê³¼ ì¬ì‚¬ìš©      | ì´ë¯¸ ì™„ë£Œëœ Task  | ê¸°ì¡´ ê²°ê³¼ ë°˜í™˜                                |
| 4. ê²°ì •ë¡ ì  ì—…ë¡œë“œ  | MinIO ì¤‘ë³µ ë°©ì§€   | ê²°ì •ë¡ ì  Object Key + `head_object` ì‚¬ì „ ê²€ì‚¬ |

> **âš ï¸ 5ì°¨ ê²€í†  ìˆ˜ì • (2025-12-08)**: ETag ê¸°ë°˜ `If-None-Match` í—¤ë”ëŠ” MinIOì—ì„œ íŒŒì¼ ë‚´ìš© í•´ì‹œë¡œ ì‚¬ìš©ë˜ë¯€ë¡œ task_id ê¸°ë°˜ ì¤‘ë³µ ë°©ì§€ì— ì í•©í•˜ì§€ ì•ŠìŒ. **ê²°ì •ë¡ ì  Object Key íŒ¨í„´**ìœ¼ë¡œ êµì²´.

**êµ¬í˜„ ì½”ë“œ**:

```python
# tasks/idempotent_task.py
from celery import shared_task
from celery.exceptions import Reject
from sqlalchemy import select, update
from sqlalchemy.dialects.postgresql import insert as pg_insert

@shared_task(bind=True, acks_late=True)
def process_dxf(self, task_id: str, file_url: str):
    """ë©±ë“±ì„±ì´ ë³´ì¥ëœ DXF ì²˜ë¦¬ Task"""

    # 1. ì¤‘ë³µ ì‹¤í–‰ ê²€ì‚¬
    existing = get_task_status(task_id)
    if existing and existing.status == 'SUCCESS':
        log.info("task_already_completed", task_id=task_id)
        return existing.result_url

    # 2. ì›ìì  ìƒíƒœ ì „ì´ (PENDING â†’ RUNNING)
    updated = atomic_update_status(
        task_id=task_id,
        from_status='PENDING',
        to_status='RUNNING',
        worker_id=self.request.hostname
    )

    if not updated:
        # ë‹¤ë¥¸ Workerê°€ ì´ë¯¸ ì²˜ë¦¬ ì¤‘
        log.warning("task_already_running", task_id=task_id)
        raise Reject("Task already being processed", requeue=False)

    try:
        # 3. ì‹¤ì œ ì²˜ë¦¬ ë¡œì§
        result = parse_and_convert_dxf(file_url)

        # 4. ê²°ì •ë¡ ì  Object Key ê¸°ë°˜ ë©±ë“±ì„± ì—…ë¡œë“œ (5ì°¨ ê²€í†  ìˆ˜ì •)
        output_url = upload_result_idempotent(
            result=result,
            task_id=task_id
        )

        # 5. ì„±ê³µ ìƒíƒœ ì—…ë°ì´íŠ¸
        update_task_status(task_id, 'SUCCESS', result_url=output_url)
        return output_url

    except Exception as e:
        update_task_status(task_id, 'FAILURE', error=str(e))
        raise


def atomic_update_status(task_id: str, from_status: str, to_status: str, worker_id: str) -> bool:
    """ì›ìì  ìƒíƒœ ì „ì´ - SELECT FOR UPDATEë¡œ Race Condition ë°©ì§€ (8ì°¨ ê²€í†  ìˆ˜ì •)

    CRITICAL: ë‚™ê´€ì  ì ê¸ˆ(rowcount ì²´í¬)ë§Œìœ¼ë¡œëŠ” ë™ì‹œ Worker ê²½ìŸ ì‹œ
    Race Condition ë°œìƒ ê°€ëŠ¥. ë°˜ë“œì‹œ SELECT FOR UPDATEë¡œ ë¹„ê´€ì  ì ê¸ˆ í•„ìˆ˜.
    """
    with db.begin():
        # CRITICAL: SELECT FOR UPDATE í•„ìˆ˜ (ë‚™ê´€ì  ì ê¸ˆë§Œìœ¼ë¡œëŠ” ë¶ˆì¶©ë¶„)
        task = db.execute(
            select(TaskStatus)
            .where(TaskStatus.task_id == task_id)
            .with_for_update(nowait=True)  # ì¦‰ì‹œ ì‹¤íŒ¨ë¡œ ê²½í•© ê°ì§€
        ).scalar_one_or_none()

        if not task or task.status != from_status:
            return False  # ìƒíƒœ ë¶ˆì¼ì¹˜ ì‹œ ì‹¤íŒ¨

        task.status = to_status
        task.worker_id = worker_id
        task.updated_at = func.now()
        db.flush()
        return True


def upload_result_idempotent(result: bytes, task_id: str) -> str:
    """ê²°ì •ë¡ ì  Object Key ê¸°ë°˜ ë©±ë“±ì„± ì—…ë¡œë“œ (5ì°¨ ê²€í†  ì¶”ê°€)

    MinIO ETagëŠ” íŒŒì¼ ë‚´ìš© í•´ì‹œì´ë¯€ë¡œ task_id ê¸°ë°˜ ì¤‘ë³µ ë°©ì§€ì— ë¶€ì í•©.
    ëŒ€ì‹  ê²°ì •ë¡ ì  Object Key + head_object ì‚¬ì „ ê²€ì‚¬ë¡œ ë©±ë“±ì„± ë³´ì¥.
    """
    import boto3
    from botocore.exceptions import ClientError

    s3_client = boto3.client('s3', endpoint_url=MINIO_ENDPOINT)
    object_key = f"results/{task_id}.gltf"

    try:
        # ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (head_object)
        s3_client.head_object(Bucket=BUCKET, Key=object_key)
        log.info("result_already_exists", task_id=task_id, key=object_key)
        return generate_presigned_url(object_key)  # ê¸°ì¡´ ê²°ê³¼ ë°˜í™˜

    except ClientError as e:
        if e.response['Error']['Code'] == '404':
            # ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ì—…ë¡œë“œ
            s3_client.put_object(
                Bucket=BUCKET,
                Key=object_key,
                Body=result,
                ContentType='model/gltf-binary'
            )
            log.info("result_uploaded", task_id=task_id, key=object_key)
            return generate_presigned_url(object_key)
        raise


def mark_as_reprocessing(task_id: str) -> bool:
    """DLQ â†’ REPROCESSING ì›ìì  ìƒíƒœ ì „ì´ + RabbitMQ ì¬íˆ¬ì… (8ì°¨ ê²€í†  ìˆ˜ì •)

    CRITICAL: SELECT FOR UPDATEë¡œ ë™ì‹œ ì¬ì²˜ë¦¬ ë°©ì§€ (ë‚™ê´€ì  ì ê¸ˆ ë¶ˆì¶©ë¶„).
    DLQ ë©”ì‹œì§€ ì¬ì²˜ë¦¬ ì‹œ ë™ì‹œì„± ì œì–´ë¥¼ ìœ„í•´ ì›ìì  ìƒíƒœ ì „ì´ ìˆ˜í–‰.
    ì´ë¯¸ ë‹¤ë¥¸ Workerê°€ ì¬ì²˜ë¦¬ ì¤‘ì¸ ê²½ìš° False ë°˜í™˜.
    """
    with db.begin():
        # CRITICAL: SELECT FOR UPDATE í•„ìˆ˜ (ë™ì‹œ ì¬ì²˜ë¦¬ ë°©ì§€)
        task = db.execute(
            select(TaskStatus)
            .where(TaskStatus.task_id == task_id)
            .where(TaskStatus.status == 'DLQ')
            .with_for_update(nowait=True)
        ).scalar_one_or_none()

        if not task:
            return False  # ì´ë¯¸ ì¬ì²˜ë¦¬ ì¤‘ì´ê±°ë‚˜ DLQ ì•„ë‹˜

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        task.status = 'REPROCESSING'
        task.retry_count = 0  # ì¬ì‹œë„ ì¹´ìš´í„° ë¦¬ì…‹
        task.reprocessed_at = func.now()
        task.reprocess_count = (task.reprocess_count or 0) + 1
        db.flush()

        # RabbitMQì— ì¬íˆ¬ì… (íŠ¸ëœì­ì…˜ ì»¤ë°‹ í›„ ì‹¤í–‰)
        republish_to_queue(task_id, task.original_payload)
        return True


def republish_to_queue(task_id: str, payload: dict):
    """DLQ ë©”ì‹œì§€ë¥¼ ì›ë³¸ íë¡œ ì¬íˆ¬ì…"""
    queue_name = payload.get('queue', 'dxf_queue')
    channel.basic_publish(
        exchange='',
        routing_key=queue_name,
        body=json.dumps(payload),
        properties=pika.BasicProperties(
            delivery_mode=2,  # persistent
            headers={'x-reprocessed': True, 'x-original-task-id': task_id}
        )
    )
```

#### DLQ ì¬ì²˜ë¦¬ ë™ì‹œì„± ì œì–´ (4ì°¨ ê²€í†  ì¶”ê°€)

> **ğŸ“Œ Backend Architect ê¶Œì¥ì‚¬í•­ ë°˜ì˜** (2025-12-08)

**ë¬¸ì œì **: `scan_and_reprocess_dlq` Taskê°€ ë™ì‹œ ì‹¤í–‰ ì‹œ ë™ì¼ ë©”ì‹œì§€ê°€ ì—¬ëŸ¬ ë²ˆ ì¬ì²˜ë¦¬ë  ìˆ˜ ìˆìŒ

**í•´ê²°ì±…**: PostgreSQL Advisory Lock ê¸°ë°˜ ë¶„ì‚° ë½

```python
# tasks/dlq_processor.py (ë™ì‹œì„± ì œì–´ ì¶”ê°€)
from contextlib import contextmanager
import hashlib

@contextmanager
def distributed_lock(lock_name: str, timeout_seconds: int = 300):
    """PostgreSQL Advisory Lock ê¸°ë°˜ ë¶„ì‚° ë½

    Args:
        lock_name: ë½ ì‹ë³„ì (ì˜ˆ: "dlq_reprocessing")
        timeout_seconds: ë½ íƒ€ì„ì•„ì›ƒ (ê¸°ë³¸ 5ë¶„)
    """
    # ë½ ID ìƒì„± (32-bit signed int)
    lock_id = int(hashlib.md5(lock_name.encode()).hexdigest()[:8], 16) % (2**31)

    conn = get_db_connection()
    try:
        # Non-blocking ë½ ì‹œë„
        acquired = conn.execute(
            "SELECT pg_try_advisory_lock(%s)", (lock_id,)
        ).scalar()

        if not acquired:
            raise LockAcquireError(f"Failed to acquire lock: {lock_name}")

        log.info("lock_acquired", lock_name=lock_name, lock_id=lock_id)
        yield

    finally:
        conn.execute("SELECT pg_advisory_unlock(%s)", (lock_id,))
        log.info("lock_released", lock_name=lock_name)


@shared_task
def scan_and_reprocess_dlq():
    """DLQ ë©”ì‹œì§€ ìŠ¤ìº” ë° ì¡°ê±´ë¶€ ì¬ì²˜ë¦¬ (ë™ì‹œì„± ì œì–´ ì ìš©)"""
    try:
        with distributed_lock("dlq_reprocessing"):
            for queue in ['dxf_dlq', 'pdf_dlq']:
                messages = get_dlq_messages(queue)
                for msg in messages:
                    # ì¬ì²˜ë¦¬ ì „ ìƒíƒœë¥¼ 'REPROCESSING'ìœ¼ë¡œ atomic update
                    if not mark_as_reprocessing(msg.task_id):
                        continue  # ì´ë¯¸ ë‹¤ë¥¸ Workerê°€ ì²˜ë¦¬ ì¤‘

                    if msg.error_code in RETRYABLE_ERRORS and msg.reprocess_count < 1:
                        requeue_message(msg, original_queue=queue.replace('_dlq', '_queue'))
                        increment_reprocess_count(msg.task_id)
                        log.info("dlq_reprocessed", task_id=msg.task_id)

    except LockAcquireError:
        log.warning("dlq_scan_skipped", reason="Another worker is processing DLQ")
```

#### í”„ë¡œë•ì…˜ Celery ì„¤ì •

```python
# celeryconfig.py
from kombu import Queue

# Broker ì„¤ì •
broker_url = "amqps://user:pass@rabbitmq:5671/vhost"
result_backend = "db+postgresql://user:pass@postgres:5432/celery"

# Task ì„¤ì •
task_time_limit = 300          # 5ë¶„ í•˜ë“œ ë¦¬ë°‹
task_soft_time_limit = 240     # 4ë¶„ ì†Œí”„íŠ¸ ë¦¬ë°‹ (ê²½ê³ )
task_acks_late = True          # ì™„ë£Œ í›„ ACK (í¬ë˜ì‹œ ì‹œ ì¬ì²˜ë¦¬)
task_reject_on_worker_lost = True

# Worker Pool ì„¤ì •
worker_pool = "prefork"
worker_concurrency = 4         # 4 vCPU ê¸°ì¤€
worker_max_tasks_per_child = 100  # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
worker_prefetch_multiplier = 1    # Fair dispatch

# í ì„¤ì •
task_queues = (
    Queue("dxf_queue", routing_key="dxf.#"),
    Queue("pdf_queue", routing_key="pdf.#"),
    Queue("dxf_dlq", routing_key="dxf.dlq"),
    Queue("pdf_dlq", routing_key="pdf.dlq"),
)

# ì¬ì‹œë„ ì •ì±…
task_annotations = {
    "tasks.process_dxf": {
        "autoretry_for": (NetworkError, TemporaryResourceError),
        "retry_kwargs": {"max_retries": 3, "countdown": 60},
        "retry_backoff": True,
        "retry_backoff_max": 600,
        "retry_jitter": True,
    }
}

# ê²°ê³¼ ë§Œë£Œ
result_expires = 86400  # 24ì‹œê°„
```

**DXF vs PDF Worker ì„¤ì • ì°¨ì´**:

| ì„¤ì •                          | DXF Worker  | PDF Worker     |
| ----------------------------- | ----------- | -------------- |
| `worker_concurrency`          | 4           | 2 (GPU ë©”ëª¨ë¦¬) |
| `worker_max_memory_per_child` | 2GB         | 8GB            |
| `task_time_limit`             | 300ì´ˆ       | 600ì´ˆ          |
| í                            | `dxf_queue` | `pdf_queue`    |

#### 5.5.7 ë©”ì‹œì§€ ìŠ¤í‚¤ë§ˆ ë²„ì „ ê´€ë¦¬ (8ì°¨ ê²€í†  ì¶”ê°€)

> **Backend Architect ê¶Œì¥ì‚¬í•­**: ë¬´ì¤‘ë‹¨ ë°°í¬ì™€ í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë©”ì‹œì§€ ìŠ¤í‚¤ë§ˆ ë²„ì „ ê´€ë¦¬ í•„ìˆ˜

**Celery ë©”ì‹œì§€ ìŠ¤í‚¤ë§ˆ ì •ì˜**:

```python
# schemas/task_message.py
from dataclasses import dataclass
from typing import Optional
from datetime import datetime

CURRENT_SCHEMA_VERSION = "1.1.0"

@dataclass
class TaskMessage:
    """Celery Task ë©”ì‹œì§€ í‘œì¤€ ìŠ¤í‚¤ë§ˆ"""
    # í•„ìˆ˜ í•„ë“œ (v1.0.0)
    schema_version: str
    task_id: str
    file_url: str
    callback_url: str

    # ì„ íƒì  í•„ë“œ (v1.1.0 ì¶”ê°€)
    priority: Optional[int] = None
    metadata: Optional[dict] = None
    created_at: Optional[datetime] = None

    def to_dict(self) -> dict:
        return {
            "schema_version": self.schema_version,
            "task_id": self.task_id,
            "file_url": self.file_url,
            "callback_url": self.callback_url,
            "priority": self.priority,
            "metadata": self.metadata,
            "created_at": self.created_at.isoformat() if self.created_at else None,
        }
```

**ë²„ì „ í˜¸í™˜ì„± ì •ì±…**:

| ë²„ì „ ë³€ê²½ ìœ í˜•    | ì˜ˆì‹œ                 | ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ               | ë‹¤ìš´íƒ€ì„ |
| ----------------- | -------------------- | ------------------------------- | -------- |
| **Patch** (1.0.X) | ë²„ê·¸ ìˆ˜ì •, ì£¼ì„ ì¶”ê°€ | ë¬´ì¤‘ë‹¨ ë°°í¬                     | ì—†ìŒ     |
| **Minor** (1.X.0) | ì„ íƒì  í•„ë“œ ì¶”ê°€     | í•˜ìœ„ í˜¸í™˜, ë¬´ì¤‘ë‹¨ ë°°í¬          | ì—†ìŒ     |
| **Major** (X.0.0) | í•„ìˆ˜ í•„ë“œ ë³€ê²½/ì‚­ì œ  | ìƒˆ í ìƒì„±, ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ | ê³„íšëœ   |

**Workerì—ì„œì˜ ë²„ì „ ì²˜ë¦¬**:

```python
# tasks/base.py
from packaging import version

def validate_message_schema(message: dict) -> dict:
    """ë©”ì‹œì§€ ìŠ¤í‚¤ë§ˆ ë²„ì „ ê²€ì¦ ë° ë§ˆì´ê·¸ë ˆì´ì…˜"""
    msg_version = message.get("schema_version", "1.0.0")

    # í•˜ìœ„ í˜¸í™˜ì„±: ì´ì „ ë²„ì „ ë©”ì‹œì§€ ì²˜ë¦¬
    if version.parse(msg_version) < version.parse("1.1.0"):
        # v1.0.0 â†’ v1.1.0 ë§ˆì´ê·¸ë ˆì´ì…˜
        message.setdefault("priority", 5)  # ê¸°ë³¸ ìš°ì„ ìˆœìœ„
        message.setdefault("metadata", {})
        message["schema_version"] = "1.1.0"

    # Major ë²„ì „ ë¶ˆì¼ì¹˜: ê±°ë¶€
    if version.parse(msg_version).major != version.parse(CURRENT_SCHEMA_VERSION).major:
        raise SchemaVersionError(
            f"Incompatible schema version: {msg_version}, expected major: {CURRENT_SCHEMA_VERSION.split('.')[0]}"
        )

    return message

@celery.task(bind=True)
def process_dxf(self, **kwargs):
    message = validate_message_schema(kwargs)
    # ... ì²˜ë¦¬ ë¡œì§
```

**Major ë²„ì „ ë§ˆì´ê·¸ë ˆì´ì…˜ ì ˆì°¨**:

```mermaid
sequenceDiagram
    participant P as Producer
    participant Q1 as dxf_queue_v1
    participant Q2 as dxf_queue_v2
    participant W1 as Worker v1
    participant W2 as Worker v2

    Note over P,W2: Phase 1: ì‹ ê·œ í ìƒì„±
    P->>Q1: ê¸°ì¡´ ë©”ì‹œì§€ (v1)
    W1->>Q1: ì†Œë¹„
    P->>Q2: ì‹ ê·œ ë©”ì‹œì§€ (v2)
    W2->>Q2: ì†Œë¹„

    Note over P,W2: Phase 2: Producer ì „í™˜
    P->>Q2: ëª¨ë“  ë©”ì‹œì§€ (v2)
    W1->>Q1: ì”ì—¬ ë©”ì‹œì§€ ì²˜ë¦¬

    Note over P,W2: Phase 3: ê¸°ì¡´ í ì œê±°
    W1--xQ1: ë¹„í™œì„±í™”
```

#### 5.5.8 Control Plane vs Data Plane ë¶„ë¦¬ (8ì°¨ ê²€í†  ì¶”ê°€)

> **System Architect ê¶Œì¥ì‚¬í•­**: ì¥ì•  ê²©ë¦¬ ë° ë…ë¦½ ìŠ¤ì¼€ì¼ë§ì„ ìœ„í•œ ëª…í™•í•œ Plane ë¶„ë¦¬

**Control Plane ì»´í¬ë„ŒíŠ¸**:

| ì»´í¬ë„ŒíŠ¸            | ì—­í•                   | ì¥ì•  ì˜í–¥ ë²”ìœ„ |
| ------------------- | --------------------- | -------------- |
| RabbitMQ Management | í ê´€ë¦¬, ëª¨ë‹ˆí„°ë§     | ê´€ë¦¬ ê¸°ëŠ¥ë§Œ    |
| Celery Beat         | ìŠ¤ì¼€ì¤„ëŸ¬, ì£¼ê¸°ì  Task | ì˜ˆì•½ Taskë§Œ    |
| Flower              | ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§       | ê°€ì‹œì„±ë§Œ       |

**Data Plane ì»´í¬ë„ŒíŠ¸**:

| ì»´í¬ë„ŒíŠ¸       | ì—­í•           | ì¥ì•  ì˜í–¥ ë²”ìœ„ |
| -------------- | ------------- | -------------- |
| Worker Pods    | Task ì‹¤í–‰     | í•´ë‹¹ Workerë§Œ  |
| RabbitMQ Nodes | ë©”ì‹œì§€ ë¼ìš°íŒ… | ì „ì²´ ì‹œìŠ¤í…œ    |
| PostgreSQL     | ìƒíƒœ ì €ì¥     | ì „ì²´ ì‹œìŠ¤í…œ    |
| MinIO          | íŒŒì¼ ì €ì¥     | ì „ì²´ ì‹œìŠ¤í…œ    |

**ë¶„ë¦¬ ì›ì¹™**:

1. **Control Plane ì¥ì•  ê²©ë¦¬**: Control Plane ì¥ì•  ì‹œ Data Plane ì˜í–¥ ìµœì†Œí™”
    - Flower ë‹¤ìš´ â†’ ëª¨ë‹ˆí„°ë§ë§Œ ë¶ˆê°€, Task ì²˜ë¦¬ ì •ìƒ
    - Beat ë‹¤ìš´ â†’ ì£¼ê¸°ì  Taskë§Œ ì¤‘ë‹¨, ìš”ì²­ ê¸°ë°˜ Task ì •ìƒ

2. **Data Plane ë…ë¦½ ìŠ¤ì¼€ì¼ë§**: ê° ì»´í¬ë„ŒíŠ¸ ë³„ë„ ìŠ¤ì¼€ì¼ë§ ê°€ëŠ¥
    - DXF Worker: CPU ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
    - PDF Worker: GPU ë©”ëª¨ë¦¬ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§

3. **ì¥ì•  ë„ë©”ì¸ ê²©ë¦¬**: ì¥ì•  ë²”ìœ„ ìµœì†Œí™”ë¡œ ë³µêµ¬ ì‹œê°„ ë‹¨ì¶•
    - Worker ì¥ì•  â†’ í•´ë‹¹ Workerë§Œ ì¬ì‹œì‘
    - RabbitMQ ì¥ì•  â†’ ì „ì²´ ì‹œìŠ¤í…œ ì˜í–¥ (ìµœìš°ì„  ë³µêµ¬ ëŒ€ìƒ)

```mermaid
graph TB
    subgraph ControlPlane["Control Plane (ê´€ë¦¬)"]
        RMgmt[RabbitMQ Management]
        Beat[Celery Beat]
        Flower[Flower UI]
    end

    subgraph DataPlane["Data Plane (ì‹¤í–‰)"]
        DXF[DXF Worker]
        PDF[PDF Worker]
        RMQ[RabbitMQ Nodes]
        PG[PostgreSQL]
        MinIO[MinIO Storage]
    end

    ControlPlane -.->|ëª¨ë‹ˆí„°ë§/ê´€ë¦¬| DataPlane
    DXF -->|ë©”ì‹œì§€| RMQ
    PDF -->|ë©”ì‹œì§€| RMQ
    DXF -->|ê²°ê³¼ ì €ì¥| PG
    PDF -->|ê²°ê³¼ ì €ì¥| PG
    DXF -->|íŒŒì¼ ì €ì¥| MinIO
    PDF -->|íŒŒì¼ ì €ì¥| MinIO
```

**Kubernetes êµ¬í˜„**:

```yaml
# Control Plane: ë‚®ì€ ë¦¬ì†ŒìŠ¤, ë†’ì€ ê°€ìš©ì„±
apiVersion: apps/v1
kind: Deployment
metadata:
    name: celery-beat
    labels:
        plane: control
spec:
    replicas: 1 # ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ (ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€)
    selector:
        matchLabels:
            app: celery-beat
    template:
        spec:
            nodeSelector:
                plane: control # Control Plane ì „ìš© ë…¸ë“œ
            resources:
                requests:
                    cpu: '100m'
                    memory: '256Mi'
                limits:
                    cpu: '500m'
                    memory: '512Mi'
---
# Data Plane: ë†’ì€ ë¦¬ì†ŒìŠ¤, ìˆ˜í‰ ìŠ¤ì¼€ì¼ë§
apiVersion: apps/v1
kind: Deployment
metadata:
    name: dxf-worker
    labels:
        plane: data
spec:
    replicas: 2 # HPAë¡œ ìë™ ìŠ¤ì¼€ì¼ë§
    selector:
        matchLabels:
            app: dxf-worker
    template:
        spec:
            nodeSelector:
                plane: data # Data Plane ì „ìš© ë…¸ë“œ
            resources:
                requests:
                    cpu: '1'
                    memory: '2Gi'
                limits:
                    cpu: '4'
                    memory: '4Gi'
```

---

### 5.6 Docker ì»¨í…Œì´ë„ˆí™”

#### Base ì´ë¯¸ì§€ ì„ íƒ

| ì´ë¯¸ì§€                       | í¬ê¸°   | ë³´ì•ˆ       | í˜¸í™˜ì„±                | ìš©ë„            |
| ---------------------------- | ------ | ---------- | --------------------- | --------------- |
| **python:3.12-slim**         | ~150MB | â­â­â­â­   | â­â­â­â­â­            | âœ… CPU Worker   |
| python:3.12-alpine           | ~55MB  | â­â­â­â­â­ | â­â­â­ musl í˜¸í™˜ ì´ìŠˆ | âŒ              |
| **nvidia/cuda:12.2-runtime** | ~1.8GB | â­â­â­â­   | â­â­â­â­â­            | âœ… GPU Worker   |
| distroless                   | ~30MB  | â­â­â­â­â­ | â­â­ ë””ë²„ê¹… ì–´ë ¤ì›€    | í”„ë¡œë•ì…˜ ìµœì í™” |

**ì„ ì • ê·¼ê±°**:

- **python:3.12-slim**: Debian ê¸°ë°˜, ëŒ€ë¶€ë¶„ì˜ wheel í˜¸í™˜, ì ì ˆí•œ í¬ê¸°
- **nvidia/cuda**: GPU ê°€ì† í•„ìˆ˜, CUDA ë¼ì´ë¸ŒëŸ¬ë¦¬ í¬í•¨

#### Multi-stage ë¹Œë“œ ì „ëµ

```dockerfile
# Stage 1: Builder
FROM python:3.12-slim AS builder
WORKDIR /app
RUN pip install pip-tools
COPY requirements.in .
RUN pip-compile requirements.in -o requirements.txt
RUN pip wheel --no-cache-dir --wheel-dir=/wheels -r requirements.txt

# Stage 2: Runtime
FROM python:3.12-slim AS runtime
WORKDIR /app

# ë¹„root ì‚¬ìš©ì
RUN useradd --create-home appuser
USER appuser

# ì˜ì¡´ì„± ì„¤ì¹˜
COPY --from=builder /wheels /wheels
RUN pip install --no-cache-dir --user /wheels/*

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ
COPY --chown=appuser:appuser . .

# Health check
HEALTHCHECK --interval=30s --timeout=10s \
  CMD celery -A worker inspect ping || exit 1

CMD ["celery", "-A", "worker", "worker", "-l", "info"]
```

**Multi-stage íš¨ê³¼**:

- ë¹Œë“œ ë„êµ¬ ì œì™¸ë¡œ 60% ì´ë¯¸ì§€ í¬ê¸° ê°ì†Œ
- ë³´ì•ˆ: ë¹Œë“œ ì‹œí¬ë¦¿ ëŸ°íƒ€ì„ì— í¬í•¨ ì•ˆ ë¨

### 5.7 ëª¨ë‹ˆí„°ë§ ë„êµ¬

#### ë©”íŠ¸ë¦­ ìˆ˜ì§‘/ì‹œê°í™”

| ê¸°ì¤€              | Prometheus + Grafana       | Datadog           | ELK Stack           |
| ----------------- | -------------------------- | ----------------- | ------------------- |
| **ë¹„ìš©**          | â­â­â­â­â­ ë¬´ë£Œ (OSS)      | â­â­ SaaS ë¹„ìš©    | â­â­â­â­ ë¬´ë£Œ (OSS) |
| **Celery í†µí•©**   | â­â­â­â­â­ celery-exporter | â­â­â­â­ ì—ì´ì „íŠ¸ | â­â­â­ ì»¤ìŠ¤í…€ í•„ìš”  |
| **ëŒ€ì‹œë³´ë“œ**      | â­â­â­â­â­ í’ë¶€ (ì»¤ìŠ¤í…€)   | â­â­â­â­â­ í’ë¶€   | â­â­â­â­ Kibana     |
| **ì•Œë¦¼**          | â­â­â­â­ Alertmanager      | â­â­â­â­â­ ë‚´ì¥   | â­â­â­ Watcher      |
| **ìš´ì˜ ë³µì¡ë„**   | â­â­â­â­ ì¤‘ê°„              | â­â­â­â­â­ ë‚®ìŒ   | â­â­â­ ë†’ìŒ         |
| **2-3ëª… íŒ€ ì í•©** | â­â­â­â­â­ ë†’ìŒ            | â­â­â­ ë¹„ìš© ë¶€ë‹´  | â­â­â­ ë³µì¡ë„       |
| **ì¢…í•©**          | **90ì **                   | 75ì               | 70ì                 |

**Prometheus + Grafana ì ìˆ˜ ê³„ì‚°**:

- ë¹„ìš© (20%): 5 Ã— 0.2 = 1.0
- Celery í†µí•© (25%): 5 Ã— 0.25 = 1.25
- ëŒ€ì‹œë³´ë“œ (15%): 5 Ã— 0.15 = 0.75
- ì•Œë¦¼ (15%): 4 Ã— 0.15 = 0.6
- ìš´ì˜ ë³µì¡ë„ (15%): 4 Ã— 0.15 = 0.6
- íŒ€ ì í•©ì„± (10%): 5 Ã— 0.1 = 0.5
- **í•©ê³„**: 4.7 Ã— 20 = **94ì ** â†’ ë³´ìˆ˜ì ìœ¼ë¡œ **90ì **

#### Celery ì „ìš© ëª¨ë‹ˆí„°ë§

| ê¸°ì¤€            | Flower     | celery-events | ìì²´ êµ¬í˜„ |
| --------------- | ---------- | ------------- | --------- |
| **ì‹¤ì‹œê°„ UI**   | â­â­â­â­â­ | âŒ            | â­â­â­    |
| **ì‘ì—… ìƒíƒœ**   | â­â­â­â­â­ | â­â­â­â­      | â­â­â­    |
| **Worker ê´€ë¦¬** | â­â­â­â­â­ | âŒ            | â­â­      |
| **ì„¤ì¹˜ ìš©ì´ì„±** | â­â­â­â­â­ | â­â­â­â­â­    | â­â­      |
| **ì¢…í•©**        | **95ì **   | 60ì           | 50ì       |

**Flower ì ìˆ˜ ê³„ì‚°**:

- ì‹¤ì‹œê°„ UI (30%): 5 Ã— 0.3 = 1.5
- ì‘ì—… ìƒíƒœ (30%): 5 Ã— 0.3 = 1.5
- Worker ê´€ë¦¬ (20%): 5 Ã— 0.2 = 1.0
- ì„¤ì¹˜ ìš©ì´ì„± (20%): 5 Ã— 0.2 = 1.0
- **í•©ê³„**: 5.0 Ã— 20 = **100ì ** â†’ ë³´ìˆ˜ì ìœ¼ë¡œ **95ì **

#### ê¶Œì¥: Prometheus + Grafana + Flower

**ì„ ì • ê·¼ê±°**:

1. **ë¹„ìš© íš¨ìœ¨**: ëª¨ë‘ ì˜¤í”ˆì†ŒìŠ¤, SaaS ë¹„ìš© ì—†ìŒ
2. **Celery ì™„ë²½ í†µí•©**: celery-exporterë¡œ Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘ + Flower ì‹¤ì‹œê°„ UI
3. **ì»¤ìŠ¤í„°ë§ˆì´ì§•**: Grafana ëŒ€ì‹œë³´ë“œ ììœ ë¡­ê²Œ êµ¬ì„± ê°€ëŠ¥
4. **2-3ëª… íŒ€ ì í•©**: ìš´ì˜ ë³µì¡ë„ ë‚®ìŒ, í•™ìŠµ ê³¡ì„  ì™„ë§Œ

**ì•„í‚¤í…ì²˜**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Celery    â”‚â”€â”€â”€â”€â–¶â”‚ celery-exporter  â”‚â”€â”€â”€â”€â–¶â”‚ Prometheus  â”‚
â”‚   Workers   â”‚     â”‚   (ë©”íŠ¸ë¦­ ìˆ˜ì§‘)   â”‚     â”‚  (ì €ì¥ì†Œ)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                           â”‚
       â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚     Flower       â”‚           â”‚
                    â”‚ (ì‹¤ì‹œê°„ Task UI)  â”‚           â–¼
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                             â”‚   Grafana   â”‚
                                             â”‚ (ì‹œê°í™”/ì•Œë¦¼)â”‚
                                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Prometheus ì•Œë¦¼ ê·œì¹™

**SLA ëª¨ë‹ˆí„°ë§ ì•Œë¦¼** (7ì¼ í‰ê·  ê¸°ì¤€):

> ì„¹ì…˜ 3ì˜ SLA(DXF < 5ì´ˆ, PDF < 30ì´ˆ)ëŠ” ë‹¨ê±´ ì²˜ë¦¬ ê¸°ì¤€ì´ë©°, ì•„ë˜ ì•Œë¦¼ì€ **7ì¼ ì´ë™ í‰ê· **ìœ¼ë¡œ SLA ìœ„ë°˜ ì—¬ë¶€ë¥¼ íŒì •í•©ë‹ˆë‹¤.

```yaml
# prometheus/rules/worker_alerts.yml
groups:
    - name: worker_sla_alerts
      rules:
          # DXF SLA ìœ„ë°˜ (7ì¼ í‰ê·  > 5ì´ˆ)
          - alert: DXFProcessingSLAViolation
            expr: |
                avg_over_time(
                  celery_task_runtime_seconds{task="tasks.process_dxf"}[7d]
                ) > 5
            for: 1h
            labels:
                severity: critical
            annotations:
                summary: 'DXF ì²˜ë¦¬ SLA ìœ„ë°˜'
                description: 'DXF 7ì¼ í‰ê·  ì²˜ë¦¬ ì‹œê°„ì´ 5ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. í˜„ì¬: {{ $value | printf "%.2f" }}ì´ˆ'

          # PDF SLA ìœ„ë°˜ (7ì¼ í‰ê·  > 30ì´ˆ)
          - alert: PDFProcessingSLAViolation
            expr: |
                avg_over_time(
                  celery_task_runtime_seconds{task="tasks.process_pdf"}[7d]
                ) > 30
            for: 1h
            labels:
                severity: critical
            annotations:
                summary: 'PDF ì²˜ë¦¬ SLA ìœ„ë°˜'
                description: 'PDF 7ì¼ í‰ê·  ì²˜ë¦¬ ì‹œê°„ì´ 30ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. í˜„ì¬: {{ $value | printf "%.2f" }}ì´ˆ'
```

**Worker ìƒíƒœ ì•Œë¦¼**:

```yaml
- name: worker_health_alerts
  rules:
      # Worker í¬ë˜ì‹œìœ¨ (3ì¼ ì—°ì† 5íšŒ/ì¼ ì´ˆê³¼)
      - alert: WorkerCrashRateHigh
        expr: |
            sum(increase(celery_worker_tasks_failed_total[1d])) by (worker) > 5
        for: 72h
        labels:
            severity: warning
        annotations:
            summary: 'Worker í¬ë˜ì‹œìœ¨ ë†’ìŒ'
            description: '{{ $labels.worker }} í¬ë˜ì‹œìœ¨ì´ 3ì¼ ì—°ì† 5íšŒ/ì¼ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.'

      # í ì ì²´ (100ê±´ ì´ˆê³¼ 10ë¶„ ì§€ì†)
      - alert: QueueBacklogCritical
        expr: celery_queue_length > 100
        for: 10m
        labels:
            severity: critical
        annotations:
            summary: 'í ì ì²´ ìœ„í—˜'
            description: '{{ $labels.queue }} íì— {{ $value }}ê±´ì´ ì ì²´ë˜ì—ˆìŠµë‹ˆë‹¤.'

      # DLQ ë©”ì‹œì§€ ì¦ê°€
      - alert: DLQDepthHigh
        expr: celery_queue_length{queue=~".*_dlq"} > 10
        for: 5m
        labels:
            severity: warning
        annotations:
            summary: 'DLQ ë©”ì‹œì§€ ì¦ê°€'
            description: '{{ $labels.queue }}ì— {{ $value }}ê±´ì˜ ì‹¤íŒ¨ ë©”ì‹œì§€ê°€ ìˆìŠµë‹ˆë‹¤.'
```

**Alertmanager ë¼ìš°íŒ…**:

```yaml
# alertmanager/config.yml
route:
    group_by: ['alertname', 'severity']
    group_wait: 30s
    group_interval: 5m
    repeat_interval: 4h
    receiver: 'slack-notifications'
    routes:
        - match:
              severity: critical
          receiver: 'pagerduty-critical'
        - match:
              severity: warning
          receiver: 'slack-notifications'

receivers:
    - name: 'slack-notifications'
      slack_configs:
          - channel: '#cad-worker-alerts'
            send_resolved: true
    - name: 'pagerduty-critical'
      pagerduty_configs:
          - service_key: '<PAGERDUTY_KEY>'
```

**í•µì‹¬ ë©”íŠ¸ë¦­ ëŒ€ì‹œë³´ë“œ íŒ¨ë„**:

| íŒ¨ë„          | PromQL                                                                | ìš©ë„         |
| ------------- | --------------------------------------------------------------------- | ------------ |
| ì²˜ë¦¬ ì‹œê°„ P95 | `histogram_quantile(0.95, celery_task_runtime_seconds_bucket)`        | SLA ëª¨ë‹ˆí„°ë§ |
| í ê¹Šì´       | `celery_queue_length`                                                 | ë¶€í•˜ ìƒíƒœ    |
| ì„±ê³µë¥         | `rate(celery_task_succeeded_total[5m]) / rate(celery_task_total[5m])` | ì•ˆì •ì„±       |
| Worker í™œì„±   | `celery_workers`                                                      | ê°€ìš©ì„±       |

### 5.8 ë³´ì•ˆ ì„¤ê³„

#### Docker ë³´ì•ˆ

| í•­ëª©             | ìš”êµ¬ì‚¬í•­    | êµ¬í˜„ ë°©ì•ˆ                       |
| ---------------- | ----------- | ------------------------------- |
| ì´ë¯¸ì§€ ë²„ì „ ê³ ì • | digest í¬í•¨ | `python:3.12.x-slim@sha256:...` |
| ì·¨ì•½ì  ìŠ¤ìº”      | CI/CD í†µí•©  | Trivy, GitHub Actions           |
| ë¹„root ì‹¤í–‰      | âœ… êµ¬í˜„ë¨   | `USER appuser`                  |
| Readonly FS      | ê¶Œì¥        | `--read-only` í”Œë˜ê·¸            |

#### ì˜ì¡´ì„± ë³´ì•ˆ

```bash
# í•´ì‹œ ê²€ì¦ í™œì„±í™”
pip-compile --generate-hashes requirements.in
pip install --require-hashes -r requirements.txt
```

**ì·¨ì•½ì  ìŠ¤ìº”**: `pip-audit` ë˜ëŠ” `safety` CI í†µí•©

#### Worker ë³´ì•ˆ

| í•­ëª©        | êµ¬í˜„                                       |
| ----------- | ------------------------------------------ |
| ë¦¬ì†ŒìŠ¤ ì œí•œ | `CELERY_TASK_TIME_LIMIT=300`, `memory: 8G` |
| ì…ë ¥ ê²€ì¦   | Magic byte, MIME type, íŒŒì¼ í¬ê¸° ê²€ì¦      |
| ë¹„ë°€ ê´€ë¦¬   | HashiCorp Vault / AWS Secrets Manager      |

#### ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ë³´ì•ˆ

- **DoS ë°©ì–´**: Rate limiting, í ê¹Šì´ ì œí•œ
- **ë©€ì›¨ì–´ ìŠ¤ìº”**: ClamAV íŒŒì´í”„ë¼ì¸ (ì„ íƒ)
- **ì„ì‹œ íŒŒì¼**: ì²˜ë¦¬ ì™„ë£Œ í›„ ì•ˆì „ ì‚­ì œ

#### ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆ

| í†µì‹  ê²½ë¡œ           | í”„ë¡œí† ì½œ | ë³´ì•ˆ ìš”êµ¬ì‚¬í•­                      |
| ------------------- | -------- | ---------------------------------- |
| Worker â†” RabbitMQ   | AMQPS    | TLS 1.3, í´ë¼ì´ì–¸íŠ¸ ì¸ì¦ì„œ         |
| Worker â†” PostgreSQL | SSL      | `sslmode=verify-full`, ì¸ì¦ì„œ ê²€ì¦ |
| Worker â†” MinIO      | HTTPS    | Pre-signed URL ë§Œë£Œ < 15ë¶„         |

**TLS Cipher Suite ì„¤ì • (4ì°¨ ê²€í†  ì¶”ê°€)**:

> **ğŸ“Œ Security Engineer ê¶Œì¥ì‚¬í•­ ë°˜ì˜** (2025-12-08)

```yaml
# RabbitMQ TLS ì„¤ì • (rabbitmq.conf)
ssl_options.verify = verify_peer
ssl_options.fail_if_no_peer_cert = true
ssl_options.cacertfile = /certs/ca.crt
ssl_options.certfile = /certs/server.crt
ssl_options.keyfile = /certs/server.key
ssl_options.versions.1 = tlsv1.3
ssl_options.ciphers.1 = TLS_AES_256_GCM_SHA384
ssl_options.ciphers.2 = TLS_AES_128_GCM_SHA256
ssl_options.ciphers.3 = TLS_CHACHA20_POLY1305_SHA256
ssl_options.depth = 2  # ì¸ì¦ì„œ ì²´ì¸ ê²€ì¦ ê¹Šì´

# PostgreSQL TLS ì„¤ì • (postgresql.conf)
ssl = on
ssl_cert_file = '/certs/server.crt'
ssl_key_file = '/certs/server.key'
ssl_ca_file = '/certs/ca.crt'
ssl_min_protocol_version = 'TLSv1.3'
ssl_ciphers = 'TLS_AES_256_GCM_SHA384:TLS_AES_128_GCM_SHA256'

# Worker ì—°ê²° ì„¤ì • (Python)
DATABASE_URL = "postgresql://user:pass@host:5432/db?sslmode=verify-full&sslrootcert=/certs/ca.crt"
```

**TLS Downgrade ê³µê²© ë°©ì§€ ì„¤ì • (5ì°¨ ê²€í†  ì¶”ê°€)**:

> **âš ï¸ Security Engineer ê¶Œì¥ì‚¬í•­**: `ssl_min_protocol_version = 'TLSv1.3'`ë§Œìœ¼ë¡œëŠ” downgrade ê³µê²© ì™„ì „ ì°¨ë‹¨ ë¶ˆê°€

```yaml
# RabbitMQ TLS ê°•í™” ì„¤ì • (rabbitmq.conf)
ssl_options.honor_cipher_order = true      # ì„œë²„ cipher ìš°ì„ ìˆœìœ„ ê°•ì œ
ssl_options.secure_renegotiate = true      # ì•ˆì „í•œ ì¬í˜‘ìƒë§Œ í—ˆìš©
ssl_options.client_renegotiation = false   # í´ë¼ì´ì–¸íŠ¸ ì¬í˜‘ìƒ ì°¨ë‹¨ (DoS ë°©ì§€)

# PostgreSQL TLS ê°•í™” ì„¤ì • (postgresql.conf)
ssl_prefer_server_ciphers = on             # ì„œë²„ cipher ìš°ì„ ìˆœìœ„ ê°•ì œ
ssl_ecdh_curve = 'prime256v1'              # ECDH ê³¡ì„  ëª…ì‹œ
```

```python
# Python Worker TLS ê°•í™” ì„¤ì •
import ssl

def create_secure_ssl_context() -> ssl.SSLContext:
    """TLS Downgrade ë°©ì§€ê°€ ì ìš©ëœ SSL Context ìƒì„±"""
    context = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)

    # TLS 1.3 ì „ìš© (í•˜ìœ„ ë²„ì „ ì°¨ë‹¨)
    context.minimum_version = ssl.TLSVersion.TLSv1_3
    context.maximum_version = ssl.TLSVersion.TLSv1_3

    # ì¬í˜‘ìƒ ë¹„í™œì„±í™” (downgrade ê³µê²© ë°©ì§€)
    context.options |= ssl.OP_NO_RENEGOTIATION

    # ì••ì¶• ë¹„í™œì„±í™” (CRIME ê³µê²© ë°©ì§€)
    context.options |= ssl.OP_NO_COMPRESSION

    # ì¸ì¦ì„œ ê²€ì¦ í•„ìˆ˜
    context.verify_mode = ssl.CERT_REQUIRED
    context.check_hostname = True
    context.load_verify_locations('/certs/ca.crt')
    context.load_cert_chain('/certs/client.crt', '/certs/client.key')

    return context
```

**mTLS ì„¤ì • (ìƒí˜¸ ì¸ì¦)**:

```yaml
# Worker â†’ RabbitMQ í´ë¼ì´ì–¸íŠ¸ ì¸ì¦ì„œ ì„¤ì •
CELERY_BROKER_USE_SSL:
    ca_certs: /certs/ca.crt
    certfile: /certs/worker-client.crt
    keyfile: /certs/worker-client.key
    cert_reqs: ssl.CERT_REQUIRED
    ssl_version: ssl.PROTOCOL_TLS_CLIENT
```

**ì¸ì¦ì„œ ë¡œí…Œì´ì…˜ ì •ì±… (5ì°¨ ê²€í†  ê°•í™”)**:

| ì¸ì¦ì„œ ìœ í˜•     | ìœ íš¨ ê¸°ê°„ | ê°±ì‹  ì‹œì              | ê´€ë¦¬ ë°©ì‹    | ì•Œë¦¼          |
| --------------- | --------- | --------------------- | ------------ | ------------- |
| Root CA         | 10ë…„      | ìˆ˜ë™ ê°±ì‹              | Vault        | ë§Œë£Œ 1ë…„ ì „   |
| Intermediate CA | 5ë…„       | ìˆ˜ë™ ê°±ì‹              | Vault        | ë§Œë£Œ 6ê°œì›” ì „ |
| Server ì¸ì¦ì„œ   | 90ì¼      | ë§Œë£Œ **30ì¼** ì „ ìë™ | cert-manager | ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ  |
| Client ì¸ì¦ì„œ   | 90ì¼      | ë§Œë£Œ **30ì¼** ì „ ìë™ | cert-manager | ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ  |

> **5ì°¨ ê²€í†  ìˆ˜ì •**: ê°±ì‹  ì‹œì  15ì¼â†’30ì¼ (ê°±ì‹  ì‹¤íŒ¨ ì‹œ ëŒ€ì‘ ì‹œê°„ í™•ë³´)

**ì¸ì¦ì„œ ê°±ì‹  ì•Œë¦¼ ì„¤ì •**:

```yaml
# Prometheus AlertManager ê·œì¹™
- alert: CertificateExpiringIn30Days
  expr: (certmanager_certificate_expiration_timestamp_seconds - time()) / 86400 < 30
  for: 1h
  labels:
      severity: warning
  annotations:
      summary: 'Certificate {{ $labels.name }} expires in 30 days'

- alert: CertificateRenewalFailed
  expr: certmanager_certificate_ready_status == 0
  for: 15m
  labels:
      severity: critical
  annotations:
      summary: 'Certificate renewal failed for {{ $labels.name }}'
```

#### ë°ì´í„° ì•”í˜¸í™” at-rest

| ì»´í¬ë„ŒíŠ¸   | ì•”í˜¸í™” ë°©ì‹                       | í‚¤ ê´€ë¦¬                             |
| ---------- | --------------------------------- | ----------------------------------- |
| MinIO/S3   | AES-256-GCM                       | KMS ê´€ë¦¬ (ìë™ ë¡œí…Œì´ì…˜, 90ì¼ ì£¼ê¸°) |
| PostgreSQL | TDE (Transparent Data Encryption) | Vault í‚¤ ì£¼ì…                       |
| ì„ì‹œ íŒŒì¼  | /tmp tmpfs + shred ì‚­ì œ           | -                                   |

**MinIO SSE-S3 ì„¤ì •**:

```yaml
# MinIO ì„œë²„ ì„¤ì •
MINIO_KMS_KES_ENDPOINT: 'https://kes.internal:7373'
MINIO_KMS_KES_KEY_NAME: 'cad-worker-key'
MINIO_KMS_KES_CERT_FILE: '/certs/client.crt'
MINIO_KMS_KES_KEY_FILE: '/certs/client.key'
```

**ì„ì‹œ íŒŒì¼ ì•ˆì „ ì‚­ì œ**:

```python
import subprocess
import os

def secure_delete(file_path: str) -> None:
    """ì²˜ë¦¬ ì™„ë£Œ í›„ ì„ì‹œ íŒŒì¼ ì•ˆì „ ì‚­ì œ"""
    if os.path.exists(file_path):
        # 3íšŒ ë®ì–´ì“°ê¸° í›„ ì‚­ì œ
        subprocess.run(
            ['shred', '-vfz', '-n', '3', file_path],
            check=True,
            capture_output=True
        )
        os.remove(file_path)
```

#### Kubernetes NetworkPolicy

**DXF Worker Egress ì œì–´**:

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
    name: dxf-worker-network-policy
    namespace: cad-workers
spec:
    podSelector:
        matchLabels:
            app: dxf-worker
    policyTypes:
        - Ingress
        - Egress
    ingress:
        # Prometheus ìŠ¤í¬ë˜í•‘ í—ˆìš©
        - from:
              - namespaceSelector:
                    matchLabels:
                        name: monitoring
          ports:
              - protocol: TCP
                port: 9090
    egress:
        # RabbitMQ í—ˆìš©
        - to:
              - namespaceSelector:
                    matchLabels:
                        name: messaging
          ports:
              - protocol: TCP
                port: 5671
        # PostgreSQL í—ˆìš©
        - to:
              - namespaceSelector:
                    matchLabels:
                        name: database
          ports:
              - protocol: TCP
                port: 5432
        # MinIO í—ˆìš©
        - to:
              - namespaceSelector:
                    matchLabels:
                        name: storage
          ports:
              - protocol: TCP
                port: 9000
        # DNS í—ˆìš© (5ì°¨ ê²€í†  ê°•í™”: CoreDNSë§Œ í—ˆìš©)
        - to:
              - namespaceSelector:
                    matchLabels:
                        kubernetes.io/metadata.name: kube-system
                podSelector:
                    matchLabels:
                        k8s-app: kube-dns
          ports:
              - protocol: UDP
                port: 53
              - protocol: TCP
                port: 53
```

> **âš ï¸ 5ì°¨ ê²€í†  ìˆ˜ì •**: `namespaceSelector: {}` (ì „ì²´ í—ˆìš©)ì€ DNS tunneling ê³µê²©ì— ì·¨ì•½. CoreDNS Podë¡œ ì œí•œ.

**PDF Worker NetworkPolicy** (GPU Worker):

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
    name: pdf-worker-network-policy
    namespace: cad-workers
spec:
    podSelector:
        matchLabels:
            app: pdf-worker
    policyTypes:
        - Ingress
        - Egress
    ingress:
        - from:
              - namespaceSelector:
                    matchLabels:
                        name: monitoring
          ports:
              - protocol: TCP
                port: 9090
    egress:
        # RabbitMQ, PostgreSQL, MinIO, DNS (DXF Workerì™€ ë™ì¼)
        - to:
              - namespaceSelector:
                    matchLabels:
                        name: messaging
          ports:
              - protocol: TCP
                port: 5671
        - to:
              - namespaceSelector:
                    matchLabels:
                        name: database
          ports:
              - protocol: TCP
                port: 5432
        - to:
              - namespaceSelector:
                    matchLabels:
                        name: storage
          ports:
              - protocol: TCP
                port: 9000
        # DNS í—ˆìš© (5ì°¨ ê²€í†  ê°•í™”: CoreDNSë§Œ í—ˆìš©)
        - to:
              - namespaceSelector:
                    matchLabels:
                        kubernetes.io/metadata.name: kube-system
                podSelector:
                    matchLabels:
                        k8s-app: kube-dns
          ports:
              - protocol: UDP
                port: 53
              - protocol: TCP
                port: 53
        # ì™¸ë¶€ ì¸í„°ë„· ì°¨ë‹¨ (ML ëª¨ë¸ ë‹¤ìš´ë¡œë“œëŠ” ë¹Œë“œ ì‹œì ì— ì™„ë£Œ)
```

**ë„¤íŠ¸ì›Œí¬ ì •ì±… ê²€ì¦**:

```bash
# NetworkPolicy ì ìš© í™•ì¸
kubectl get networkpolicy -n cad-workers

# ì—°ê²° í…ŒìŠ¤íŠ¸ (í—ˆìš©ëœ ì„œë¹„ìŠ¤)
kubectl exec -n cad-workers dxf-worker-xxx -- nc -zv rabbitmq.messaging 5671

# ì—°ê²° í…ŒìŠ¤íŠ¸ (ì°¨ë‹¨ëœ ì™¸ë¶€ ì ‘ê·¼)
kubectl exec -n cad-workers dxf-worker-xxx -- nc -zv google.com 443
# Expected: connection refused
```

**ëŸ°íƒ€ì„ ë³´ì•ˆ**:

```yaml
# docker-compose.yml
security_opt:
    - no-new-privileges:true
cap_drop:
    - ALL
read_only: true
tmpfs:
    - /tmp:size=2G # ìµœëŒ€ íŒŒì¼ 500MB Ã— 2 + ë²„í¼
```

#### ëŸ°íƒ€ì„ ë³´ì•ˆ ê°•í™” (Kubernetes)

**seccomp í”„ë¡œíŒŒì¼ (5ì°¨ ê²€í†  ë³´ê°•)**:

> **âš ï¸ Security Engineer ê¶Œì¥ì‚¬í•­**: asyncio, multiprocessingì— í•„ìš”í•œ syscall ì¶”ê°€

```yaml
# seccomp/cad-worker-profile.json
{
    'defaultAction': 'SCMP_ACT_ERRNO',
    'architectures': ['SCMP_ARCH_X86_64'],
    'syscalls': [{ 'names': [
                        # ê¸°ë³¸ íŒŒì¼ I/O
                        'read',
                        'write',
                        'open',
                        'close',
                        'stat',
                        'fstat',
                        'openat',
                        'newfstatat',
                        'lstat',
                        'readlink',
                        'unlink',

                        # ë©”ëª¨ë¦¬ ê´€ë¦¬
                        'mmap',

                        'mprotect',
                        'munmap',
                        'brk',
                        'mremap',
                        # ì‹œê·¸ë„ ì²˜ë¦¬
                        'rt_sigaction',

                        'rt_sigprocmask',
                        'rt_sigreturn',
                        # ê¸°ë³¸ ì‹œìŠ¤í…œ ì½œ
                        'ioctl',
                        'access',
                        'pipe',
                        'pipe2',
                        'select',
                        'sched_yield',
                        'fcntl',
                        'dup',
                        'dup2',

                        # í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬ (Celery prefork)
                        'clone',
                        'clone3',
                        'execve',
                        'exit',
                        'exit_group',
                        'wait4',
                        'set_robust_list',
                        'set_tid_address',
                        'prctl',
                        'arch_prctl',

                        # ë™ì‹œì„± (asyncio, multiprocessing)
                        'futex',
                        'epoll_create',
                        'epoll_create1',
                        'epoll_ctl',
                        'epoll_wait',
                        'epoll_pwait',
                        'eventfd',
                        'eventfd2',

                        # ë„¤íŠ¸ì›Œí¬
                        'socket',
                        'connect',
                        'sendto',
                        'recvfrom',
                        'send',
                        'recv',
                        'bind',
                        'listen',
                        'accept',
                        'accept4',
                        'getsockname',
                        'getpeername',
                        'setsockopt',
                        'getsockopt',
                        'shutdown',

                        # í”„ë¡œì„¸ìŠ¤ ì •ë³´
                        'getpid',
                        'gettid',
                        'getuid',
                        'getgid',
                        'geteuid',
                        'getegid',
                        'getppid',
                        'getpgrp',
                        'setsid',

                        # ì‹œê°„/ëœë¤
                        'clock_gettime',

                        'gettimeofday',
                        'nanosleep',
                        'getrandom',
                        # íŒŒì¼ ë””ìŠ¤í¬ë¦½í„° ê´€ë¦¬
                        'poll',
                        'ppoll',
                        'pselect6',
                    ], 'action': 'SCMP_ACT_ALLOW' }],
}
```

**syscall ì¶”ê°€ ì‚¬ìœ **:

| ì¶”ê°€ëœ syscall                | ìš©ë„                 | ì‚¬ìš©ì²˜                          |
| ----------------------------- | -------------------- | ------------------------------- |
| `epoll_pwait`, `eventfd2`     | ë¹„ë™ê¸° ì´ë²¤íŠ¸ ëŒ€ê¸°   | asyncio ì´ë²¤íŠ¸ ë£¨í”„             |
| `clone3`, `set_robust_list`   | í”„ë¡œì„¸ìŠ¤/ìŠ¤ë ˆë“œ ìƒì„± | Celery prefork, multiprocessing |
| `rt_sigreturn`                | ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë³µê·€   | Graceful shutdown               |
| `fcntl`, `readlink`, `unlink` | íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¡°ì‘ | ì„ì‹œ íŒŒì¼ ê´€ë¦¬                  |
| `pipe2`, `dup`, `dup2`        | íŒŒì¼ ë””ìŠ¤í¬ë¦½í„° ë³µì œ | ì„œë¸Œí”„ë¡œì„¸ìŠ¤ í†µì‹                |

**Pod Security Context ì ìš©**:

```yaml
spec:
    securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
        seccompProfile:
            type: Localhost
            localhostProfile: profiles/cad-worker-profile.json
    containers:
        - name: worker
          securityContext:
              allowPrivilegeEscalation: false
              readOnlyRootFilesystem: true
              capabilities:
                  drop:
                      - ALL
```

#### ì¹¨í•´ íƒì§€ (Falco)

**CAD Worker ì „ìš© Falco ê·œì¹™**:

```yaml
# falco-rules/cad-worker-rules.yaml
- rule: CAD Worker Unexpected Network Connection
  desc: CAD Workerê°€ í—ˆìš©ë˜ì§€ ì•Šì€ ì™¸ë¶€ ì—°ê²° ì‹œë„
  condition: >
      container.name startswith "cad-worker" and
      evt.type in (connect, sendto) and
      not (
        fd.sip in (rabbitmq_ips) or
        fd.sip in (postgres_ips) or
        fd.sip in (minio_ips) or
        fd.sport = 53
      )
  output: >
      Unexpected network connection from CAD Worker
      (container=%container.name connection=%fd.name user=%user.name)
  priority: WARNING
  tags: [network, cad-worker]

- rule: CAD Worker Suspicious Process
  desc: CAD Worker ì»¨í…Œì´ë„ˆì—ì„œ ë¹„ì •ìƒ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
  condition: >
      container.name startswith "cad-worker" and
      spawned_process and
      not proc.name in (python, python3, celery, sh)
  output: >
      Suspicious process in CAD Worker
      (container=%container.name process=%proc.name cmdline=%proc.cmdline)
  priority: CRITICAL
  tags: [process, cad-worker]

- rule: CAD Worker File Write Outside Temp
  desc: CAD Workerê°€ /tmp ì™¸ë¶€ì— íŒŒì¼ ì“°ê¸° ì‹œë„
  condition: >
      container.name startswith "cad-worker" and
      evt.type in (open, openat) and
      evt.is_open_write = true and
      not fd.name startswith "/tmp"
  output: >
      File write outside /tmp in CAD Worker
      (container=%container.name file=%fd.name)
  priority: WARNING
  tags: [file, cad-worker]
```

**Falco ì•Œë¦¼ ì—°ë™**:

```yaml
# falco-config.yaml
program_output:
    enabled: true
    keep_alive: false
    program: |
        jq '{
          text: "Falco Alert: \(.output)",
          channel: "#security-alerts"
        }' | curl -X POST -H 'Content-type: application/json' \
        --data @- https://hooks.slack.com/services/xxx

json_output: true
json_include_output_property: true
```

#### ë¹„ë°€ ê´€ë¦¬ ì •ì±…

> **ìƒì„¸ êµ¬í˜„**: ì„¹ì…˜ 5.8.6 Secret ìë™ ë¡œí…Œì´ì…˜ ì°¸ì¡°

**ë¹„ë°€ ìœ í˜•ë³„ ë¡œí…Œì´ì…˜ ì£¼ê¸°** (ê¸°ë³¸ ì •ì±…):

| ë¹„ë°€ ìœ í˜•         | ë¡œí…Œì´ì…˜ ì£¼ê¸°       | ì €ì¥ì†Œ                | ì ‘ê·¼ ë°©ì‹   |
| ----------------- | ------------------- | --------------------- | ----------- |
| DB Credentials    | 90ì¼ (ë˜ëŠ” Dynamic) | Vault/Secrets Manager | íŒŒì¼ ì£¼ì…   |
| API Keys          | 30ì¼                | Vault/Secrets Manager | í™˜ê²½ ë³€ìˆ˜   |
| TLS ì¸ì¦ì„œ        | 365ì¼ (ìë™ ê°±ì‹ )   | cert-manager          | ë³¼ë¥¨ ë§ˆìš´íŠ¸ |
| RabbitMQ Password | 90ì¼                | Vault/Secrets Manager | í™˜ê²½ ë³€ìˆ˜   |

> â„¹ï¸ External Secrets Operator ì„¤ì •, Vault Dynamic Secrets, ì ‘ê·¼ ê¶Œí•œ ë§¤íŠ¸ë¦­ìŠ¤, ê°ì‚¬ ë¡œê¹… ìƒì„¸ëŠ” **ì„¹ì…˜ 5.8.6** ì°¸ì¡°

#### ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨ ì²˜ë¦¬

**ê²€ì¦ íŒŒì´í”„ë¼ì¸**:

```
íŒŒì¼ ìˆ˜ì‹  â†’ Magic Byte ê²€ì¦ â†’ MIME Type ê²€ì¦ â†’ íŒŒì¼ í¬ê¸° ê²€ì¦ â†’ ì²˜ë¦¬
              â†“ ì‹¤íŒ¨           â†“ ì‹¤íŒ¨           â†“ ì‹¤íŒ¨
           ê²©ë¦¬ í ì´ë™     ê²©ë¦¬ í ì´ë™     ê²©ë¦¬ í ì´ë™
```

**ê²€ì¦ ê·œì¹™** (íƒ€ì…ë³„ ì œí•œ):

> ì„¹ì…˜ 3ì˜ "ìµœëŒ€ 500MB"ëŠ” ì‹œìŠ¤í…œ ì „ì²´ ìµœëŒ€ê°’ì´ë©°, ì•„ë˜ëŠ” íŒŒì¼ íƒ€ì…ë³„ ì œí•œì…ë‹ˆë‹¤.

| ê²€ì¦ í•­ëª©   | DXF íŒŒì¼                  | PDF íŒŒì¼                 | ì‹¤íŒ¨ ì‹œ   |
| ----------- | ------------------------- | ------------------------ | --------- |
| Magic Byte  | DXF í—¤ë” ê²€ì¦ (ì•„ë˜ ì°¸ì¡°) | `%PDF-` (5ë°”ì´íŠ¸)        | ì¦‰ì‹œ ê±°ë¶€ |
| MIME Type   | `python-magic` ê¸°ë°˜ ê²€ì¦  | `python-magic` ê¸°ë°˜ ê²€ì¦ | ì¦‰ì‹œ ê±°ë¶€ |
| íŒŒì¼ í¬ê¸°   | â‰¤ 100MB                   | â‰¤ 500MB                  | ì¦‰ì‹œ ê±°ë¶€ |
| íŒŒì¼ í™•ì¥ì | `.dxf` (í•„ìˆ˜ ì¼ì¹˜)        | `.pdf` (í•„ìˆ˜ ì¼ì¹˜)       | ì¦‰ì‹œ ê±°ë¶€ |

**ì…ë ¥ ê²€ì¦ ê°•í™” (4ì°¨ ê²€í†  ì¶”ê°€)**:

> **ğŸ“Œ Security Engineer ê¶Œì¥ì‚¬í•­ ë°˜ì˜** (2025-12-08)

**DXF Magic Byte ì—„ê²© ê²€ì¦**:

```python
# validators/dxf_validator.py
import magic  # python-magic ë¼ì´ë¸ŒëŸ¬ë¦¬

# DXF íŒŒì¼ ìœ íš¨ì„± ê²€ì¦ íŒ¨í„´
DXF_ASCII_HEADER = b'  0\r\nSECTION'      # ASCII DXF (9ë°”ì´íŠ¸)
DXF_BINARY_HEADER = b'AutoCAD Binary DXF'  # Binary DXF (18ë°”ì´íŠ¸)


def validate_dxf_magic_byte(file_path: str) -> bool:
    """DXF íŒŒì¼ Magic Byte ì—„ê²© ê²€ì¦

    ê¸°ì¡´ `0 0 (ASCII)` ê²€ì¦ì€ ë„ˆë¬´ ê´‘ë²”ìœ„í•˜ì—¬ ìš°íšŒ ê°€ëŠ¥.
    DXF íŒŒì¼ í˜•ì‹ì— ë§ëŠ” ì‹¤ì œ í—¤ë”ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.
    """
    with open(file_path, 'rb') as f:
        header = f.read(22)

        # Binary DXF ê²€ì¦
        if header[:18] == DXF_BINARY_HEADER:
            return True

        # ASCII DXF ê²€ì¦ (ë‹¤ì–‘í•œ ì¤„ë°”ê¿ˆ ì²˜ë¦¬)
        # ê³µë°±ìœ¼ë¡œ ì‹œì‘í•˜ê³  "0\nSECTION" ë˜ëŠ” "0\r\nSECTION" í¬í•¨
        header_str = header.decode('ascii', errors='ignore')
        if header_str.strip().startswith('0') and 'SECTION' in header_str:
            return True

    return False


def validate_mime_type(file_path: str, expected_type: str) -> bool:
    """python-magic ê¸°ë°˜ MIME Type ê²€ì¦ (í´ë¼ì´ì–¸íŠ¸ í—¤ë” ë¬´ì‹œ)

    í´ë¼ì´ì–¸íŠ¸ê°€ ì œê³µí•œ Content-Type í—¤ë”ëŠ” ì¡°ì‘ ê°€ëŠ¥í•˜ë¯€ë¡œ
    ì‹¤ì œ íŒŒì¼ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ MIME Typeì„ ê²€ì¦í•©ë‹ˆë‹¤.
    """
    mime = magic.Magic(mime=True)
    detected_type = mime.from_file(file_path)

    # DXFëŠ” text/plain ë˜ëŠ” application/octet-streamìœ¼ë¡œ íƒì§€ë  ìˆ˜ ìˆìŒ
    if expected_type == 'dxf':
        return detected_type in ['text/plain', 'application/octet-stream', 'application/dxf']

    # PDFëŠ” ëª…í™•í•˜ê²Œ application/pdf
    if expected_type == 'pdf':
        return detected_type == 'application/pdf'

    return False


def validate_file_extension(file_path: str, expected_ext: str) -> bool:
    """íŒŒì¼ í™•ì¥ì í•„ìˆ˜ ì¼ì¹˜ ê²€ì¦ (ê²½ê³  â†’ ê±°ë¶€ë¡œ ë³€ê²½)"""
    import os
    _, ext = os.path.splitext(file_path)
    return ext.lower() == expected_ext.lower()
```

**Polyglot íŒŒì¼ ë°©ì–´ (5ì°¨ ê²€í†  í™•ì¥)**:

```python
def detect_polyglot_attack(file_path: str) -> bool:
    """Polyglot íŒŒì¼ ê³µê²© íƒì§€

    DXF + PHP, DXF + HTML ë“± ì—¬ëŸ¬ í˜•ì‹ìœ¼ë¡œ í•´ì„ë  ìˆ˜ ìˆëŠ”
    ì•…ì˜ì  íŒŒì¼ì„ íƒì§€í•©ë‹ˆë‹¤.
    """
    dangerous_patterns = [
        # ìŠ¤í¬ë¦½íŠ¸ ì‚½ì…
        b'<?php',           # PHP ì½”ë“œ
        b'<script',         # JavaScript
        b'<html',           # HTML
        b'#!/',             # Shebang

        # ì••ì¶•/ì•„ì¹´ì´ë¸Œ
        b'PK\x03\x04',      # ZIP/JAR
        b'\x1f\x8b\x08',    # GZIP

        # XML bombs (5ì°¨ ê²€í†  ì¶”ê°€)
        b'<!DOCTYPE',       # DOCTYPE ì •ì˜ (XXE ê°€ëŠ¥)
        b'<!ENTITY',        # ì—”í‹°í‹° ì •ì˜ (Billion Laughs)

        # PDF ìœ„í˜‘ (5ì°¨ ê²€í†  ì¶”ê°€)
        b'/JS',             # PDF JavaScript
        b'/JavaScript',     # PDF JavaScript (ëª…ì‹œì )
        b'/Launch',         # PDF ì™¸ë¶€ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰

        # DXF ìœ„í˜‘ (5ì°¨ ê²€í†  ì¶”ê°€)
        b'XRECORD',         # AutoCAD í™•ì¥ ë ˆì½”ë“œ (ì•…ì„± ë°ì´í„°)
        b'ACAD_REACTORS',   # AutoCAD ë¦¬ì•¡í„° (ìë™ ì‹¤í–‰ íŠ¸ë¦¬ê±°)

        # ì‹¤í–‰ íŒŒì¼ (5ì°¨ ê²€í†  ì¶”ê°€)
        b'MZ\x90\x00',      # Windows PE (ì‹¤í–‰ íŒŒì¼)
        b'\x7fELF',         # Linux ELF (ì‹¤í–‰ íŒŒì¼)
    ]

    with open(file_path, 'rb') as f:
        content = f.read(8192)  # ì²˜ìŒ 8KB ê²€ì‚¬ (í™•ì¥)
        for pattern in dangerous_patterns:
            if pattern in content:
                return True
    return False
```

**ZIP Bomb ë°©ì–´ (5ì°¨ ê²€í†  ì¶”ê°€)**:

> **âš ï¸ Security Engineer ê¶Œì¥ì‚¬í•­**: DXF Binary í˜•ì‹ì€ ë‚´ë¶€ì ìœ¼ë¡œ ZIP êµ¬ì¡° ì‚¬ìš© ê°€ëŠ¥

```python
import zipfile
import os
from typing import Tuple

def detect_compression_bomb(file_path: str, max_ratio: int = 100) -> Tuple[bool, str]:
    """ì••ì¶• í­íƒ„(ZIP Bomb) íƒì§€

    ì••ì¶• í•´ì œ í›„ í¬ê¸°ê°€ ì••ì¶• í¬ê¸°ì˜ max_ratio ë°°ë¥¼ ì´ˆê³¼í•˜ë©´ íƒì§€.

    Args:
        file_path: ê²€ì‚¬í•  íŒŒì¼ ê²½ë¡œ
        max_ratio: ìµœëŒ€ í—ˆìš© ì••ì¶•ë¥  (ê¸°ë³¸ 100ë°°)

    Returns:
        (is_bomb, reason): íƒì§€ ì—¬ë¶€ì™€ ì‚¬ìœ 
    """
    if not zipfile.is_zipfile(file_path):
        return False, "Not a ZIP file"

    try:
        with zipfile.ZipFile(file_path, 'r') as zf:
            compressed_size = 0
            uncompressed_size = 0

            for info in zf.infolist():
                compressed_size += info.compress_size
                uncompressed_size += info.file_size

                # ê°œë³„ íŒŒì¼ í¬ê¸° ì œí•œ (500MB)
                if info.file_size > 500 * 1024 * 1024:
                    return True, f"Individual file too large: {info.filename}"

            # ì••ì¶•ë¥  ê²€ì¦
            if compressed_size > 0:
                ratio = uncompressed_size / compressed_size
                if ratio > max_ratio:
                    return True, f"Compression ratio {ratio:.1f}x exceeds limit {max_ratio}x"

            # ì´ ì••ì¶• í•´ì œ í¬ê¸° ì œí•œ (1GB)
            if uncompressed_size > 1 * 1024 * 1024 * 1024:
                return True, f"Total uncompressed size exceeds 1GB: {uncompressed_size}"

    except zipfile.BadZipFile:
        # ì†ìƒëœ ZIP â†’ ê±°ë¶€
        return True, "Corrupted ZIP structure"

    return False, "OK"


def validate_binary_dxf(file_path: str) -> bool:
    """Binary DXF íŒŒì¼ì˜ ì••ì¶• í­íƒ„ ê²€ì‚¬

    Binary DXFëŠ” ë‚´ë¶€ì ìœ¼ë¡œ ZIP êµ¬ì¡°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ
    ì••ì¶• í•´ì œ ì „ ê²€ì¦ í•„ìˆ˜.
    """
    is_bomb, reason = detect_compression_bomb(file_path)
    if is_bomb:
        raise ValidationError(f"Potential compression bomb: {reason}")

    return True
```

**í†µí•© ê²€ì¦ í”Œë¡œìš° (5ì°¨ ê²€í†  ê°•í™”)**:

```python
def validate_input_file(file_path: str, file_type: str) -> None:
    """í†µí•© ì…ë ¥ ê²€ì¦ (5ì°¨ ê²€í†  ê°•í™” ë²„ì „)"""

    # 1. íŒŒì¼ í™•ì¥ì ê²€ì¦ (í•„ìˆ˜ ì¼ì¹˜)
    if not validate_file_extension(file_path, f'.{file_type}'):
        raise ValidationError(f"Extension must be .{file_type}")

    # 2. Magic Byte ê²€ì¦
    if file_type == 'dxf' and not validate_dxf_magic_byte(file_path):
        raise ValidationError("Invalid DXF file header")
    elif file_type == 'pdf':
        with open(file_path, 'rb') as f:
            if not f.read(5) == b'%PDF-':
                raise ValidationError("Invalid PDF file header")

    # 3. MIME Type ê²€ì¦ (python-magic ê¸°ë°˜)
    if not validate_mime_type(file_path, file_type):
        raise ValidationError(f"MIME type mismatch for {file_type}")

    # 4. Polyglot ê³µê²© íƒì§€
    if detect_polyglot_attack(file_path):
        raise ValidationError("Potential polyglot file attack detected")

    # 5. ZIP Bomb íƒì§€ (5ì°¨ ê²€í†  ì¶”ê°€)
    if file_type == 'dxf':
        validate_binary_dxf(file_path)

    # 6. íŒŒì¼ í¬ê¸° ê²€ì¦
    max_sizes = {'dxf': 100 * 1024 * 1024, 'pdf': 500 * 1024 * 1024}
    if os.path.getsize(file_path) > max_sizes.get(file_type, 0):
        raise ValidationError(f"File too large for {file_type}")
```

**ì‹¤íŒ¨ ì²˜ë¦¬ í”Œë¡œìš°**:

```python
# tasks/validation.py
from celery.exceptions import Reject

class ValidationError(Exception):
    """Non-retryable validation error"""
    pass

@celery.task(bind=True)
def validate_and_process(self, file_path: str):
    try:
        # 1. Magic byte ê²€ì¦
        if not validate_magic_byte(file_path):
            raise ValidationError("Invalid magic byte")

        # 2. MIME type ê²€ì¦
        if not validate_mime_type(file_path):
            raise ValidationError("Invalid MIME type")

        # 3. íŒŒì¼ í¬ê¸° ê²€ì¦
        if not validate_file_size(file_path):
            raise ValidationError("File too large")

        # 4. ì •ìƒ ì²˜ë¦¬
        return process_file(file_path)

    except ValidationError as e:
        # Non-retryable: DLQë¡œ ì§ì ‘ ì´ë™
        logger.error(f"Validation failed: {e}", extra={
            "task_id": self.request.id,
            "file_path": file_path,
            "error_type": "validation"
        })
        raise Reject(str(e), requeue=False)
```

**ì•Œë¦¼ ì •ì±…**:

| ì¡°ê±´                    | ì•Œë¦¼ ì±„ë„         | ê¸´ê¸‰ë„ |
| ----------------------- | ----------------- | ------ |
| ë‹¨ì¼ ê²€ì¦ ì‹¤íŒ¨          | ë¡œê·¸ë§Œ            | ë‚®ìŒ   |
| ë™ì¼ IP 3íšŒ ì—°ì† ì‹¤íŒ¨   | Slack             | ì¤‘ê°„   |
| 1ì‹œê°„ ë‚´ 10íšŒ ì´ìƒ ì‹¤íŒ¨ | Slack + PagerDuty | ë†’ìŒ   |

**DLQ ìë™ ì •ë¦¬ ì •ì±…**:

- 24ì‹œê°„ í›„ ìë™ ì‚­ì œ (validation ì‹¤íŒ¨)
- 7ì¼ í›„ ìë™ ì‚­ì œ (ì²˜ë¦¬ ì‹¤íŒ¨)
- ê´€ë¦¬ì í™•ì¸ í›„ ìˆ˜ë™ ì¬ì²˜ë¦¬ ë˜ëŠ” ì‚­ì œ

#### 5.8.6 Secret ìë™ ë¡œí…Œì´ì…˜ (8ì°¨ ê²€í†  ì¶”ê°€)

> **Security Engineer ê¶Œì¥ì‚¬í•­**: ì¥ê¸° credential ë…¸ì¶œ ìœ„í—˜ ë°©ì§€ë¥¼ ìœ„í•œ ìë™ ë¡œí…Œì´ì…˜ í•„ìˆ˜

**External Secrets Operator ì„¤ì •**:

```yaml
# external-secret.yaml
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata:
    name: worker-db-credentials
    namespace: cad-worker
spec:
    refreshInterval: 1h # 1ì‹œê°„ë§ˆë‹¤ ë™ê¸°í™”
    secretStoreRef:
        name: vault-backend
        kind: ClusterSecretStore
    target:
        name: worker-db-secret
        creationPolicy: Owner
        template:
            engineVersion: v2
            data:
                POSTGRES_USER: '{{ .username }}'
                POSTGRES_PASSWORD: '{{ .password }}'
                POSTGRES_HOST: '{{ .host }}'
    data:
        - secretKey: username
          remoteRef:
              key: secret/data/postgres/worker
              property: username
        - secretKey: password
          remoteRef:
              key: secret/data/postgres/worker
              property: password
        - secretKey: host
          remoteRef:
              key: secret/data/postgres/worker
              property: host
```

**Vault Dynamic Secrets (í”„ë¡œë•ì…˜ ê¶Œì¥)**:

```hcl
# Vault Database Secrets Engine ì„¤ì •
resource "vault_database_secret_backend_role" "worker_db" {
  backend             = vault_mount.postgres.path
  name                = "worker-role"
  db_name             = vault_database_secret_backend_connection.postgres.name
  creation_statements = [
    "CREATE ROLE \"{{name}}\" WITH LOGIN PASSWORD '{{password}}' VALID UNTIL '{{expiration}}';",
    "GRANT SELECT, INSERT, UPDATE ON ALL TABLES IN SCHEMA public TO \"{{name}}\";",
  ]
  revocation_statements = [
    "DROP ROLE IF EXISTS \"{{name}}\";"
  ]
  default_ttl = 3600   # 1ì‹œê°„
  max_ttl     = 86400  # 24ì‹œê°„
}
```

**ë¡œí…Œì´ì…˜ ì •ì±…**:

| ì‹œí¬ë¦¿ ìœ í˜•       | ë¡œí…Œì´ì…˜ ì£¼ê¸°   | ë°©ë²•                    | ë¹„ê³                     |
| ----------------- | --------------- | ----------------------- | ----------------------- |
| DB ë¹„ë°€ë²ˆí˜¸       | 1ì‹œê°„ (Dynamic) | Vault Dynamic Secrets   | TTL ë§Œë£Œ ì‹œ ìë™ ì¬ë°œê¸‰ |
| RabbitMQ ë¹„ë°€ë²ˆí˜¸ | 30ì¼            | External Secrets + ìˆ˜ë™ | ì—°ê²° í’€ ì¬ì‹œì‘ í•„ìš”     |
| MinIO Access Key  | 90ì¼            | External Secrets + ìˆ˜ë™ | ë°°í¬ íŒŒì´í”„ë¼ì¸ì— í†µí•©  |
| API í‚¤ (ë‚´ë¶€)     | 7ì¼             | Vault Dynamic Secrets   | ì„œë¹„ìŠ¤ ê°„ í†µì‹           |

**Worker Pod ìë™ ì¬ì‹œì‘ ì„¤ì •**:

```yaml
# deployment.yaml - ì‹œí¬ë¦¿ ë³€ê²½ ì‹œ ìë™ ì¬ì‹œì‘
apiVersion: apps/v1
kind: Deployment
metadata:
    name: dxf-worker
    annotations:
        reloader.stakater.com/auto: 'true' # Reloader ì—°ë™
spec:
    template:
        metadata:
            annotations:
                # ì‹œí¬ë¦¿ í•´ì‹œ ê¸°ë°˜ ë¡¤ë§ ì—…ë°ì´íŠ¸ (ëŒ€ì•ˆ)
                checksum/secret: '{{ include (print $.Template.BasePath "/secret.yaml") . | sha256sum }}'
```

**ì ‘ê·¼ ê¶Œí•œ ë§¤íŠ¸ë¦­ìŠ¤**:

| Worker     | DB             | RabbitMQ      | MinIO         | Vault   |
| ---------- | -------------- | ------------- | ------------- | ------- |
| DXF Worker | âœ… task_status | âœ… dxf_queue  | âœ… read/write | âœ… read |
| PDF Worker | âœ… task_status | âœ… pdf_queue  | âœ… read/write | âœ… read |
| Flower     | âŒ             | âœ… all (read) | âŒ            | âŒ      |

**ê°ì‚¬ ë¡œê¹…**:

```yaml
# Vault audit log ì„¤ì •
vault audit enable file file_path=/var/log/vault_audit.log

# ë¡œê·¸ í¬ë§· (SIEM ì—°ë™)
{
  "time": "2025-12-08T10:00:00Z",
  "type": "response",
  "auth": {"accessor": "worker-dxf-001"},
  "request": {"path": "secret/data/db-credentials"},
  "response": {"data": {"keys": ["username", "password"]}}
}
```

**ì¥ì•  ëŒ€ì‘**:

| ìƒí™©                      | ìë™ ë³µêµ¬                   | ìˆ˜ë™ ì¡°ì¹˜              |
| ------------------------- | --------------------------- | ---------------------- |
| Vault ì—°ê²° ì‹¤íŒ¨           | ìºì‹œëœ ì‹œí¬ë¦¿ ì‚¬ìš© (TTL ë‚´) | Vault í´ëŸ¬ìŠ¤í„° ë³µêµ¬    |
| ì‹œí¬ë¦¿ ë§Œë£Œ               | ì‹ ê·œ ë°œê¸‰ ìë™ ì‹œë„         | DB ìˆ˜ë™ ë¹„ë°€ë²ˆí˜¸ ë¦¬ì…‹  |
| ë¡œí…Œì´ì…˜ ì¤‘ Worker í¬ë˜ì‹œ | Kubernetes ìë™ ì¬ì‹œì‘      | ë¡œê·¸ í™•ì¸ í›„ ì›ì¸ ë¶„ì„ |

---

### 5.9 ë°°í¬ ì „ëµ

#### Workerë³„ ë°°í¬ ë°©ì‹

| Worker     | ì „ëµ           | ê·¼ê±°                         |
| ---------- | -------------- | ---------------------------- |
| DXF Worker | Rolling Update | Stateless, ë¹ ë¥¸ ì¬ì‹œì‘       |
| PDF Worker | Blue/Green     | GPU ë¦¬ì†ŒìŠ¤ ë¹„ìš©, ë‹¨ê³„ì  ì „í™˜ |

#### Rolling Update ì„¤ì • (DXF)

```yaml
strategy:
    type: RollingUpdate
    rollingUpdate:
        maxSurge: 1
        maxUnavailable: 0
```

#### Blue/Green ì„¤ì • (PDF - 5ì°¨ ê²€í†  ìƒì„¸í™”)

> **âš ï¸ DevOps Architect ê¶Œì¥ì‚¬í•­**: GPU ë…¸ë“œ ê²½í•© ë°©ì§€ë¥¼ ìœ„í•œ ì‚¬ì „ í™•ë³´ ì ˆì°¨ í•„ìš”

**GPU ë…¸ë“œ ê²½í•© ë¬¸ì œ**:

- ë™ì‹œ 2ê°œ Deployment (Blue + Green)ê°€ GPU ë…¸ë“œ í• ë‹¹ ê²½í•© ì‹œ Green ë²„ì „ Pending ê°€ëŠ¥
- í•´ê²°ì±…: PriorityClass ê¸°ë°˜ ìš°ì„ ìˆœìœ„ + ì‚¬ì „ ë…¸ë“œ í™•ë³´

```yaml
# 1. PriorityClass ì„¤ì •
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
    name: gpu-worker-high
value: 1000000
globalDefault: false
description: 'GPU Worker Blue/Green ë°°í¬ìš© ë†’ì€ ìš°ì„ ìˆœìœ„'
---
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
    name: gpu-worker-low
value: 100000
globalDefault: false
description: 'GPU Worker ê¸°ì¡´ ë²„ì „ (Green ë°°í¬ ì‹œ ì¤‘ë‹¨ë¨)'
```

**Blue/Green ë°°í¬ ì ˆì°¨**:

```yaml
# ìƒˆ ë²„ì „ ë°°í¬ â†’ íŠ¸ë˜í”½ ì „í™˜ â†’ êµ¬ë²„ì „ ì œê±°
steps:
  1. [ì‚¬ì „ ê²€ì¦] GPU ë…¸ë“œ ê°€ìš©ì„± í™•ì¸
     kubectl get nodes -l accelerator=nvidia-t4 -o jsonpath='{.items[*].status.allocatable.nvidia\.com/gpu}'

  2. [Blue ìš°ì„ ìˆœìœ„ í•˜í–¥] ê¸°ì¡´ ë²„ì „ ìš°ì„ ìˆœìœ„ ë³€ê²½
     kubectl patch deployment pdf-worker-blue -p '{"spec":{"template":{"spec":{"priorityClassName":"gpu-worker-low"}}}}'

  3. [Green ë°°í¬] ë†’ì€ ìš°ì„ ìˆœìœ„ë¡œ ì‹ ê·œ ë²„ì „ ë°°í¬
     kubectl apply -f pdf-worker-green.yaml  # priorityClassName: gpu-worker-high

  4. [Health Check] Green ë²„ì „ ì¤€ë¹„ ì™„ë£Œ í™•ì¸
     kubectl wait --for=condition=available deployment/pdf-worker-green --timeout=300s
     celery -A worker inspect ping -d celery@pdf-worker-green-xxx

  5. [íŠ¸ë˜í”½ ì „í™˜] Service selector ì—…ë°ì´íŠ¸
     kubectl patch service pdf-worker -p '{"spec":{"selector":{"version":"green"}}}'

  6. [Blue ì œê±°] 5ë¶„ ëŒ€ê¸° í›„ êµ¬ë²„ì „ ì‚­ì œ
     sleep 300 && kubectl delete deployment pdf-worker-blue
```

**GPU ë…¸ë“œ ë¶€ì¡± ì‹œ ëŒ€ì‘**:

| ìƒí™©                     | ëŒ€ì‘ ë°©ì•ˆ                 | ìë™í™” |
| ------------------------ | ------------------------- | ------ |
| Green Pending (GPU ë¶€ì¡±) | Blue 1 Podì”© ìˆœì°¨ ì¢…ë£Œ    | ìˆ˜ë™   |
| GPU ë…¸ë“œ ì¶”ê°€ ê°€ëŠ¥       | Cluster Autoscaler íŠ¸ë¦¬ê±° | ìë™   |
| ê¸´ê¸‰ ë¡¤ë°± í•„ìš”           | Blue PriorityClass ë³µì›   | ìˆ˜ë™   |

```bash
# GPU ë¶€ì¡± ì‹œ Blue ìˆœì°¨ ì¢…ë£Œ ìŠ¤í¬ë¦½íŠ¸
#!/bin/bash
BLUE_PODS=$(kubectl get pods -l app=pdf-worker,version=blue -o name | head -1)
kubectl delete $BLUE_PODS --grace-period=300
sleep 60  # Green ìŠ¤ì¼€ì¤„ë§ ëŒ€ê¸°
kubectl wait --for=condition=available deployment/pdf-worker-green --timeout=120s
```

#### ë¡¤ë°± ì ˆì°¨

1. `kubectl rollout undo deployment/dxf-worker`
2. Flowerì—ì„œ ì‘ì—… ìƒíƒœ í™•ì¸
3. í ì ì²´ ì‹œ Worker ìˆ˜ë™ ìŠ¤ì¼€ì¼ì—…

#### HPA (Horizontal Pod Autoscaler) ì„¤ì •

**DXF Worker HPA**:

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
    name: dxf-worker-hpa
spec:
    scaleTargetRef:
        apiVersion: apps/v1
        kind: Deployment
        name: dxf-worker
    minReplicas: 3 # 5ì°¨ ê²€í† : 2â†’3 (ê°€ìš©ì„± ê°•í™”)
    maxReplicas: 10
    metrics:
        # CPU ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
        - type: Resource
          resource:
              name: cpu
              target:
                  type: Utilization
                  averageUtilization: 70
        # í ê¹Šì´ ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§ (External Metrics)
        - type: External
          external:
              metric:
                  name: celery_queue_length
                  selector:
                      matchLabels:
                          queue: dxf_queue
              target:
                  type: AverageValue
                  averageValue: '5' # Workerë‹¹ ìµœëŒ€ 5ê°œ Task
    behavior:
        scaleDown:
            stabilizationWindowSeconds: 120 # 5ì°¨ ê²€í† : 300â†’120ì´ˆ (DXF ë¹ ë¥¸ ì²˜ë¦¬)
            policies:
                - type: Percent
                  value: 50
                  periodSeconds: 60
        scaleUp:
            stabilizationWindowSeconds: 0 # ì¦‰ì‹œ ìŠ¤ì¼€ì¼ì—…
            policies:
                - type: Pods
                  value: 2
                  periodSeconds: 60
```

**PDF Worker HPA** (GPU ê³ ë ¤):

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
    name: pdf-worker-hpa
spec:
    scaleTargetRef:
        apiVersion: apps/v1
        kind: Deployment
        name: pdf-worker
    minReplicas: 2 # 5ì°¨ ê²€í† : 1â†’2 (ê°€ìš©ì„± ê°•í™”)
    maxReplicas: 5
    metrics:
        - type: Resource
          resource:
              name: cpu
              target:
                  type: Utilization
                  averageUtilization: 60
    behavior:
        scaleDown:
            stabilizationWindowSeconds: 600 # 10ë¶„ ìœ ì§€ (GPU ë¹„ìš© ê³ ë ¤)
```

> **5ì°¨ ê²€í†  HPA ì¡°ì • ìš”ì•½**:
>
> - DXF Worker: `minReplicas` 2â†’3, `stabilizationWindowSeconds` 300â†’120ì´ˆ
> - PDF Worker: `minReplicas` 1â†’2, `stabilizationWindowSeconds` 600ì´ˆ ìœ ì§€

**ë¦¬ì†ŒìŠ¤ Requests/Limits**:

```yaml
# DXF Worker
resources:
  requests:
    cpu: 3000m      # 75% of 4 vCPU
    memory: 6Gi     # 75% of 8GB
  limits:
    cpu: 4000m
    memory: 8Gi

# PDF Worker
resources:
  requests:
    cpu: 3000m
    memory: 12Gi
    nvidia.com/gpu: 1
  limits:
    cpu: 4000m
    memory: 16Gi
    nvidia.com/gpu: 1
```

#### Image Tag ë¶ˆë³€ì„± ì •ì±… (8ì°¨ ê²€í†  ë³´ì™„)

> âš ï¸ **CRITICAL**: `:latest` íƒœê·¸ëŠ” í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ **ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€**

**Image Tag ê·œì¹™**:
| í™˜ê²½ | íƒœê·¸ í˜•ì‹ | ì˜ˆì‹œ |
|------|----------|------|
| Development | `dev-<branch>-<sha7>` | `dev-feature-abc1234` |
| Staging | `stg-<sha7>` | `stg-abc1234` |
| Production | `v<semver>-<sha7>` | `v1.2.3-abc1234` |

**ê¸ˆì§€ íŒ¨í„´**:

```yaml
# âŒ ê¸ˆì§€: ì¬í˜„ ë¶ˆê°€, ë¡¤ë°± ë¶ˆê°€
image: ghcr.io/cad-platform/dxf-worker:latest

# âœ… ì˜¬ë°”ë¥¸ ì‚¬ìš©: ë¶ˆë³€ íƒœê·¸
image: ghcr.io/cad-platform/dxf-worker:v1.2.3-abc1234
```

**CI/CD ê²€ì¦ ë‹¨ê³„**:

```yaml
# .github/workflows/image-tag-validation.yml
- name: Validate Image Tag
  run: |
      if [[ "${{ env.IMAGE_TAG }}" == "latest" ]] || \
         [[ "${{ env.IMAGE_TAG }}" =~ ^[0-9]+\.[0-9]+\.[0-9]+$ ]]; then
        echo "âŒ ERROR: Mutable tag detected. Use SHA-based immutable tags."
        exit 1
      fi
      echo "âœ… Image tag validation passed: ${{ env.IMAGE_TAG }}"
```

#### ìë™ ë¡¤ë°± ë©”ì»¤ë‹ˆì¦˜ (8ì°¨ ê²€í†  ë³´ì™„)

**Deployment ë¡¤ë°± ì„¤ì •**:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
    name: dxf-worker
spec:
    replicas: 3
    progressDeadlineSeconds: 300 # 5ë¶„ ë‚´ ë°°í¬ ì™„ë£Œ í•„ìš”
    minReadySeconds: 30 # 30ì´ˆê°„ Ready ìœ ì§€ í™•ì¸
    revisionHistoryLimit: 5 # ë¡¤ë°± ê°€ëŠ¥ ë¦¬ë¹„ì „ 5ê°œ
    strategy:
        type: RollingUpdate
        rollingUpdate:
            maxSurge: 1
            maxUnavailable: 0
    template:
        spec:
            containers:
                - name: dxf-worker
                  livenessProbe:
                      httpGet:
                          path: /health/live
                          port: 8080
                      initialDelaySeconds: 10
                      periodSeconds: 10
                      failureThreshold: 3
                  readinessProbe:
                      httpGet:
                          path: /health/ready
                          port: 8080
                      initialDelaySeconds: 5
                      periodSeconds: 5
                      failureThreshold: 3
```

**ArgoCD ìë™ ë³µêµ¬ ì„¤ì •**: ìƒì„¸ ì •ì˜ëŠ” [ì„¹ì…˜ 5.12 GitOps ì›Œí¬í”Œë¡œìš°](#512-gitops-ì›Œí¬í”Œë¡œìš°) ì°¸ì¡°

> ğŸ“Œ **ì°¸ì¡°**: ArgoCD Application ì •ì˜ëŠ” ë‹¨ì¼ ìœ„ì¹˜(5.12ì ˆ)ì—ì„œ ê´€ë¦¬í•˜ì—¬ ì„¤ì • ë¶ˆì¼ì¹˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.

> âš ï¸ **ArgoCD ë¡¤ë°± ë°©ë²•**: ArgoCDëŠ” ìë™ ë¡¤ë°±ì„ ì§€ì›í•˜ì§€ ì•ŠìŒ. ìˆ˜ë™ ë¡¤ë°± ì‹œ `argocd app rollback dxf-worker <revision>` ë˜ëŠ” ArgoCD UIì—ì„œ History â†’ Rollback ì‚¬ìš©

**ë¡¤ë°± íŠ¸ë¦¬ê±° ì¡°ê±´**:
| ì¡°ê±´ | ì„ê³„ê°’ | ìë™ ì¡°ì¹˜ |
|------|--------|----------|
| Deployment Timeout | > 300ì´ˆ (progressDeadlineSeconds) | K8s ìë™ ë¡¤ë°± |
| Pod Ready ì‹¤íŒ¨ | minReadySeconds ë‚´ Unhealthy | K8s ìë™ ë¡¤ë°± |
| Health Check ì‹¤íŒ¨ | 3íšŒ ì—°ì† (failureThreshold) | Pod ì¬ì‹œì‘ |
| ArgoCD Degraded | Health ìƒíƒœ ê°ì§€ | selfHealë¡œ ì¬ë™ê¸°í™” (ë¡¤ë°±ì€ ìˆ˜ë™) |

---

### 5.10 CI/CD íŒŒì´í”„ë¼ì¸

#### GitHub Actions ì›Œí¬í”Œë¡œìš°

```yaml
# .github/workflows/cad-worker-ci.yml
name: CAD Worker CI/CD

on:
    push:
        branches: [main, develop]
        paths:
            - 'cad-worker/**'
    pull_request:
        branches: [main]

env:
    REGISTRY: ghcr.io
    IMAGE_NAME: ${{ github.repository }}/cad-worker

jobs:
    test:
        runs-on: ubuntu-latest
        steps:
            - uses: actions/checkout@v4

            - name: Set up Python
              uses: actions/setup-python@v5
              with:
                  python-version: '3.12'

            - name: Install uv
              run: curl -LsSf https://astral.sh/uv/install.sh | sh

            - name: Install dependencies
              run: |
                  uv venv
                  uv pip install -r requirements.txt
                  uv pip install pytest pytest-cov pytest-celery mypy ruff bandit safety

            - name: Lint with Ruff
              run: ruff check --exit-zero=false .

            - name: Type check with mypy
              run: mypy --strict src/

            - name: Security scan with Bandit (SAST)
              run: |
                  bandit -r src/ -ll -i -f json -o bandit-report.json || true
                  bandit -r src/ -ll -i
              continue-on-error: false

            - name: Dependency vulnerability scan with Safety
              run: safety check --bare --output json > safety-report.json || safety check --bare

            - name: Run tests
              run: pytest --cov=src --cov-fail-under=80 --cov-report=xml

            - name: Upload coverage
              uses: codecov/codecov-action@v3

            - name: Upload security reports
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: security-reports
                  path: |
                      bandit-report.json
                      safety-report.json

    build:
        needs: test
        runs-on: ubuntu-latest
        permissions:
            contents: read
            packages: write
        steps:
            - uses: actions/checkout@v4

            - name: Set up Docker Buildx
              uses: docker/setup-buildx-action@v3

            - name: Login to Container Registry
              uses: docker/login-action@v3
              with:
                  registry: ${{ env.REGISTRY }}
                  username: ${{ github.actor }}
                  password: ${{ secrets.GITHUB_TOKEN }}

            - name: Get short SHA
              id: vars
              run: echo "sha_short=$(git rev-parse --short HEAD)" >> $GITHUB_OUTPUT

            - name: Extract metadata
              id: meta
              uses: docker/metadata-action@v5
              with:
                  images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
                  tags: |
                      # dev/staging: {branch}-{sha7} í˜•ì‹
                      type=sha,prefix={{branch}}-,format=short
                      # production: v{semver}-{sha7} í˜•ì‹ (ë¦´ë¦¬ì¦ˆ íƒœê·¸ ì‹œ)
                      type=raw,value=v${{ github.ref_name }}-${{ steps.vars.outputs.sha_short }},enable=${{ startsWith(github.ref, 'refs/tags/v') }}
                      # staging ì „ìš©
                      type=raw,value=stg-${{ steps.vars.outputs.sha_short }},enable=${{ github.ref == 'refs/heads/staging' }}

            # 9ì°¨ ê²€í†  ë°˜ì˜: Build â†’ Export â†’ Load â†’ Scan â†’ Push (ë™ì¼ ì´ë¯¸ì§€ ë³´ì¥)
            # âš ï¸ ì´ì „ ë°©ì‹(ì´ì¤‘ ë¹Œë“œ)ì€ ìŠ¤ìº”ëœ ì´ë¯¸ì§€ â‰  í‘¸ì‹œëœ ì´ë¯¸ì§€ ë¬¸ì œ ìˆìŒ

            # 1ë‹¨ê³„: Build & Export tarball (ì¬ë¹Œë“œ ë°©ì§€ìš© ì•„í‹°íŒ©íŠ¸ ìƒì„±)
            - name: Build and export image
              uses: docker/build-push-action@v5
              with:
                  context: ./cad-worker
                  push: false
                  load: false
                  outputs: type=docker,dest=/tmp/image.tar
                  tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
                  cache-from: type=gha
                  cache-to: type=gha,mode=max

            # 2ë‹¨ê³„: Load tarball to Docker (ìŠ¤ìº” ë° í‘¸ì‹œìš©)
            - name: Load image for scanning
              run: docker load -i /tmp/image.tar

            # 3ë‹¨ê³„: Scan loaded image (tarballì—ì„œ ë¡œë“œí•œ ë™ì¼ ì´ë¯¸ì§€)
            - name: Scan with Trivy
              uses: aquasecurity/trivy-action@master
              with:
                  image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
                  exit-code: '1'
                  severity: 'HIGH,CRITICAL'
                  # ìŠ¤ìº” ì‹¤íŒ¨ ì‹œ ë¹Œë“œ ì¤‘ë‹¨ â†’ í‘¸ì‹œ ë‹¨ê³„ ë„ë‹¬ ë¶ˆê°€

            # 4ë‹¨ê³„: Push same image (ì¬ë¹Œë“œ ì—†ì´ ë™ì¼ ì´ë¯¸ì§€ í‘¸ì‹œ)
            - name: Push scanned image
              run: docker push ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}

            # 5ë‹¨ê³„: Tag and push additional tags
            - name: Tag and push additional tags
              run: |
                  for tag in ${{ steps.meta.outputs.tags }}; do
                    docker tag ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }} $tag
                    docker push $tag
                  done

    # GitOps ë°©ì‹: ì´ë¯¸ì§€ íƒœê·¸ë§Œ Gitì— ì—…ë°ì´íŠ¸, ArgoCDê°€ ìë™ ë°°í¬
    # ìƒì„¸ ë°°í¬ ì ˆì°¨ëŠ” ì„¹ì…˜ 5.12 GitOps ì›Œí¬í”Œë¡œìš° ì°¸ì¡°
    update-manifest:
        needs: build
        runs-on: ubuntu-latest
        if: github.ref == 'refs/heads/main'
        steps:
            - name: Checkout infra repo
              uses: actions/checkout@v4
              with:
                  repository: your-org/cad-platform-infra
                  token: ${{ secrets.INFRA_REPO_TOKEN }}
                  path: infra

            - name: Update image tag
              run: |
                  cd infra/kubernetes/overlays/production
                  kustomize edit set image cad-worker=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}

            - name: Commit and push
              run: |
                  cd infra
                  git config user.name "github-actions[bot]"
                  git config user.email "github-actions[bot]@users.noreply.github.com"
                  git add .
                  git commit -m "chore: update cad-worker image to ${{ github.sha }}"
                  git push
                  # ArgoCDê°€ Git ë³€ê²½ ê°ì§€ í›„ ìë™ ë°°í¬ (ì„¹ì…˜ 5.12 ì°¸ì¡°)
```

#### ì´ë¯¸ì§€ íƒœê¹… ì „ëµ (8ì°¨ ê²€í†  ë³´ì™„)

> âš ï¸ **`:latest` íƒœê·¸ ì‚¬ìš© ê¸ˆì§€** - ì¬í˜„ì„± ë° ë¡¤ë°± ë³´ì¥ì„ ìœ„í•´ ë¶ˆë³€ íƒœê·¸ë§Œ ì‚¬ìš©

| íƒœê·¸ í˜•ì‹               | ì˜ˆì‹œ             | ìš©ë„               | í™˜ê²½           |
| ----------------------- | ---------------- | ------------------ | -------------- |
| `{branch}-{short-sha}`  | `main-a1b2c3d`   | ê°œë°œ/í…ŒìŠ¤íŠ¸ ë¹Œë“œ   | dev, staging   |
| `v{semver}-{short-sha}` | `v1.2.3-a1b2c3d` | ë¦´ë¦¬ì¦ˆ ë²„ì „ (ë¶ˆë³€) | **production** |
| `stg-{short-sha}`       | `stg-a1b2c3d`    | ìŠ¤í…Œì´ì§• ê²€ì¦      | staging        |
| ~~`latest`~~            | ~~`latest`~~     | ~~ì‚¬ìš© ê¸ˆì§€~~      | **ê¸ˆì§€**       |

#### í™˜ê²½ë³„ ë°°í¬ ì „ëµ

```
develop â†’ staging (ìë™)
    â†“
main â†’ production (ìˆ˜ë™ ìŠ¹ì¸)
    â†“
tag â†’ release (ìë™)
```

#### í’ˆì§ˆ ê²Œì´íŠ¸

| ë‹¨ê³„     | ì²´í¬ í•­ëª©                        | ì‹¤íŒ¨ ì‹œ            |
| -------- | -------------------------------- | ------------------ |
| Lint     | `ruff check --exit-zero=false`   | ë¹Œë“œ ì¤‘ë‹¨          |
| Type     | `mypy --strict`                  | ë¹Œë“œ ì¤‘ë‹¨          |
| Test     | `pytest --cov-fail-under=80`     | ë¹Œë“œ ì¤‘ë‹¨          |
| Scan     | `trivy --severity HIGH,CRITICAL` | ë¹Œë“œ ì¤‘ë‹¨          |
| Manifest | `kustomize edit set image`       | Git ì—…ë°ì´íŠ¸ ì‹¤íŒ¨  |
| Deploy   | ArgoCD ìë™ ë™ê¸°í™” (5.12 ì°¸ì¡°)   | selfHeal ìë™ ë³µêµ¬ |

#### í…ŒìŠ¤íŠ¸ ì „ëµ

**pytest-celery í†µí•© í…ŒìŠ¤íŠ¸:**

```python
# tests/conftest.py
import pytest
from celery.contrib.testing.app import TestApp
from celery.contrib.testing.worker import start_worker

@pytest.fixture(scope="session")
def celery_app():
    """Celery í…ŒìŠ¤íŠ¸ ì•± ì„¤ì •"""
    app = TestApp(
        broker="memory://",
        backend="cache+memory://",
        include=["cad_worker.tasks"]
    )
    app.conf.update(
        task_always_eager=False,
        task_eager_propagates=True,
    )
    return app

@pytest.fixture(scope="session")
def celery_worker(celery_app):
    """í…ŒìŠ¤íŠ¸ìš© Worker ì‹œì‘"""
    with start_worker(celery_app, pool="solo", loglevel="info") as worker:
        yield worker

# tests/test_dxf_task.py
def test_dxf_processing_success(celery_app, celery_worker, sample_dxf):
    """DXF ë³€í™˜ íƒœìŠ¤í¬ ì„±ê³µ ì¼€ì´ìŠ¤"""
    from cad_worker.tasks import process_dxf

    result = process_dxf.delay(
        file_url=sample_dxf,
        output_format="gltf"
    )

    # 5ì´ˆ SLA ê²€ì¦
    assert result.get(timeout=5) is not None
    assert result.status == "SUCCESS"
```

**í˜„ì‹¤ì ì¸ í…ŒìŠ¤íŠ¸ í”½ìŠ¤ì²˜ ìƒì„± (5ì°¨ ê²€í†  ì¶”ê°€)**:

> **âš ï¸ Quality Engineer ê¶Œì¥ì‚¬í•­**: `b"mock dxf content"` ìˆ˜ì¤€ì˜ Mockì€ ì‹¤ì œ íŒŒì„œ ê²€ì¦ ë¶ˆê°€

```python
# tests/conftest.py - í˜„ì‹¤ì  DXF/PDF í”½ìŠ¤ì²˜
import pytest
import ezdxf
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from io import BytesIO
import tempfile
import os

@pytest.fixture
def sample_dxf_bytes():
    """ìµœì†Œ ìœ íš¨ DXF íŒŒì¼ ìƒì„± (ì‹¤ì œ íŒŒì„œ í…ŒìŠ¤íŠ¸ìš©)"""
    doc = ezdxf.new("R2018")  # AutoCAD 2018 í˜•ì‹
    msp = doc.modelspace()

    # ê¸°ë³¸ ë„í˜• ì¶”ê°€
    msp.add_line((0, 0), (100, 0))      # ê°€ë¡œì„ 
    msp.add_line((100, 0), (100, 50))   # ì„¸ë¡œì„ 
    msp.add_circle((50, 25), 10)        # ì›

    # ë ˆì´ì–´ ì¶”ê°€
    doc.layers.add("WALLS", color=1)    # ë¹¨ê°„ìƒ‰ ë ˆì´ì–´
    doc.layers.add("DOORS", color=3)    # ë…¹ìƒ‰ ë ˆì´ì–´

    # BytesIOë¡œ ë°˜í™˜
    stream = BytesIO()
    doc.write(stream)
    stream.seek(0)
    return stream.read()


@pytest.fixture
def sample_pdf_bytes():
    """ìµœì†Œ ìœ íš¨ PDF íŒŒì¼ ìƒì„± (ì‹¤ì œ íŒŒì„œ í…ŒìŠ¤íŠ¸ìš©)"""
    stream = BytesIO()
    c = canvas.Canvas(stream, pagesize=A4)

    # ê¸°ë³¸ ë„í˜• ë° í…ìŠ¤íŠ¸ ì¶”ê°€
    c.drawString(100, 750, "CAD Worker Test PDF")
    c.rect(50, 600, 200, 100)  # ì‚¬ê°í˜•
    c.circle(300, 650, 30)      # ì›

    c.save()
    stream.seek(0)
    return stream.read()


@pytest.fixture
def sample_dxf_file(sample_dxf_bytes, tmp_path):
    """ì„ì‹œ DXF íŒŒì¼ ìƒì„±"""
    file_path = tmp_path / "test_sample.dxf"
    file_path.write_bytes(sample_dxf_bytes)
    return str(file_path)


@pytest.fixture
def sample_pdf_file(sample_pdf_bytes, tmp_path):
    """ì„ì‹œ PDF íŒŒì¼ ìƒì„±"""
    file_path = tmp_path / "test_sample.pdf"
    file_path.write_bytes(sample_pdf_bytes)
    return str(file_path)


@pytest.fixture
def complex_dxf_bytes():
    """ë³µì¡í•œ DXF (ë ˆì´ì–´, ë¸”ë¡, ìŠ¤íƒ€ì¼ í¬í•¨)"""
    doc = ezdxf.new("R2018")
    msp = doc.modelspace()

    # ë‹¤ì¤‘ ë ˆì´ì–´
    for i, name in enumerate(["WALLS", "DOORS", "WINDOWS", "FURNITURE"]):
        doc.layers.add(name, color=i + 1)

    # ë¸”ë¡ ì •ì˜
    block = doc.blocks.new(name="DOOR")
    block.add_line((0, 0), (10, 0))
    block.add_arc((5, 0), 5, 0, 90)

    # ë¸”ë¡ ì°¸ì¡°
    msp.add_blockref("DOOR", (50, 50))
    msp.add_blockref("DOOR", (100, 50), dxfattribs={"rotation": 90})

    # ë‹¤ì–‘í•œ ì—”í‹°í‹°
    msp.add_lwpolyline([(0, 0), (100, 0), (100, 100), (0, 100)], close=True)
    msp.add_text("Room 101", dxfattribs={"height": 5, "layer": "FURNITURE"})

    stream = BytesIO()
    doc.write(stream)
    stream.seek(0)
    return stream.read()
```

**ì™¸ë¶€ ì„œë¹„ìŠ¤ Mock ì „ëµ:**

```python
# tests/conftest.py - Mock Fixtures
import pytest
from unittest.mock import MagicMock, patch
from io import BytesIO

@pytest.fixture
def mock_minio_client(sample_dxf_bytes):
    """MinIO/S3 í´ë¼ì´ì–¸íŠ¸ Mock (í˜„ì‹¤ì  ë°ì´í„° ì‚¬ìš©)"""
    with patch("boto3.client") as mock_s3:
        # get_object Mock - í˜„ì‹¤ì  DXF ë°ì´í„° ë°˜í™˜
        mock_s3.return_value.get_object.return_value = {
            "Body": BytesIO(sample_dxf_bytes),
            "ContentLength": len(sample_dxf_bytes)
        }
        # put_object Mock
        mock_s3.return_value.put_object.return_value = {
            "ETag": '"abc123"',
            "VersionId": "v1"
        }
        # generate_presigned_url Mock
        mock_s3.return_value.generate_presigned_url.return_value = (
            "https://minio.internal/bucket/key?signature=..."
        )
        yield mock_s3

@pytest.fixture
def mock_db_session():
    """PostgreSQL ì„¸ì…˜ Mock"""
    with patch("sqlalchemy.orm.Session") as mock_session:
        # Query mock
        mock_query = MagicMock()
        mock_session.return_value.query.return_value = mock_query
        mock_query.filter.return_value.first.return_value = None

        # Commit/Rollback mock
        mock_session.return_value.commit.return_value = None
        mock_session.return_value.rollback.return_value = None
        yield mock_session

@pytest.fixture
def mock_rabbitmq_connection():
    """RabbitMQ ì—°ê²° Mock (Celery ë¸Œë¡œì»¤ ëŒ€ì²´)"""
    with patch("kombu.Connection") as mock_conn:
        mock_channel = MagicMock()
        mock_conn.return_value.__enter__.return_value.channel.return_value = mock_channel
        yield mock_conn

# tests/test_dxf_task_unit.py
def test_dxf_parsing_with_mock(mock_minio_client, mock_db_session, sample_dxf_bytes):
    """ë‹¨ìœ„ í…ŒìŠ¤íŠ¸: ì™¸ë¶€ ì˜ì¡´ì„± Mock"""
    from cad_worker.services.dxf_parser import parse_dxf

    result = parse_dxf(sample_dxf_bytes)

    assert result is not None
    assert "entities" in result
    mock_minio_client.return_value.get_object.assert_called_once()

def test_task_status_update_with_mock(mock_db_session):
    """ë‹¨ìœ„ í…ŒìŠ¤íŠ¸: DB ìƒíƒœ ì—…ë°ì´íŠ¸ Mock"""
    from cad_worker.services.status import update_task_status

    update_task_status("task-123", "SUCCESS")

    mock_db_session.return_value.commit.assert_called_once()
```

**Mock vs ì‹¤ì œ ì„œë¹„ìŠ¤ ì‚¬ìš© ê¸°ì¤€:**

| í…ŒìŠ¤íŠ¸ ìœ í˜• | MinIO          | PostgreSQL     | RabbitMQ       | ì´ìœ                      |
| ----------- | -------------- | -------------- | -------------- | ------------------------ |
| ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ | Mock           | Mock           | Mock           | ë¹ ë¥¸ ì‹¤í–‰, ê²©ë¦¬ëœ í…ŒìŠ¤íŠ¸ |
| í†µí•© í…ŒìŠ¤íŠ¸ | Mock           | Mock           | In-memory      | Celery í†µí•© ê²€ì¦         |
| E2E í…ŒìŠ¤íŠ¸  | Testcontainers | Testcontainers | Testcontainers | ì‹¤ì œ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜     |
| ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ | ì‹¤ì œ           | ì‹¤ì œ           | ì‹¤ì œ           | ì •í™•í•œ ì„±ëŠ¥ ì¸¡ì •         |

**ì»¤ë²„ë¦¬ì§€ ìš”êµ¬ì‚¬í•­:**

| ì˜ì—­          | ìµœì†Œ ì»¤ë²„ë¦¬ì§€ | ëª©í‘œ ì»¤ë²„ë¦¬ì§€ |
| ------------- | ------------- | ------------- |
| ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ | 85%           | 95%           |
| Task í•¸ë“¤ëŸ¬   | 80%           | 90%           |
| ìœ í‹¸ë¦¬í‹°      | 70%           | 80%           |
| **ì „ì²´**      | **80%**       | **85%**       |

**í…ŒìŠ¤íŠ¸ ë¶„ë¥˜:**

| ìœ í˜•        | ë„êµ¬                    | ì‹¤í–‰ ì‹œì  | ì†Œìš” ì‹œê°„ |
| ----------- | ----------------------- | --------- | --------- |
| ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ | pytest                  | ì»¤ë°‹ë§ˆë‹¤  | < 30ì´ˆ    |
| í†µí•© í…ŒìŠ¤íŠ¸ | pytest-celery           | PRë§ˆë‹¤    | < 2ë¶„     |
| E2E í…ŒìŠ¤íŠ¸  | pytest + docker-compose | ë°°í¬ ì „   | < 5ë¶„     |
| ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ | locust                  | ì£¼ 1íšŒ    | ~10ë¶„     |

#### E2E í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì²´í¬ë¦¬ìŠ¤íŠ¸ (8ì°¨ ê²€í†  ë³´ì™„)

> **Quality Engineer ê¶Œì¥ì‚¬í•­**: ë°°í¬ ì „ ì•„ë˜ ì‹œë‚˜ë¦¬ì˜¤ ëª¨ë‘ í†µê³¼ í•„ìˆ˜

**í•µì‹¬ E2E ì‹œë‚˜ë¦¬ì˜¤:**

| #      | ì‹œë‚˜ë¦¬ì˜¤                                | ê²€ì¦ í•­ëª©                                           | ì˜ˆìƒ ì†Œìš” | ìƒíƒœ |
| ------ | --------------------------------------- | --------------------------------------------------- | --------- | ---- |
| E2E-01 | **DXF íŒŒì¼ ì—…ë¡œë“œ â†’ ì²˜ë¦¬ â†’ ê²°ê³¼ ì¡°íšŒ**  | ì—…ë¡œë“œ API â†’ Worker ì²˜ë¦¬ â†’ ê²°ê³¼ URL ë°˜í™˜            | ~3ì´ˆ      | â³   |
| E2E-02 | **PDF ë³€í™˜ ìš”ì²­ â†’ GPU ì²˜ë¦¬ â†’ ë‹¤ìš´ë¡œë“œ** | ë³€í™˜ API â†’ PDF Worker â†’ MinIO ì €ì¥ â†’ Pre-signed URL | ~15ì´ˆ     | â³   |
| E2E-03 | **ì¤‘ë³µ ìš”ì²­ ë©±ë“±ì„± ê²€ì¦**               | ë™ì¼ nonce 2íšŒ ìš”ì²­ â†’ 409 Conflict ì‘ë‹µ             | ~1ì´ˆ      | â³   |
| E2E-04 | **Worker ì¥ì•  ì‹œ ì¬ì‹œë„**               | Worker ê°•ì œ ì¢…ë£Œ â†’ ìë™ ì¬ì‹œë„ â†’ ì„±ê³µ               | ~30ì´ˆ     | â³   |
| E2E-05 | **DLQ ì´ë™ ë° ì¬ì²˜ë¦¬**                  | ì˜êµ¬ ì‹¤íŒ¨ â†’ DLQ ì´ë™ â†’ ìˆ˜ë™ ì¬ì²˜ë¦¬ API              | ~45ì´ˆ     | â³   |
| E2E-06 | **Graceful Shutdown**                   | SIGTERM â†’ ì§„í–‰ ì¤‘ ì‘ì—… ì™„ë£Œ â†’ ì¢…ë£Œ                  | ~60ì´ˆ     | â³   |
| E2E-07 | **Rate Limiting ë™ì‘**                  | 100 req/min ì´ˆê³¼ â†’ 429 ì‘ë‹µ                         | ~5ì´ˆ      | â³   |
| E2E-08 | **ì¸ì¦ í† í° ë§Œë£Œ ì²˜ë¦¬**                 | ë§Œë£Œ í† í° â†’ 401 â†’ ê°±ì‹  â†’ ì¬ìš”ì²­ ì„±ê³µ                | ~3ì´ˆ      | â³   |

**E2E í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í™˜ê²½:**

```yaml
# docker-compose.e2e.yml
version: '3.8'
services:
    e2e-test:
        build:
            context: .
            dockerfile: Dockerfile.test
        depends_on:
            postgres:
                condition: service_healthy
            rabbitmq:
                condition: service_healthy
            minio:
                condition: service_started
            dxf-worker:
                condition: service_started
        environment:
            - TEST_ENV=e2e
            - POSTGRES_URL=postgresql://test:test@postgres:5432/test
            - RABBITMQ_URL=amqp://test:test@rabbitmq:5672/
            - MINIO_ENDPOINT=minio:9000
        command: pytest tests/e2e/ -v --tb=short --timeout=120

    postgres:
        image: postgres:15-alpine
        healthcheck:
            test: ['CMD-SHELL', 'pg_isready -U test']
            interval: 5s
            timeout: 5s
            retries: 5

    rabbitmq:
        image: rabbitmq:3-management-alpine
        healthcheck:
            test: ['CMD', 'rabbitmq-diagnostics', 'check_running']
            interval: 5s
            timeout: 5s
            retries: 5

    minio:
        image: minio/minio:RELEASE.2024-01-01T00-00-00Z
        command: server /data

    dxf-worker:
        build: .
        command: celery -A cad_worker worker -Q dxf -c 2
```

**CI í†µí•© (ë°°í¬ ê²Œì´íŠ¸):**

```yaml
# .github/workflows/e2e-gate.yml
e2e-tests:
    runs-on: ubuntu-latest
    needs: [build, unit-tests]
    steps:
        - name: Start E2E environment
          run: docker-compose -f docker-compose.e2e.yml up -d

        - name: Wait for services
          run: |
              for i in {1..30}; do
                docker-compose -f docker-compose.e2e.yml exec -T e2e-test curl -s http://localhost:8080/health && break
                sleep 2
              done

        - name: Run E2E tests
          run: docker-compose -f docker-compose.e2e.yml run e2e-test

        - name: E2E Gate Check
          if: failure()
          run: |
              echo "âŒ E2E tests failed - blocking deployment"
              exit 1
```

#### ì¬ì‹œë„/DLQ í…ŒìŠ¤íŠ¸ ìš”êµ¬ì‚¬í•­

> **í•„ìˆ˜ í…ŒìŠ¤íŠ¸**: Task ì¬ì‹œë„ ë° DLQ ì´ë™ ì‹œë‚˜ë¦¬ì˜¤ëŠ” ë°˜ë“œì‹œ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ì— í¬í•¨

**DLQ ê´€ë ¨ í•„ìˆ˜ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤:**

```python
# tests/test_retry_dlq.py
import pytest
from unittest.mock import patch, MagicMock
from celery.exceptions import MaxRetriesExceededError

class TestRetryAndDLQ:
    """ì¬ì‹œë„ ë° DLQ ì´ë™ í…ŒìŠ¤íŠ¸"""

    def test_task_retries_on_transient_error(self, celery_app, celery_worker):
        """ì¼ì‹œì  ì˜¤ë¥˜ ì‹œ ì¬ì‹œë„ ë™ì‘ ê²€ì¦"""
        from cad_worker.tasks import process_dxf

        with patch("cad_worker.services.dxf_parser.parse_dxf") as mock_parse:
            # ì²« 2ë²ˆ ì‹¤íŒ¨, 3ë²ˆì§¸ ì„±ê³µ
            mock_parse.side_effect = [
                ConnectionError("DB ì¼ì‹œ ì˜¤ë¥˜"),
                ConnectionError("DB ì¼ì‹œ ì˜¤ë¥˜"),
                {"entities": [], "result_url": "http://..."}
            ]

            result = process_dxf.delay("task-123", "http://file.dxf")
            assert result.get(timeout=30) is not None
            assert mock_parse.call_count == 3

    def test_task_moved_to_dlq_after_max_retries(self, celery_app, celery_worker):
        """ìµœëŒ€ ì¬ì‹œë„ í›„ DLQ ì´ë™ ê²€ì¦"""
        from cad_worker.tasks import process_dxf

        with patch("cad_worker.services.dxf_parser.parse_dxf") as mock_parse:
            mock_parse.side_effect = ValueError("ì˜êµ¬ì  íŒŒì‹± ì˜¤ë¥˜")

            result = process_dxf.delay("task-456", "http://invalid.dxf")

            with pytest.raises(MaxRetriesExceededError):
                result.get(timeout=60)

            # DLQ ì´ë™ í™•ì¸ (RabbitMQ ê¸°ì¤€)
            # assert_task_in_dlq("task-456")

    def test_dlq_message_contains_error_context(self, celery_app):
        """DLQ ë©”ì‹œì§€ì— ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ í¬í•¨ ê²€ì¦ (5ì°¨ ê²€í†  ì™„ì„±)"""
        import requests
        from datetime import datetime

        # RabbitMQ Management APIë¥¼ í†µí•œ DLQ ë©”ì‹œì§€ ì¡°íšŒ
        rabbitmq_api = "http://rabbitmq:15672/api"
        auth = ("guest", "guest")

        # DLQ íì—ì„œ ë©”ì‹œì§€ ì¡°íšŒ (peek, acknowledge ì—†ì´)
        response = requests.post(
            f"{rabbitmq_api}/queues/%2F/dxf_dlq/get",
            json={"count": 1, "ackmode": "ack_requeue_false", "encoding": "auto"},
            auth=auth
        )

        assert response.status_code == 200
        messages = response.json()

        if messages:
            msg = messages[0]
            payload = msg.get("payload", {})

            # í•„ìˆ˜ ì»¨í…ìŠ¤íŠ¸ í•„ë“œ ê²€ì¦
            expected_fields = ["task_id", "error_message", "retry_count", "original_args"]
            for field in expected_fields:
                assert field in payload, f"Missing field: {field}"

            # ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ ìƒì„¸ ê²€ì¦
            assert len(payload["error_message"]) > 0, "Error message is empty"
            assert isinstance(payload["retry_count"], int), "retry_count must be int"
            assert payload["retry_count"] >= 0, "retry_count must be non-negative"

            # íƒ€ì„ìŠ¤íƒ¬í”„ ê²€ì¦
            if "failed_at" in payload:
                failed_at = datetime.fromisoformat(payload["failed_at"])
                assert failed_at < datetime.utcnow(), "failed_at is in the future"

    def test_dlq_reprocessing_succeeds_after_fix(self, celery_app, celery_worker):
        """DLQ ì¬ì²˜ë¦¬ ì„±ê³µ ì‹œë‚˜ë¦¬ì˜¤ (5ì°¨ ê²€í†  ì™„ì„±)"""
        from cad_worker.tasks import process_dxf, scan_and_reprocess_dlq
        from unittest.mock import patch

        # 1. ì˜ë„ì ìœ¼ë¡œ ì‹¤íŒ¨ì‹œì¼œ DLQ ì´ë™
        with patch("cad_worker.services.dxf_parser.parse_dxf") as mock_parse:
            mock_parse.side_effect = ConnectionError("DB ì¼ì‹œ ì˜¤ë¥˜")

            result = process_dxf.delay("task-reprocess-test", "http://test.dxf")

            # ìµœëŒ€ ì¬ì‹œë„ í›„ ì‹¤íŒ¨ ì˜ˆìƒ
            with pytest.raises(Exception):
                result.get(timeout=120)

        # 2. DLQ ì´ë™ í™•ì¸
        dlq_messages = get_dlq_messages("dxf_dlq")
        assert any(m.task_id == "task-reprocess-test" for m in dlq_messages)

        # 3. ì›ì¸ ìˆ˜ì • (mock ë³€ê²½ - ì„±ê³µ ë°˜í™˜)
        with patch("cad_worker.services.dxf_parser.parse_dxf") as mock_parse:
            mock_parse.return_value = {"entities": [], "result_url": "http://ok.gltf"}

            # 4. scan_and_reprocess_dlq ì‹¤í–‰
            scan_and_reprocess_dlq.delay()

            # ì¬ì²˜ë¦¬ ì™„ë£Œ ëŒ€ê¸°
            import time
            time.sleep(30)

            # 5. ì¬ì²˜ë¦¬ ì„±ê³µ í™•ì¸
            task_status = get_task_status("task-reprocess-test")
            assert task_status.status == "SUCCESS"
```

**ì¬ì‹œë„ ê´€ë ¨ í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸:**

| ì‹œë‚˜ë¦¬ì˜¤         | í…ŒìŠ¤íŠ¸ ëª©ì                            | ìš°ì„ ìˆœìœ„    |
| ---------------- | ------------------------------------- | ----------- |
| ì¬ì‹œë„ íšŸìˆ˜ ê²€ì¦ | `max_retries=3` ì„¤ì • ì¤€ìˆ˜             | ğŸ”´ Critical |
| ì¬ì‹œë„ ê°„ê²© ê²€ì¦ | Exponential backoff ë™ì‘              | ğŸŸ¡ High     |
| DLQ ì´ë™ ì¡°ê±´    | `MaxRetriesExceededError` í›„ DLQ ì „ì†¡ | ğŸ”´ Critical |
| DLQ ë©”ì‹œì§€ í¬ë§·  | ì—ëŸ¬ ì»¨í…ìŠ¤íŠ¸ í¬í•¨ ì—¬ë¶€               | ğŸŸ¡ High     |
| DLQ ì¬ì²˜ë¦¬       | `scan_and_reprocess_dlq` ì„±ê³µ         | ğŸ”´ Critical |
| ë™ì‹œì„± ì œì–´      | ë¶„ì‚° ë½ìœ¼ë¡œ ì¤‘ë³µ ì¬ì²˜ë¦¬ ë°©ì§€          | ğŸŸ¡ High     |

#### Edge Case ê²½ê³„ê°’ í…ŒìŠ¤íŠ¸ (6ì°¨ ê²€í†  ì¶”ê°€)

> **Quality Engineer ê¶Œì¥ì‚¬í•­**: ê²½ê³„ê°’ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ë³´ê°•

| í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤       | ì…ë ¥ ê°’                 | ì˜ˆìƒ ê²°ê³¼             | ê²€ì¦ ë°©ë²•                         |
| ------------------- | ----------------------- | --------------------- | --------------------------------- |
| íŒŒì¼ í¬ê¸° 0         | 0 bytes                 | `VALIDATION_ERROR`    | `assert exc.code == 'EMPTY_FILE'` |
| ìµœì†Œ ìœ íš¨ í¬ê¸°      | 1 byte                  | íŒŒì„œ ì‹œë„ â†’ ì‹¤íŒ¨      | Magic byte ê²€ì¦                   |
| ìµœëŒ€ í¬ê¸° ê²½ê³„ (í•˜) | 99.9MB                  | ì •ìƒ ì²˜ë¦¬             | ì„±ê³µ ì‘ë‹µ í™•ì¸                    |
| ìµœëŒ€ í¬ê¸° ê²½ê³„ (ìƒ) | 100.1MB                 | `VALIDATION_ERROR`    | `FILE_TOO_LARGE` ì—ëŸ¬             |
| ë¹ˆ DXF ì—”í‹°í‹°       | ENTITIES ì„¹ì…˜ ë¹„ì–´ìˆìŒ  | ë¹ˆ geometry ë°˜í™˜      | `result.entities == []`           |
| ìµœëŒ€ ì—”í‹°í‹° ìˆ˜      | 100,000ê°œ LINE          | ì •ìƒ ì²˜ë¦¬ (ëŠë¦¼)      | íƒ€ì„ì•„ì›ƒ ë‚´ ì™„ë£Œ                  |
| Unicode íŒŒì¼ëª…      | `ë„ë©´_ìµœì¢…_v2.dxf`      | ì •ìƒ ì²˜ë¦¬             | URL ì¸ì½”ë”© ê²€ì¦                   |
| íŠ¹ìˆ˜ë¬¸ì íŒŒì¼ëª…     | `plan (1) [final].dxf`  | ì •ìƒ ì²˜ë¦¬             | ì´ìŠ¤ì¼€ì´í”„ ê²€ì¦                   |
| ë™ì‹œ ë™ì¼ íŒŒì¼      | ê°™ì€ hash íŒŒì¼ 2ê°œ ë™ì‹œ | ë©±ë“±ì„± ë³´ì¥           | ê²°ê³¼ ë™ì¼ì„± í™•ì¸                  |
| ì¤‘ë³µ task_id        | ì´ë¯¸ ì¡´ì¬í•˜ëŠ” UUID      | `DUPLICATE_TASK` ì—ëŸ¬ | DB ì œì•½ì¡°ê±´ ê²€ì¦                  |

**ê²½ê³„ê°’ í…ŒìŠ¤íŠ¸ êµ¬í˜„ ì˜ˆì‹œ**:

```python
import pytest
from pathlib import Path

class TestBoundaryValues:
    """ê²½ê³„ê°’ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸"""

    @pytest.mark.parametrize("size_mb,expected", [
        (0, "EMPTY_FILE"),
        (0.001, "INVALID_FORMAT"),  # 1KB - ë„ˆë¬´ ì‘ì•„ì„œ ìœ íš¨í•˜ì§€ ì•ŠìŒ
        (99.9, "SUCCESS"),
        (100.1, "FILE_TOO_LARGE"),
    ])
    def test_file_size_boundaries(self, size_mb: float, expected: str):
        """íŒŒì¼ í¬ê¸° ê²½ê³„ê°’ í…ŒìŠ¤íŠ¸"""
        file_content = b"0" * int(size_mb * 1024 * 1024)
        result = process_file(file_content)
        assert result.status == expected

    @pytest.mark.parametrize("filename", [
        "ë„ë©´_ìµœì¢…_v2.dxf",
        "Ğ¿Ğ»Ğ°Ğ½_ÑÑ‚Ğ°Ğ¶Ğ°.dxf",
        "floor plan (1) [final].dxf",
        "test\x00null.dxf",  # null byte í¬í•¨
    ])
    def test_unicode_filenames(self, filename: str):
        """ìœ ë‹ˆì½”ë“œ ë° íŠ¹ìˆ˜ë¬¸ì íŒŒì¼ëª… í…ŒìŠ¤íŠ¸"""
        # null byteëŠ” ê±°ë¶€ë˜ì–´ì•¼ í•¨
        if "\x00" in filename:
            with pytest.raises(ValidationError):
                validate_filename(filename)
        else:
            assert validate_filename(filename) is True

    def test_concurrent_identical_files(self, celery_worker):
        """ë™ì¼ íŒŒì¼ ë™ì‹œ ì²˜ë¦¬ ë©±ë“±ì„± í…ŒìŠ¤íŠ¸"""
        file_hash = "abc123"
        task1 = process_dxf.delay(file_hash=file_hash)
        task2 = process_dxf.delay(file_hash=file_hash)

        result1 = task1.get(timeout=30)
        result2 = task2.get(timeout=30)

        # ë©±ë“±ì„±: ë‘ ê²°ê³¼ê°€ ë™ì¼í•´ì•¼ í•¨
        assert result1.output_url == result2.output_url
```

#### GitOps ë°°í¬ (ArgoCD)

> ğŸ“Œ **ì°¸ì¡°**: ArgoCD Application ì •ì˜ ë° ìƒì„¸ ì„¤ì •ì€ **[ì„¹ì…˜ 5.12 GitOps ì›Œí¬í”Œë¡œìš°](#512-gitops-ì›Œí¬í”Œë¡œìš°-8ì°¨-ê²€í† -ì¶”ê°€)**ì—ì„œ ë‹¨ì¼ ê´€ë¦¬í•©ë‹ˆë‹¤. ì„¤ì • ë¶ˆì¼ì¹˜ ë°©ì§€ë¥¼ ìœ„í•´ ì¤‘ë³µ ì •ì˜ë¥¼ ì œê±°í–ˆìŠµë‹ˆë‹¤ (8ì°¨ ê²€í†  ë°˜ì˜).

**í™˜ê²½ë³„ Kustomize êµ¬ì¡°**:

```
k8s/workers/
â”œâ”€â”€ base/
â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”œâ”€â”€ service.yaml
â”‚   â””â”€â”€ configmap.yaml
â”œâ”€â”€ overlays/
â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”‚   â””â”€â”€ patches/
â”‚   â”‚       â””â”€â”€ replicas.yaml
â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”‚   â””â”€â”€ patches/
â”‚   â””â”€â”€ prod/
â”‚       â”œâ”€â”€ kustomization.yaml
â”‚       â””â”€â”€ patches/
â”‚           â”œâ”€â”€ replicas.yaml
â”‚           â”œâ”€â”€ resources.yaml
â”‚           â””â”€â”€ hpa.yaml
```

**ë°°í¬ ì „ëµ (Blue/Green with ArgoCD)**:

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Rollout # Argo Rollouts CRD
metadata:
    name: dxf-worker
spec:
    replicas: 3
    strategy:
        blueGreen:
            activeService: dxf-worker-active
            previewService: dxf-worker-preview
            autoPromotionEnabled: false # ìˆ˜ë™ ìŠ¹ì¸ í•„ìš”
            prePromotionAnalysis:
                templates:
                    - templateName: success-rate
                args:
                    - name: service-name
                      value: dxf-worker-preview
```

---

### 5.11 ë¡œê·¸ ì§‘ê³„ ë° ë¶„ì‚° íŠ¸ë ˆì´ì‹±

#### ë¡œê·¸ ì§‘ê³„ ì•„í‚¤í…ì²˜ (Promtail + Loki + Grafana)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Workers    â”‚â”€â”€â”€â”€â–¶â”‚   Promtail   â”‚â”€â”€â”€â”€â–¶â”‚    Loki      â”‚â”€â”€â”€â”€â–¶â”‚   Grafana    â”‚
â”‚  (stdout)    â”‚     â”‚  (ìˆ˜ì§‘ê¸°)     â”‚     â”‚  (ì €ì¥ì†Œ)    â”‚     â”‚  (ì‹œê°í™”)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### êµ¬ì¡°í™” ë¡œê¹… (structlog)

```python
# cad_worker/logging_config.py
import structlog
import logging

def configure_logging():
    """structlog ê¸°ë°˜ êµ¬ì¡°í™” ë¡œê¹… ì„¤ì •"""
    structlog.configure(
        processors=[
            structlog.contextvars.merge_contextvars,
            structlog.processors.add_log_level,
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.JSONRenderer()
        ],
        wrapper_class=structlog.make_filtering_bound_logger(logging.INFO),
        context_class=dict,
        logger_factory=structlog.PrintLoggerFactory(),
        cache_logger_on_first_use=True,
    )

# ì‚¬ìš© ì˜ˆì‹œ
logger = structlog.get_logger()

@celery.task(bind=True)
def process_dxf(self, task_id: str, file_url: str):
    log = logger.bind(
        task_id=task_id,
        worker_id=self.request.hostname,
        file_type="dxf"
    )
    log.info("task_started", file_url=file_url)

    try:
        result = parse_and_convert(file_url)
        log.info("task_completed",
                 processing_time_ms=result.time_ms,
                 output_size_bytes=result.size)
        return result
    except Exception as e:
        log.error("task_failed", error=str(e), exc_info=True)
        raise
```

#### ë¡œê·¸ í•„ë“œ í‘œì¤€í™”

| í•„ë“œ                 | íƒ€ì…    | ì„¤ëª…             | ì˜ˆì‹œ                             |
| -------------------- | ------- | ---------------- | -------------------------------- |
| `timestamp`          | ISO8601 | ì´ë²¤íŠ¸ ë°œìƒ ì‹œê° | `2025-12-08T10:00:00Z`           |
| `level`              | string  | ë¡œê·¸ ë ˆë²¨        | `info`, `error`, `warning`       |
| `task_id`            | UUID    | ì‘ì—… ì‹ë³„ì      | `550e8400-...`                   |
| `worker_id`          | string  | Worker ì‹ë³„ì    | `dxf-worker-001`                 |
| `file_type`          | string  | íŒŒì¼ ìœ í˜•        | `dxf`, `pdf`                     |
| `event`              | string  | ì´ë²¤íŠ¸ ìœ í˜•      | `task_started`, `task_completed` |
| `processing_time_ms` | int     | ì²˜ë¦¬ ì‹œê°„ (ms)   | `2340`                           |
| `error`              | string  | ì—ëŸ¬ ë©”ì‹œì§€      | `Invalid DXF format`             |

#### ë¡œê·¸ ë³´ì¡´ ì •ì±…

| ë ˆë²¨    | ë³´ì¡´ ê¸°ê°„ | ì €ì¥ì†Œ     | ì¸ë±ì‹±        |
| ------- | --------- | ---------- | ------------- |
| ERROR   | 90ì¼      | Loki (SSD) | ì „ì²´ ì¸ë±ìŠ¤   |
| WARNING | 30ì¼      | Loki (SSD) | ì„ íƒì  ì¸ë±ìŠ¤ |
| INFO    | 14ì¼      | Loki (HDD) | ìµœì†Œ ì¸ë±ìŠ¤   |
| DEBUG   | 3ì¼       | Loki (HDD) | ì¸ë±ìŠ¤ ì—†ìŒ   |

#### ë¡œê·¸ ìƒ˜í”Œë§ ì „ëµ

**ì´ë²¤íŠ¸ë³„ ìƒ˜í”Œë§ ë¹„ìœ¨ (5ì°¨ ê²€í†  ì¡°ì •)**:

| ì´ë²¤íŠ¸ ìœ í˜•              | ìƒ˜í”Œë§ ë¹„ìœ¨ | ì´ìœ                                                  |
| ------------------------ | ----------- | ---------------------------------------------------- |
| `task_failed` (FAILURE)  | **100%**    | ì¥ì•  ë¶„ì„ í•„ìˆ˜                                       |
| `task_retry`             | **100%**    | ì¬ì‹œë„ íŒ¨í„´ ë¶„ì„                                     |
| `task_success` (SUCCESS) | **50%**     | 5ì°¨ ê²€í† : 10â†’50% (ì¥ì•  ë¶„ì„ ì‹œ ì¶©ë¶„í•œ ì»¨í…ìŠ¤íŠ¸ í™•ë³´) |
| `health_check`           | **1%**      | ì£¼ê¸°ì  ì²´í¬ë¡œ ì¸í•œ ë…¸ì´ì¦ˆ ê°ì†Œ                       |

> **âš ï¸ 5ì°¨ ê²€í†  ìˆ˜ì •**: SUCCESS 10% ìƒ˜í”Œë§ì€ ì¥ì•  ë¶„ì„ ì‹œ ì„±ê³µ ì‚¬ë¡€ì™€ì˜ ë¹„êµê°€ ì–´ë ¤ì›€. 50%ë¡œ ìƒí–¥í•˜ì—¬ A/B ë¹„êµ ë¶„ì„ ê°€ëŠ¥.

**êµ¬í˜„ ì˜ˆì‹œ:**

```python
import random
import structlog

class SamplingProcessor:
    """ì´ë²¤íŠ¸ë³„ ë¡œê·¸ ìƒ˜í”Œë§"""

    SAMPLING_RATES = {
        "task_failed": 1.0,      # 100%
        "task_retry": 1.0,       # 100%
        "task_success": 0.5,     # 50% (5ì°¨ ê²€í†  ì¡°ì •)
        "health_check": 0.01,    # 1%
    }

    def __call__(self, logger, method_name, event_dict):
        event = event_dict.get("event", "")
        rate = self.SAMPLING_RATES.get(event, 1.0)

        if random.random() > rate:
            raise structlog.DropEvent

        event_dict["sampled"] = True
        event_dict["sample_rate"] = rate
        return event_dict
```

#### Loki ë ˆì´ë¸” ì¹´ë””ë„ë¦¬í‹° ì œí•œ

> **âš ï¸ ê³ ì¹´ë””ë„ë¦¬í‹° ë ˆì´ë¸” ì£¼ì˜**: `task_id`, `user_id` ë“± ìœ ë‹ˆí¬ ê°’ì€ ë ˆì´ë¸”ë¡œ ì‚¬ìš© ê¸ˆì§€

**í—ˆìš© ë ˆì´ë¸” (5ì°¨ ê²€í† : ìµœëŒ€ 4ê°œë¡œ ì œí•œ)**:

| ë ˆì´ë¸”      | ì¹´ë””ë„ë¦¬í‹° | ì˜ˆì‹œ ê°’                          |
| ----------- | ---------- | -------------------------------- |
| `namespace` | ë‚®ìŒ       | `cad-worker`                     |
| `app`       | ë‚®ìŒ       | `dxf-worker`, `pdf-worker`       |
| `level`     | ë§¤ìš° ë‚®ìŒ  | `info`, `error`, `warning`       |
| `event`     | ì¤‘ê°„       | `task_started`, `task_completed` |

> **5ì°¨ ê²€í†  ìˆ˜ì •**: `pod` ë ˆì´ë¸” ì œê±°. PodëŠ” ìˆ˜ì‹œë¡œ ì¬ìƒì„±ë˜ì–´ ì¹´ë””ë„ë¦¬í‹° ì¦ê°€ â†’ 4ê°œë¡œ ì œí•œ.

**ê¸ˆì§€ ë ˆì´ë¸” (ê³ ì¹´ë””ë„ë¦¬í‹°):**

```yaml
# âŒ ì‚¬ìš© ê¸ˆì§€ - Loki ì„±ëŠ¥ ì €í•˜ ìœ ë°œ
labels:
    task_id: '550e8400-...' # ë§¤ ìš”ì²­ë§ˆë‹¤ ìœ ë‹ˆí¬
    user_id: 'user-123' # ì‚¬ìš©ì ìˆ˜ë§Œí¼ ì¦ê°€
    file_name: 'drawing.dxf' # íŒŒì¼ë§ˆë‹¤ ë‹¤ë¦„
    pod: 'dxf-worker-xxx' # 5ì°¨ ê²€í† : Pod ì¬ìƒì„± ì‹œ ì¹´ë””ë„ë¦¬í‹° ì¦ê°€
```

#### Promtail ì„¤ì •

```yaml
# promtail-config.yml
server:
    http_listen_port: 9080
    grpc_listen_port: 0

positions:
    filename: /tmp/positions.yaml

clients:
    - url: http://loki:3100/loki/api/v1/push

scrape_configs:
    - job_name: cad-workers
      kubernetes_sd_configs:
          - role: pod
      relabel_configs:
          - source_labels: [__meta_kubernetes_namespace]
            target_label: namespace
          - source_labels: [__meta_kubernetes_pod_name]
            target_label: pod
          - source_labels: [__meta_kubernetes_pod_label_app]
            target_label: app
      pipeline_stages:
          - json:
                expressions:
                    level: level
                    task_id: task_id
                    event: event
          - labels:
                level:
                task_id:
                event:
```

#### ë¶„ì‚° íŠ¸ë ˆì´ì‹± (Phase 4+, OpenTelemetry)

> **Phase 4 ì´í›„ êµ¬í˜„ ì˜ˆì •**

```python
# í–¥í›„ OpenTelemetry í†µí•© ì˜ˆì‹œ
from opentelemetry import trace
from opentelemetry.instrumentation.celery import CeleryInstrumentor

tracer = trace.get_tracer(__name__)
CeleryInstrumentor().instrument()

@celery.task(bind=True)
def process_dxf(self, task_id: str, file_url: str):
    with tracer.start_as_current_span("dxf_processing") as span:
        span.set_attribute("task.id", task_id)
        span.set_attribute("file.type", "dxf")
        # ... ì²˜ë¦¬ ë¡œì§
```

---

### 5.12 GitOps ì›Œí¬í”Œë¡œìš°

> **DevOps Architect ê¶Œì¥ì‚¬í•­**: ì„ ì–¸ì  ì¸í”„ë¼ ê´€ë¦¬, ë“œë¦¬í”„íŠ¸ ê°ì§€, ê°ì‚¬ ì¶”ì ì„ ìœ„í•œ GitOps í•„ìˆ˜

#### GitOps ë„êµ¬ ì„ íƒ

| ë„êµ¬       | ê¸°ëŠ¥ì„±     | í•™ìŠµ ê³¡ì„   | ì»¤ë®¤ë‹ˆí‹°   | 2-3ëª… íŒ€ ì í•©ì„± | ì„ íƒ    |
| ---------- | ---------- | ---------- | ---------- | --------------- | ------- |
| **ArgoCD** | â­â­â­â­â­ | â­â­â­â­   | â­â­â­â­â­ | â­â­â­â­â­      | âœ… ê¶Œì¥ |
| Flux       | â­â­â­â­   | â­â­â­â­â­ | â­â­â­â­   | â­â­â­â­        | ëŒ€ì•ˆ    |
| Jenkins X  | â­â­â­â­â­ | â­â­â­     | â­â­â­     | â­â­            | âŒ      |

**ArgoCD ì„ ì • ê·¼ê±°**:

- ì§ê´€ì ì¸ Web UIë¡œ ë°°í¬ ìƒíƒœ ì‹œê°í™”
- Application CRDë¡œ ì„ ì–¸ì  ë°°í¬ ê´€ë¦¬
- ìë™ ë™ê¸°í™” ë° ë“œë¦¬í”„íŠ¸ ê°ì§€
- Helm, Kustomize, Jsonnet ì§€ì›
- RBAC ê¸°ë°˜ ì ‘ê·¼ ì œì–´

#### ArgoCD Application ì •ì˜

```yaml
# argocd/applications/cad-workers.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
    name: cad-workers
    namespace: argocd
    finalizers:
        - resources-finalizer.argocd.argoproj.io
spec:
    project: cad-platform
    source:
        repoURL: https://github.com/your-org/cad-platform-infra.git
        targetRevision: HEAD
        path: kubernetes/overlays/production
    destination:
        server: https://kubernetes.default.svc
        namespace: cad-worker
    syncPolicy:
        automated:
            prune: true # ì‚­ì œëœ ë¦¬ì†ŒìŠ¤ ìë™ ì œê±°
            selfHeal: true # ìˆ˜ë™ ë³€ê²½ ì‹œ ìë™ ë³µêµ¬
            allowEmpty: false # ë¹ˆ ìƒíƒœ ë°©ì§€
        syncOptions:
            - CreateNamespace=true
            - PrunePropagationPolicy=foreground
            - PruneLast=true
        retry:
            limit: 5
            backoff:
                duration: 5s
                factor: 2
                maxDuration: 3m
```

#### í™˜ê²½ë³„ Kustomize êµ¬ì¡°

```
kubernetes/
â”œâ”€â”€ base/
â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”œâ”€â”€ deployment-dxf.yaml
â”‚   â”œâ”€â”€ deployment-pdf.yaml
â”‚   â”œâ”€â”€ service.yaml
â”‚   â””â”€â”€ configmap.yaml
â”œâ”€â”€ overlays/
â”‚   â”œâ”€â”€ development/
â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”‚   â”œâ”€â”€ replica-patch.yaml      # replicas: 1
â”‚   â”‚   â””â”€â”€ resource-patch.yaml     # ë‚®ì€ ë¦¬ì†ŒìŠ¤
â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”‚   â”œâ”€â”€ replica-patch.yaml      # replicas: 2
â”‚   â”‚   â””â”€â”€ ingress-patch.yaml
â”‚   â””â”€â”€ production/
â”‚       â”œâ”€â”€ kustomization.yaml
â”‚       â”œâ”€â”€ replica-patch.yaml      # replicas: 4+
â”‚       â”œâ”€â”€ resource-patch.yaml     # ë†’ì€ ë¦¬ì†ŒìŠ¤
â”‚       â”œâ”€â”€ hpa.yaml                # ìë™ ìŠ¤ì¼€ì¼ë§
â”‚       â””â”€â”€ pdb.yaml                # PodDisruptionBudget
```

**í™˜ê²½ë³„ Kustomization ì˜ˆì‹œ**:

```yaml
# kubernetes/overlays/production/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namespace: cad-worker-prod

resources:
    - ../../base

namePrefix: prod-

commonLabels:
    environment: production

patchesStrategicMerge:
    - replica-patch.yaml
    - resource-patch.yaml

configMapGenerator:
    - name: worker-config
      behavior: merge
      literals:
          - LOG_LEVEL=INFO
          - ENVIRONMENT=production

images:
    - name: cad-worker
      newName: ghcr.io/org/cad-worker # 9ì°¨ ê²€í†  ë°˜ì˜: ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë³€ê²½ ì§€ì›
      newTag: v1.2.3 # í”„ë¡œë•ì…˜ ë²„ì „ ê³ ì • (SHA ê¸°ë°˜ ë¶ˆë³€ íƒœê·¸ ê¶Œì¥)
```

#### í™˜ê²½ë³„ ë°°í¬ ì •ì±…

| í™˜ê²½        | ë™ê¸°í™” ë°©ì‹ | ìŠ¹ì¸ í•„ìš”   | ì•Œë¦¼              | ë¡¤ë°±         |
| ----------- | ----------- | ----------- | ----------------- | ------------ |
| **dev**     | ìë™ ë™ê¸°í™” | âŒ          | Slack             | ìë™         |
| **staging** | ìë™ ë™ê¸°í™” | PR ìŠ¹ì¸     | Slack             | ìë™         |
| **prod**    | ìˆ˜ë™ ë™ê¸°í™” | ëª…ì‹œì  ìŠ¹ì¸ | Slack + PagerDuty | ìˆ˜ë™ í™•ì¸ í›„ |

**ArgoCD Notification ì„¤ì •**:

```yaml
# argocd-notifications-cm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
    name: argocd-notifications-cm
    namespace: argocd
data:
    service.slack: |
        token: $slack-token

    template.app-sync-succeeded: |
        message: |
          âœ… Application {{.app.metadata.name}} synced!
          Revision: {{.app.status.sync.revision}}

    trigger.on-sync-succeeded: |
        - when: app.status.sync.status == 'Synced'
          send: [app-sync-succeeded]
```

#### ë“œë¦¬í”„íŠ¸ ê°ì§€ ë° ë³µêµ¬

```yaml
# ArgoCD Applicationì— selfHeal í™œì„±í™”
spec:
    syncPolicy:
        automated:
            selfHeal: true # í´ëŸ¬ìŠ¤í„° ìƒíƒœ ìë™ ë³µêµ¬
```

**ë“œë¦¬í”„íŠ¸ ê°ì§€ ì‹œë‚˜ë¦¬ì˜¤**:

| ë³€ê²½ ìœ í˜•          | ArgoCD ë™ì‘          | ì•Œë¦¼       |
| ------------------ | -------------------- | ---------- |
| kubectl ìˆ˜ë™ ë³€ê²½  | ìë™ ë³µêµ¬ (selfHeal) | Slack ê²½ê³  |
| ConfigMap ë³€ê²½     | ìë™ ë™ê¸°í™”          | ì—†ìŒ       |
| ì™¸ë¶€ Operator ë³€ê²½ | ë¬´ì‹œ (annotation)    | ì—†ìŒ       |
| ì´ë¯¸ì§€ íƒœê·¸ ë³€ê²½   | ë™ê¸°í™” ëŒ€ê¸°          | Slack ì •ë³´ |

---

### 5.13 Service Mesh í†µí•© ì „ëµ

> **System Architect ê¶Œì¥ì‚¬í•­**: mTLS ì¤‘ì•™ ê´€ë¦¬, íŠ¸ë˜í”½ ì •ì±…, ê´€ì¸¡ì„± ê°•í™”ë¥¼ ìœ„í•œ Service Mesh ë„ì… ê²€í† 

#### Service Mesh ì„ íƒ ë¹„êµ

| ê¸°ì¤€            | Istio         | Linkerd           | Consul Connect |
| --------------- | ------------- | ----------------- | -------------- |
| ê¸°ëŠ¥ í’ë¶€ë„     | â­â­â­â­â­    | â­â­â­â­          | â­â­â­â­       |
| ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰   | â­â­â­ (ë†’ìŒ) | â­â­â­â­â­ (ë‚®ìŒ) | â­â­â­â­       |
| í•™ìŠµ ê³¡ì„        | â­â­â­        | â­â­â­â­â­        | â­â­â­â­       |
| 2-3ëª… íŒ€ ì í•©ì„± | â­â­â­        | â­â­â­â­â­        | â­â­â­â­       |
| ì»¤ë®¤ë‹ˆí‹°/ì§€ì›   | â­â­â­â­â­    | â­â­â­â­â­        | â­â­â­â­       |

**ê¶Œì¥: Linkerd** (ì†Œê·œëª¨ íŒ€, ë‚®ì€ ì˜¤ë²„í—¤ë“œ)

**Linkerd ì„ ì • ê·¼ê±°**:

- ê°€ë³ê³  ë¹ ë¥¸ ì„¤ì¹˜ (~5ë¶„)
- ìë™ mTLS (zero-config)
- Rust ê¸°ë°˜ í”„ë¡ì‹œ (ë‚®ì€ ë¦¬ì†ŒìŠ¤)
- ì§ê´€ì ì¸ ëŒ€ì‹œë³´ë“œ
- CNCF Graduated í”„ë¡œì íŠ¸

#### Linkerd ì„¤ì¹˜ ë° ì„¤ì •

```bash
# Linkerd CLI ì„¤ì¹˜
curl --proto '=https' --tlsv1.2 -sSfL https://run.linkerd.io/install | sh

# ì‚¬ì „ ê²€ì‚¬
linkerd check --pre

# Linkerd ì„¤ì¹˜
linkerd install --crds | kubectl apply -f -
linkerd install | kubectl apply -f -

# ì„¤ì¹˜ í™•ì¸
linkerd check

# ëŒ€ì‹œë³´ë“œ ì„¤ì¹˜ (ì„ íƒ)
linkerd viz install | kubectl apply -f -
```

#### Worker Namespace ë©”ì‹œí™”

```yaml
# namespace.yaml - Linkerd ì£¼ì… í™œì„±í™”
apiVersion: v1
kind: Namespace
metadata:
    name: cad-worker
    annotations:
        linkerd.io/inject: enabled # ìë™ ì‚¬ì´ë“œì¹´ ì£¼ì…
```

```yaml
# deployment.yaml - ëª…ì‹œì  ì£¼ì… (ì„ íƒ)
apiVersion: apps/v1
kind: Deployment
metadata:
    name: dxf-worker
    annotations:
        linkerd.io/inject: enabled
spec:
    template:
        metadata:
            annotations:
                linkerd.io/inject: enabled
                config.linkerd.io/proxy-cpu-request: '100m'
                config.linkerd.io/proxy-memory-request: '64Mi'
```

#### mTLS ì¤‘ì•™ ê´€ë¦¬

```yaml
# LinkerdëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë“  ë©”ì‹œ ë‚´ í†µì‹ ì— mTLS ì ìš©
# ëª…ì‹œì  ì •ì±… ì„¤ì • (ì„ íƒ)
apiVersion: policy.linkerd.io/v1beta1
kind: Server
metadata:
    name: dxf-worker
    namespace: cad-worker
spec:
    podSelector:
        matchLabels:
            app: dxf-worker
    port: 8080
    proxyProtocol: HTTP/2
---
apiVersion: policy.linkerd.io/v1beta1
kind: ServerAuthorization
metadata:
    name: allow-backend
    namespace: cad-worker
spec:
    server:
        name: dxf-worker
    client:
        meshTLS:
            serviceAccounts:
                - name: cad-backend
                  namespace: cad-backend
```

#### íŠ¸ë˜í”½ ì •ì±… (Retry, Timeout)

```yaml
# service-profile.yaml
apiVersion: linkerd.io/v1alpha2
kind: ServiceProfile
metadata:
    name: dxf-worker.cad-worker.svc.cluster.local
    namespace: cad-worker
spec:
    routes:
        - name: POST /api/process
          condition:
              method: POST
              pathRegex: /api/process
          responseClasses:
              - condition:
                    status:
                        min: 500
                        max: 599
                isFailure: true
          retries:
              budget:
                  retryRatio: 0.2 # ìµœëŒ€ 20% ì¬ì‹œë„
                  minRetriesPerSecond: 10
                  ttl: 10s
          timeout: 30s # ìš”ì²­ íƒ€ì„ì•„ì›ƒ
```

#### ê´€ì¸¡ì„± (Jaeger ì—°ë™)

```yaml
# Linkerd Jaeger í™•ì¥ ì„¤ì¹˜
linkerd jaeger install | kubectl apply -f -

# íŠ¸ë ˆì´ì‹± í™œì„±í™” (deployment)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dxf-worker
spec:
  template:
    metadata:
      annotations:
        config.linkerd.io/trace-collector: collector.linkerd-jaeger:55678
        config.alpha.linkerd.io/trace-collector-service-account: collector
```

#### ë„ì… ë¡œë“œë§µ

| Phase   | ì‘ì—…                              | ì˜ˆìƒ ê¸°ê°„ | ì„ í–‰ ì¡°ê±´           |
| ------- | --------------------------------- | --------- | ------------------- |
| Phase 4 | Linkerd ì„¤ì¹˜ ë° mTLS í™œì„±í™”       | 1ì¼       | K8s í´ëŸ¬ìŠ¤í„° ì•ˆì •í™” |
| Phase 5 | íŠ¸ë˜í”½ ì •ì±… (retry, timeout) ì„¤ì • | 2ì¼       | Phase 4 ì™„ë£Œ        |
| Phase 6 | ê´€ì¸¡ì„± (Jaeger) ì—°ë™              | 1ì¼       | Phase 5 ì™„ë£Œ        |
| Phase 7 | ê³ ê¸‰ ì •ì±… (Circuit Breaker)       | 2ì¼       | ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ    |

**ì£¼ì˜ì‚¬í•­**:

- Service MeshëŠ” Phase 4 ì´í›„ ì„ íƒì  ë„ì…
- ì´ˆê¸°ì—ëŠ” Kubernetes NetworkPolicyë¡œ ì¶©ë¶„
- ë¦¬ì†ŒìŠ¤ ì˜¤ë²„í—¤ë“œ ëª¨ë‹ˆí„°ë§ í•„ìˆ˜ (ì‚¬ì´ë“œì¹´ë‹¹ ~50MB ë©”ëª¨ë¦¬)

---

## 6. ì„±ëŠ¥ ë² ì´ìŠ¤ë¼ì¸

> **Quality Engineer ê¶Œì¥ì‚¬í•­**: SLA ëª©í‘œ vs í˜„ì‹¤ ë¹„êµë¥¼ ìœ„í•œ ë² ì´ìŠ¤ë¼ì¸ ì¸¡ì • í•„ìˆ˜

### í˜„ì¬ ì¸¡ì •ê°’ í…œí”Œë¦¿ (8ì°¨ ê²€í†  ë³´ì™„)

**Phase 3B êµ¬í˜„ í›„ ì‹¤ì¸¡ ê°±ì‹  í•„ìš”** (ì•„ë˜ëŠ” ìœ ì‚¬ ì›Œí¬ë¡œë“œ ê¸°ë°˜ ì˜ˆìƒê°’)

> ğŸ“Š **ì˜ˆìƒê°’ ê·¼ê±°**: Open-source CAD ì²˜ë¦¬ ë²¤ì¹˜ë§ˆí¬, DXF-parser ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸, GPU ê¸°ë°˜ PDF ë Œë”ë§ ì‚¬ë¡€ ì°¸ì¡°

#### ì§€ì—° ì‹œê°„ (Latency)

| ë©”íŠ¸ë¦­          | P50 (ì˜ˆìƒ) | P95 (ì˜ˆìƒ) | P99 (ì˜ˆìƒ) | SLA ëª©í‘œ     | ìƒíƒœ              |
| --------------- | ---------- | ---------- | ---------- | ------------ | ----------------- |
| DXF ì²˜ë¦¬ ì‹œê°„   | **~1.2ì´ˆ** | **~3.5ì´ˆ** | **~4.8ì´ˆ** | < 5ì´ˆ        | ğŸ¯ ëª©í‘œ ë‹¬ì„± ì˜ˆìƒ |
| PDF ì²˜ë¦¬ ì‹œê°„   | **~8ì´ˆ**   | **~22ì´ˆ**  | **~28ì´ˆ**  | < 30ì´ˆ       | ğŸ¯ ëª©í‘œ ë‹¬ì„± ì˜ˆìƒ |
| í ëŒ€ê¸° ì‹œê°„    | **~0.3ì´ˆ** | **~1.2ì´ˆ** | **~1.8ì´ˆ** | < 2ì´ˆ        | ğŸ¯ ëª©í‘œ ë‹¬ì„± ì˜ˆìƒ |
| End-to-End ì‘ë‹µ | **~2ì´ˆ**   | **~6ì´ˆ**   | **~9ì´ˆ**   | < 10ì´ˆ (DXF) | ğŸ¯ ëª©í‘œ ë‹¬ì„± ì˜ˆìƒ |

**ì˜ˆìƒê°’ ì‚°ì¶œ ê·¼ê±°**:

- DXF: í‰ê·  50KB íŒŒì¼ ê¸°ì¤€, ezdxf ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²¤ì¹˜ë§ˆí¬ (10K ì—”í‹°í‹°/ì´ˆ)
- PDF: A4 10í˜ì´ì§€ ê¸°ì¤€, GPU (T4) ë Œë”ë§ ë²¤ì¹˜ë§ˆí¬
- í ëŒ€ê¸°: RabbitMQ ë‹¨ì¼ ë…¸ë“œ ì²˜ë¦¬ëŸ‰ 50K msg/sec ê¸°ì¤€
- E2E: ë„¤íŠ¸ì›Œí¬ ì˜¤ë²„í—¤ë“œ (~200ms) + ì²˜ë¦¬ ì‹œê°„ + ê²°ê³¼ ì €ì¥ (~300ms)

#### ì²˜ë¦¬ëŸ‰ (Throughput)

| Worker              | í˜„ì¬ ì²˜ë¦¬ëŸ‰ (ì˜ˆìƒ) | ëª©í‘œ ì²˜ë¦¬ëŸ‰ | ë³‘ëª©ì               |
| ------------------- | ------------------ | ----------- | ------------------- |
| DXF Worker (4 vCPU) | **~8 req/min**     | 480 req/hr  | CPU ì—°ì‚° (íŒŒì‹±)     |
| PDF Worker (GPU)    | **~4 req/min**     | 40 req/hr   | GPU ë©”ëª¨ë¦¬ (ë Œë”ë§) |

**ìŠ¤ì¼€ì¼ë§ ì˜ˆì¸¡**:

- DXF Worker 1ëŒ€ (4 concurrent) â†’ 32 req/min â†’ **1,920 req/hr** (ëª©í‘œì˜ 4ë°°)
- PDF Worker 1ëŒ€ (2 concurrent, GPU) â†’ 8 req/min â†’ **480 req/hr** (ëª©í‘œì˜ 12ë°°)

#### ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  (ì˜ˆìƒ)

| ì»´í¬ë„ŒíŠ¸   | CPU í‰ê·              | CPU P95  | ë©”ëª¨ë¦¬ í‰ê·  | ë©”ëª¨ë¦¬ P95 |
| ---------- | -------------------- | -------- | ----------- | ---------- |
| DXF Worker | **~60%**             | **~85%** | **~4GB**    | **~6.5GB** |
| PDF Worker | **~40%** (GPU: ~70%) | **~65%** | **~10GB**   | **~14GB**  |
| RabbitMQ   | **~15%**             | **~35%** | **~512MB**  | **~1GB**   |
| PostgreSQL | **~25%**             | **~55%** | **~2GB**    | **~3.5GB** |

> âš ï¸ **Phase 3B í›„ 7ì¼ ë‚´ ì‹¤ì¸¡ í•„ìˆ˜** - ì˜ˆìƒê°’ê³¼ ì‹¤ì¸¡ê°’ 10% ì´ìƒ ì°¨ì´ ì‹œ SLA ì¡°ì • ê²€í† 

### ì¸¡ì • ë°©ë²•

**Prometheus Metrics**:

```python
# metrics.py
from prometheus_client import Histogram, Counter, Gauge

# ì²˜ë¦¬ ì‹œê°„ íˆìŠ¤í† ê·¸ë¨
TASK_DURATION = Histogram(
    'worker_task_duration_seconds',
    'Task processing duration',
    ['task_type', 'status'],
    buckets=[0.1, 0.5, 1, 2, 5, 10, 30, 60, 120, 300]
)

# í ëŒ€ê¸° ì‹œê°„
QUEUE_WAIT_TIME = Histogram(
    'worker_queue_wait_seconds',
    'Time spent waiting in queue',
    ['queue_name'],
    buckets=[0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10]
)

# ì²˜ë¦¬ëŸ‰ ì¹´ìš´í„°
TASKS_PROCESSED = Counter(
    'worker_tasks_total',
    'Total tasks processed',
    ['task_type', 'status']
)

# í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì‘ì—…
TASKS_IN_PROGRESS = Gauge(
    'worker_tasks_in_progress',
    'Tasks currently being processed',
    ['task_type']
)
```

**Grafana ëŒ€ì‹œë³´ë“œ ì¿¼ë¦¬ ì˜ˆì‹œ**:

```promql
# P50 ì²˜ë¦¬ ì‹œê°„
histogram_quantile(0.50, sum(rate(worker_task_duration_seconds_bucket[5m])) by (le, task_type))

# P95 ì²˜ë¦¬ ì‹œê°„
histogram_quantile(0.95, sum(rate(worker_task_duration_seconds_bucket[5m])) by (le, task_type))

# P99 ì²˜ë¦¬ ì‹œê°„
histogram_quantile(0.99, sum(rate(worker_task_duration_seconds_bucket[5m])) by (le, task_type))

# ë¶„ë‹¹ ì²˜ë¦¬ëŸ‰
sum(rate(worker_tasks_total[1m])) by (task_type) * 60
```

### ì¸¡ì • ì£¼ê¸°

| ë‹¨ê³„            | ì¸¡ì • ì‹œì            | ëª©ì            |
| --------------- | ------------------- | -------------- |
| ì´ˆê¸° ë² ì´ìŠ¤ë¼ì¸ | Phase 3B ì™„ë£Œ í›„    | ê¸°ì¤€ì  ì„¤ì •    |
| ì£¼ê°„ ëª¨ë‹ˆí„°ë§   | ë§¤ì£¼ ì›”ìš”ì¼         | ì¶”ì„¸ ë¶„ì„      |
| ë¶€í•˜ í…ŒìŠ¤íŠ¸     | ê¸°ëŠ¥ ë¦´ë¦¬ìŠ¤ ì „      | ì„±ëŠ¥ íšŒê·€ ë°©ì§€ |
| ì¸ì‹œë˜íŠ¸ í›„     | ì¥ì•  ë³µêµ¬ í›„ 24ì‹œê°„ | ë³µêµ¬ ê²€ì¦      |

### SLA ë‹¬ì„± ê¸°ì¤€

| ë©”íŠ¸ë¦­  | ëª©í‘œ   | ê²½ê³  ì„ê³„ê°’ | ìœ„í—˜ ì„ê³„ê°’ |
| ------- | ------ | ----------- | ----------- |
| DXF P95 | < 5ì´ˆ  | > 3ì´ˆ       | > 5ì´ˆ       |
| PDF P95 | < 30ì´ˆ | > 20ì´ˆ      | > 30ì´ˆ      |
| ê°€ìš©ì„±  | 99.5%  | < 99.7%     | < 99.5%     |
| ì˜¤ë¥˜ìœ¨  | < 0.1% | > 0.05%     | > 0.1%      |

---

## 7. ì „ë¬¸ê°€ ë¶„ì„ ì¢…í•©

> **í‰ê°€ ê¸°ì¤€**: ì „ì²´ ê¸°ìˆ  ìŠ¤íƒ íš¡ë‹¨ ë¹„êµ (5ê°œ ê°€ì¤‘ì¹˜ ê¸°ì¤€)
> Python, Celery, prefork, uv ë“± ëª¨ë“  ê¸°ìˆ ì„ ë™ì¼ ê¸°ì¤€ìœ¼ë¡œ ë¹„êµí•œ ê²°ê³¼ì…ë‹ˆë‹¤.

### í•µì‹¬ ê²°ì • í‰ê°€ ë§¤íŠ¸ë¦­ìŠ¤

| ê¸°ì¤€ (ê°€ì¤‘ì¹˜)   | Python 3.12 | Celery     | prefork    | uv         |
| --------------- | ----------- | ---------- | ---------- | ---------- |
| ì„±ëŠ¥ (25%)      | â­â­â­â­â­  | â­â­â­â­   | â­â­â­â­â­ | â­â­â­â­â­ |
| ì•ˆì •ì„± (25%)    | â­â­â­â­â­  | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­   |
| ìƒíƒœê³„ (20%)    | â­â­â­â­â­  | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­   |
| í†µí•©ì„± (15%)    | â­â­â­â­â­  | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |
| íŒ€ ì í•©ì„± (15%) | â­â­â­â­    | â­â­â­     | â­â­â­â­   | â­â­â­â­   |
| **ê°€ì¤‘ ì´ì **   | **95ì **    | **89ì **   | **97ì **   | **87ì **   |

> â€» ì„¹ì…˜ 5.1 Python ë²„ì „ ì„ íƒ(97ì )ê³¼ ë‹¤ë¥¸ í‰ê°€ ê¸°ì¤€ ì‚¬ìš©. ì„¹ì…˜ 5.1ì€ Python ë²„ì „ ë‚´ë¶€ ë¹„êµìš©(6ê°œ ê¸°ì¤€), ì„¹ì…˜ 6ì€ ì „ì²´ ìŠ¤íƒ ë¹„êµìš©(5ê°œ ê¸°ì¤€).

> **ê°€ì¤‘ ì´ì  ê³„ì‚°**:
>
> - Python 3.12: (5Ã—0.25) + (5Ã—0.25) + (5Ã—0.20) + (5Ã—0.15) + (4Ã—0.15) = **4.75 â†’ 95ì **
> - Celery: (4Ã—0.25) + (5Ã—0.25) + (5Ã—0.20) + (5Ã—0.15) + (3Ã—0.15) = **4.45 â†’ 89ì **
> - prefork: (5Ã—0.25) + (5Ã—0.25) + (5Ã—0.20) + (5Ã—0.15) + (4Ã—0.15) = **4.85 â†’ 97ì **
> - uv: (5Ã—0.25) + (4Ã—0.25) + (4Ã—0.20) + (5Ã—0.15) + (4Ã—0.15) = **4.35 â†’ 87ì **

### ë¶„ì„ ìš”ì•½

**ì£¼ìš” ì¸ì‚¬ì´íŠ¸**:

1. **Python 3.12**: ëˆ„ì  15-65% ì„±ëŠ¥ í–¥ìƒê³¼ ML ìƒíƒœê³„ ì™„ë²½ í˜¸í™˜ìœ¼ë¡œ ìµœì  ì„ íƒ
2. **Celery + prefork**: GIL ìš°íšŒì™€ RabbitMQ ë„¤ì´í‹°ë¸Œ ì§€ì›ìœ¼ë¡œ CPU-bound ì‘ì—…ì— ìµœì 
3. **Worker ë¶„ë¦¬ ì „ëµ**: DXF/PDF ë…ë¦½ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„±ê³¼ ì¥ì•  ê²©ë¦¬ í™•ë³´
4. **uv íŒ¨í‚¤ì§€ ê´€ë¦¬**: 10-100x ë¹ ë¥¸ ì†ë„ë¡œ Docker ë¹Œë“œ ì‹œê°„ ëŒ€í­ ë‹¨ì¶•

---

## 8. ê¶Œì¥ ê¸°ìˆ  ìŠ¤íƒ ì¢…í•©

### requirements.in

```ini
# Core
celery[rabbitmq]>=5.5.0
pika>=1.3.0

# DXF Processing
ezdxf>=1.3.0

# PDF Processing
PyMuPDF>=1.24.0

# 3D Output
pygltflib>=1.16.0

# Image Processing
opencv-python-headless>=4.9.0
numpy>=1.26.0

# ML Inference (GPU Worker)
torch>=2.1.0
ultralytics>=8.0.0
onnxruntime-gpu>=1.16.0

# Database
psycopg2-binary>=2.9.9
SQLAlchemy>=2.0.0

# Storage
boto3>=1.34.0

# Monitoring
prometheus-client>=0.19.0
celery-exporter>=1.3.0

# Utilities
pydantic>=2.5.0
python-dotenv>=1.0.0
structlog>=24.1.0

# Resilience
pybreaker>=1.0.0
```

### pyproject.toml

```toml
[project]
name = "cad-worker"
version = "0.1.0"
requires-python = ">=3.12"

[tool.ruff]
line-length = 88
target-version = "py312"

[tool.ruff.lint]
select = ["E", "F", "I", "N", "W", "UP", "B", "C4", "SIM"]
ignore = ["E501"]

[tool.ruff.format]
quote-style = "double"
indent-style = "space"

[tool.mypy]
python_version = "3.12"
strict = true
warn_return_any = true
disallow_untyped_defs = true

[[tool.mypy.overrides]]
module = ["celery.*", "ezdxf.*", "fitz.*", "cv2.*"]
ignore_missing_imports = true

[tool.pytest.ini_options]
testpaths = ["tests"]
asyncio_mode = "auto"
addopts = "-v --cov=src --cov-report=term-missing"
```

### ë§ˆì´ê·¸ë ˆì´ì…˜ ê²½ë¡œ

```
Phase 1          Phase 2          Phase 3
Python 3.12  â”€â”€â–¶ Python 3.13  â”€â”€â–¶ Python 3.14
Celery 5.5   â”€â”€â–¶ Celery 5.6+  â”€â”€â–¶ Celery 6.x
(í˜„ì¬)           (2027 ê²€í† )       (2028 ê²€í† )
```

**ë§ˆì´ê·¸ë ˆì´ì…˜ ê³ ë ¤ì‚¬í•­:**

- Python ì—…ê·¸ë ˆì´ë“œ: ML ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸í™˜ì„± í™•ì¸ í•„ìˆ˜ (PyTorch, ultralytics)
- Celery ì—…ê·¸ë ˆì´ë“œ: Worker pool ì„¤ì • í˜¸í™˜ì„± ê²€ì¦, ì„¤ì • íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜
- 3.12 â†’ 3.13 ì „í™˜ ì‹œ: `typing` ëª¨ë“ˆ deprecated í•­ëª© í™•ì¸, `asyncio` API ë³€ê²½ ê²€í† 

---

## 9. ê²°ê³¼

### ê¸ì •ì  ê²°ê³¼

| ê²°ê³¼          | ì„¤ëª…                                                 |
| ------------- | ---------------------------------------------------- |
| **ì„±ëŠ¥ í–¥ìƒ** | Python 3.12ë¡œ ëˆ„ì  15-65% ì²˜ë¦¬ ì†ë„ ê°œì„  (3.10 ëŒ€ë¹„) |
| **ì•ˆì •ì„±**    | prefork poolë¡œ GIL ìš°íšŒ, ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€            |
| **í™•ì¥ì„±**    | DXF/PDF Worker ë…ë¦½ ìŠ¤ì¼€ì¼ë§                         |
| **ìš´ì˜ íš¨ìœ¨** | Ruff ë‹¨ì¼ ë„êµ¬ë¡œ ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬ ê°„ì†Œí™”               |
| **ëª¨ë‹ˆí„°ë§**  | Prometheus + Grafanaë¡œ ì‹¤ì‹œê°„ ê°€ì‹œì„± í™•ë³´            |

### ë¶€ì •ì  ê²°ê³¼

| ê²°ê³¼            | ì˜í–¥                     | ì™„í™” ë°©ì•ˆ                  |
| --------------- | ------------------------ | -------------------------- |
| **ìš´ì˜ ë³µì¡ë„** | 2ê°œ Worker ê´€ë¦¬ í•„ìš”     | Docker Compose í†µí•© ê´€ë¦¬   |
| **ë©”ëª¨ë¦¬ ì‚¬ìš©** | prefork pool ë©”ëª¨ë¦¬ ì¦ê°€ | max_tasks_per_childë¡œ ì œì–´ |
| **GPU ë¹„ìš©**    | PDF Worker GPU í•„ìš”      | ìˆ˜ìš” ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§         |
| **í•™ìŠµ ê³¡ì„ **   | Celery ì„¤ì • ë³µì¡ë„       | ë¬¸ì„œí™” ë° í…œí”Œë¦¿ ì œê³µ      |

### ë¦¬ìŠ¤í¬

| ë¦¬ìŠ¤í¬                               | í™•ë¥  | ì˜í–¥ | ëŒ€ì‘                                         |
| ------------------------------------ | ---- | ---- | -------------------------------------------- |
| Celery ë³µì¡ì„±ìœ¼ë¡œ ì¸í•œ ë””ë²„ê¹… ì–´ë ¤ì›€ | ì¤‘ê°„ | ì¤‘ê°„ | ìƒì„¸ ë¡œê¹…, Flower ëª¨ë‹ˆí„°ë§ í™œìš©              |
| Python 3.14 ì¡°ê¸° ì „í™˜ ì••ë°•           | ë‚®ìŒ | ë‚®ìŒ | 3.12 LTS 2028-10ê¹Œì§€ ìœ ì§€, ì ì§„ ì „í™˜         |
| GPU Worker ë¹„ìš© ì¦ê°€                 | ì¤‘ê°„ | ë†’ìŒ | ìˆ˜ìš” ê¸°ë°˜ ì˜¤í† ìŠ¤ì¼€ì¼ë§, ìŠ¤íŒŸ ì¸ìŠ¤í„´ìŠ¤ í™œìš©   |
| uv ë„êµ¬ ì„±ìˆ™ë„ ë¦¬ìŠ¤í¬                | ë‚®ìŒ | ë‚®ìŒ | pip-tools ëŒ€ì•ˆ ì¤€ë¹„, Astral íŒ€ ì§€ì† ëª¨ë‹ˆí„°ë§ |
| ë³´ì•ˆ ì·¨ì•½ì  ë°œê²¬                     | ì¤‘ê°„ | ë†’ìŒ | ì •ê¸° ì·¨ì•½ì  ìŠ¤ìº”, íŒ¨ì¹˜ ì •ì±… ìˆ˜ë¦½             |
| ëŒ€ìš©ëŸ‰ íŒŒì¼ DoS                      | ë‚®ìŒ | ë†’ìŒ | ë¦¬ì†ŒìŠ¤ ì œí•œ, Rate limiting                   |
| ë°ì´í„° ìœ ì¶œ                          | ë‚®ìŒ | ë†’ìŒ | TLS ì•”í˜¸í™”, ì ‘ê·¼ ì œì–´                        |

### 9.1 í™•ì¥ì„± ì„ê³„ê°’ ë° ë³‘ëª©ì  ë¶„ì„

**ì»´í¬ë„ŒíŠ¸ë³„ í™•ì¥ ì„ê³„ê°’**:

| ì»´í¬ë„ŒíŠ¸       | í˜„ì¬ êµ¬ì„±       | ë³‘ëª© ì„ê³„ê°’                | ì¦ì„¤ ì‹œì             | ì¦ì„¤ ë°©ì•ˆ                           |
| -------------- | --------------- | -------------------------- | -------------------- | ----------------------------------- |
| **RabbitMQ**   | ë‹¨ì¼ ë…¸ë“œ       | ~50 Workers                | Worker 30ê°œ ì´ˆê³¼ ì‹œ  | 3ë…¸ë“œ í´ëŸ¬ìŠ¤í„° ì „í™˜                 |
| **PostgreSQL** | 100 connections | ~80% ì‚¬ìš©                  | 80ê°œ connection ì´ˆê³¼ | max_connections 500, PgBouncer ë„ì… |
| **MinIO**      | ë‹¨ì¼ ë…¸ë“œ       | ~500MB/s throughput        | ì²˜ë¦¬ëŸ‰ 400MB/s ì´ˆê³¼  | ë¶„ì‚° ëª¨ë“œ (4+ ë…¸ë“œ)                 |
| **DXF Worker** | 2 replicas      | concurrency Ã— replicas = 8 | í ê¹Šì´ > 50 ì§€ì†    | HPA ìµœëŒ€ 10 ì¦ì„¤                    |
| **PDF Worker** | 1 replica (GPU) | 2 concurrent tasks         | í ê¹Šì´ > 10 ì§€ì†    | HPA ìµœëŒ€ 5 ì¦ì„¤                     |

**ì²˜ë¦¬ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸**:

| ì‹œë‚˜ë¦¬ì˜¤  | DXF Workers            | PDF Workers           | ì˜ˆìƒ ì²˜ë¦¬ëŸ‰               | ë³‘ëª©ì                  |
| --------- | ---------------------- | --------------------- | ------------------------- | ---------------------- |
| ê¸°ë³¸ êµ¬ì„± | 2 Ã— 4 = 8 concurrent   | 1 Ã— 2 = 2 concurrent  | DXF 480ê±´/h, PDF 40ê±´/h   | -                      |
| ì¤‘ê°„ ë¶€í•˜ | 5 Ã— 4 = 20 concurrent  | 2 Ã— 2 = 4 concurrent  | DXF 1200ê±´/h, PDF 80ê±´/h  | RabbitMQ ì—°ê²° ìˆ˜       |
| ê³ ë¶€í•˜    | 10 Ã— 4 = 40 concurrent | 5 Ã— 2 = 10 concurrent | DXF 2400ê±´/h, PDF 200ê±´/h | PostgreSQL connections |

**ìˆ˜í‰ í™•ì¥ ì „ëµ**:

```yaml
# í™•ì¥ íŠ¸ë¦¬ê±° ì¡°ê±´
scalability_triggers:
    worker_scale_up:
        - condition: 'avg(celery_queue_length) > 5 for 5m'
          action: 'Add 1 worker replica'
        - condition: 'avg(cpu_utilization) > 70% for 10m'
          action: 'Add 1 worker replica'

    infrastructure_scale_up:
        - condition: 'rabbitmq_connections > 80% of max'
          action: 'Plan cluster migration'
        - condition: 'postgresql_connections > 80% of max'
          action: 'Enable PgBouncer or increase max_connections'

    vertical_scale_up:
        - condition: 'worker_memory_usage > 90% of limit'
          action: 'Increase memory limit or reduce concurrency'
```

**ì„±ëŠ¥ ë² ì´ìŠ¤ë¼ì¸**:

| ë©”íŠ¸ë¦­        | ë² ì´ìŠ¤ë¼ì¸ | ëª©í‘œ (P95) | í—ˆìš© ë²”ìœ„ | ì•Œë¦¼ ì„ê³„ê°’ |
| ------------- | ---------- | ---------- | --------- | ----------- |
| DXF ì²˜ë¦¬ ì‹œê°„ | 2ì´ˆ        | 3ì´ˆ        | < 5ì´ˆ     | > 7ì´ˆ       |
| PDF ì²˜ë¦¬ ì‹œê°„ | 18ì´ˆ       | 20ì´ˆ       | < 30ì´ˆ    | > 45ì´ˆ      |
| í ëŒ€ê¸° ì‹œê°„  | 500ms      | 1ì´ˆ        | < 2ì´ˆ     | > 5ì´ˆ       |
| ì„±ê³µë¥         | 99.5%      | 99%        | > 98%     | < 95%       |

#### RabbitMQ í´ëŸ¬ìŠ¤í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ (5ì°¨ ê²€í†  ì¶”ê°€)

> **âš ï¸ System Architect ê¶Œì¥ì‚¬í•­**: "Worker 30ê°œ ì´ˆê³¼ ì‹œ í´ëŸ¬ìŠ¤í„° ì „í™˜" ëª…ì‹œí•˜ë‚˜ êµ¬ì²´ì  ì ˆì°¨ ë¶€ì¬

**ë§ˆì´ê·¸ë ˆì´ì…˜ íŠ¸ë¦¬ê±°**:

- Worker 30ê°œ ì´ˆê³¼ ì˜ˆìƒ (í˜„ì¬ ì—°ê²° ìˆ˜ Ã— 2 > 50)
- ë‹¨ì¼ ë…¸ë“œ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  > 80% ì§€ì†
- ê³ ê°€ìš©ì„± ìš”êµ¬ì‚¬í•­ ì¶”ê°€

**Blue-Green ë§ˆì´ê·¸ë ˆì´ì…˜ ì ˆì°¨**:

````yaml
# Phase 1: í´ëŸ¬ìŠ¤í„° ì¤€ë¹„ (ë‹¤ìš´íƒ€ì„ 0)
steps:
  1. [ì‹ ê·œ í´ëŸ¬ìŠ¤í„° ë°°í¬]
     - 3ë…¸ë“œ RabbitMQ í´ëŸ¬ìŠ¤í„° êµ¬ì„±
     - Quorum Queue í™œì„±í™”
     ```bash
     # Helm ê¸°ë°˜ í´ëŸ¬ìŠ¤í„° ë°°í¬
     helm install rabbitmq-cluster bitnami/rabbitmq \
       --set replicaCount=3 \
       --set clustering.enabled=true \
       --set auth.username=admin \
       --set auth.password=$RABBITMQ_PASSWORD
     ```

  2. [Quorum Queue ë§ˆì´ê·¸ë ˆì´ì…˜]
     - ê¸°ì¡´ Classic Queue â†’ Quorum Queue ë³€í™˜
     ```python
     # í ì„ ì–¸ ì‹œ quorum íƒ€ì… ì§€ì •
     channel.queue_declare(
         queue='dxf_queue',
         durable=True,
         arguments={
             'x-queue-type': 'quorum',
             'x-delivery-limit': 3  # DLQ ì´ë™ ì „ ì¬ì „ì†¡ íšŸìˆ˜
         }
     )
     ```

  3. [Federation ì„¤ì •] (ë°ì´í„° ë™ê¸°í™”)
     ```bash
     # ê¸°ì¡´ ë…¸ë“œ â†’ ì‹ ê·œ í´ëŸ¬ìŠ¤í„° Federation
     rabbitmqctl set_parameter federation-upstream origin \
       '{"uri":"amqp://old-rabbitmq:5672","expires":3600000}'
     ```

# Phase 2: íŠ¸ë˜í”½ ì „í™˜ (ë‹¤ìš´íƒ€ì„ 0)
steps:
  4. [Worker ì—°ê²° ì „í™˜]
     - í™˜ê²½ ë³€ìˆ˜ ì—…ë°ì´íŠ¸ (Rolling Update)
     ```yaml
     # ConfigMap ì—…ë°ì´íŠ¸
     RABBITMQ_URL: "amqp://admin:pass@rabbitmq-cluster:5672"
     ```

  5. [íŠ¸ë˜í”½ ê²€ì¦]
     - Prometheus ë©”íŠ¸ë¦­ í™•ì¸
     - í ê¹Šì´, ì—°ê²° ìˆ˜, ë©”ì‹œì§€ ì²˜ë¦¬ìœ¨ ëª¨ë‹ˆí„°ë§

  6. [ê¸°ì¡´ ë…¸ë“œ ì œê±°]
     - Federation í•´ì œ
     - ê¸°ì¡´ ë‹¨ì¼ ë…¸ë“œ ì¢…ë£Œ
````

**Quorum Queue ì„¤ì •**:

```python
# celeryconfig.py - Quorum Queue ì§€ì› ì„¤ì •
task_queues = (
    Queue(
        "dxf_queue",
        Exchange("dxf"),
        routing_key="dxf.#",
        queue_arguments={
            'x-queue-type': 'quorum',
            'x-delivery-limit': 3,
            'x-dead-letter-exchange': 'dlx',
            'x-dead-letter-routing-key': 'dxf.dlq'
        }
    ),
    Queue(
        "pdf_queue",
        Exchange("pdf"),
        routing_key="pdf.#",
        queue_arguments={
            'x-queue-type': 'quorum',
            'x-delivery-limit': 3,
            'x-dead-letter-exchange': 'dlx',
            'x-dead-letter-routing-key': 'pdf.dlq'
        }
    ),
)
```

**ë¡¤ë°± ì ˆì°¨**:

| ë‹¨ê³„             | ì‘ì—…                              | ì†Œìš” ì‹œê°„ |
| ---------------- | --------------------------------- | --------- |
| 1                | Worker í™˜ê²½ ë³€ìˆ˜ ë³µì› (ê¸°ì¡´ ë…¸ë“œ) | 5ë¶„       |
| 2                | Rolling Update ë°°í¬               | 10ë¶„      |
| 3                | í ìƒíƒœ ê²€ì¦                      | 5ë¶„       |
| **ì´ ë¡¤ë°± ì‹œê°„** |                                   | **20ë¶„**  |

**í´ëŸ¬ìŠ¤í„° ìš´ì˜ ëª¨ë‹ˆí„°ë§**:

```promql
# í´ëŸ¬ìŠ¤í„° ìƒíƒœ ì•Œë¦¼ ê·œì¹™
- alert: RabbitMQClusterNodeDown
  expr: rabbitmq_cluster_members < 3
  for: 1m
  labels:
    severity: critical
  annotations:
    summary: "RabbitMQ cluster has fewer than 3 nodes"

- alert: QuorumQueueNotReady
  expr: rabbitmq_queue_consumers == 0 and rabbitmq_queue_messages > 0
  for: 5m
  labels:
    severity: warning
```

### 9.2 Incident Response Runbook (6ì°¨ ê²€í†  ì¶”ê°€)

> **DevOps Architect ê¶Œì¥ì‚¬í•­**: ì¥ì•  ëŒ€ì‘ ì ˆì°¨ ë¬¸ì„œí™” í•„ìš”

#### ì¥ì•  ë¶„ë¥˜ ë° ëŒ€ì‘ ì‹œê°„

| ì‹¬ê°ë„ | ì •ì˜                                | SLO ì˜í–¥   | ëŒ€ì‘ ì‹œê°„ | ì—ìŠ¤ì»¬ë ˆì´ì…˜     |
| ------ | ----------------------------------- | ---------- | --------- | ---------------- |
| **P1** | ì „ì²´ ì„œë¹„ìŠ¤ ì¤‘ë‹¨ (ëª¨ë“  Worker ë¶ˆëŠ¥) | 99.9% ìœ„ë°˜ | 15ë¶„ ë‚´   | ì¦‰ì‹œ ì˜¨ì½œ â†’ CTO  |
| **P2** | ë¶€ë¶„ ê¸°ëŠ¥ ì¥ì•  (íŠ¹ì • Worker íƒ€ì…)   | 99.5% ìœ„ë°˜ | 30ë¶„ ë‚´   | ì˜¨ì½œ ë‹´ë‹¹ì      |
| **P3** | ì„±ëŠ¥ ì €í•˜ (SLA ê·¼ì ‘)                | ê²½ê³  ìˆ˜ì¤€  | 2ì‹œê°„ ë‚´  | ì •ê·œ ê·¼ë¬´ì‹œê°„ ë‚´ |
| **P4** | ì ì¬ì  ë¬¸ì œ (ëª¨ë‹ˆí„°ë§ ê²½ê³ )         | ì˜í–¥ ì—†ìŒ  | 24ì‹œê°„ ë‚´ | ë°±ë¡œê·¸ ë“±ë¡      |

#### ì£¼ìš” ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤ë³„ ëŒ€ì‘

**ì‹œë‚˜ë¦¬ì˜¤ 1: RabbitMQ í´ëŸ¬ìŠ¤í„° ì¥ì• **

```bash
# 1ë‹¨ê³„: ìƒíƒœ í™•ì¸
kubectl exec -it rabbitmq-0 -n cad-workers -- rabbitmqctl cluster_status
kubectl exec -it rabbitmq-0 -n cad-workers -- rabbitmqctl list_queues name messages consumers

# 2ë‹¨ê³„: í ì ì²´ í™•ì¸
kubectl exec -it rabbitmq-0 -n cad-workers -- rabbitmqctl list_queues name messages | awk '$2 > 100 {print}'

# 3ë‹¨ê³„: ë³µêµ¬ ì ˆì°¨
# - ë…¸ë“œ ì¬ì‹œì‘ ì‹œë„
kubectl rollout restart statefulset/rabbitmq -n cad-workers

# - ê¸´ê¸‰: í ì¬ìƒì„± (ë©”ì‹œì§€ ìœ ì‹¤ ê°ìˆ˜)
# rabbitmqctl delete_queue dxf_queue && rabbitmqctl declare queue dxf_queue durable=true
```

**ì‹œë‚˜ë¦¬ì˜¤ 2: Worker Pod ì „ì²´ ì¤‘ë‹¨**

```bash
# 1ë‹¨ê³„: Pod ìƒíƒœ í™•ì¸
kubectl get pods -n cad-workers -l tier=worker
kubectl describe pods -n cad-workers -l app=dxf-worker | grep -A 5 "Events:"

# 2ë‹¨ê³„: ë¡œê·¸ í™•ì¸
kubectl logs -n cad-workers -l app=dxf-worker --tail=100 --since=10m

# 3ë‹¨ê³„: ê¸´ê¸‰ ìŠ¤ì¼€ì¼ì—…
kubectl scale deployment/dxf-worker --replicas=5 -n cad-workers

# 4ë‹¨ê³„: Readiness í™•ì¸
kubectl wait --for=condition=ready pod -l app=dxf-worker -n cad-workers --timeout=120s
```

**ì‹œë‚˜ë¦¬ì˜¤ 3: PostgreSQL Connection Pool ê³ ê°ˆ**

```bash
# 1ë‹¨ê³„: ì—°ê²° ìˆ˜ í™•ì¸
kubectl exec -it postgresql-0 -n cad-workers -- psql -U admin -d cad_db -c \
  "SELECT count(*) as active, max_conn FROM pg_stat_activity, (SELECT setting::int as max_conn FROM pg_settings WHERE name='max_connections') s GROUP BY max_conn;"

# 2ë‹¨ê³„: ìœ íœ´ ì—°ê²° ê°•ì œ ì¢…ë£Œ
kubectl exec -it postgresql-0 -n cad-workers -- psql -U admin -d cad_db -c \
  "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE state = 'idle' AND query_start < now() - interval '10 minutes';"

# 3ë‹¨ê³„: Worker ìˆœì°¨ ì¬ì‹œì‘ (ì—°ê²° ì¬ì„¤ì •)
kubectl rollout restart deployment/dxf-worker -n cad-workers
```

**ì‹œë‚˜ë¦¬ì˜¤ 4: MinIO ìŠ¤í† ë¦¬ì§€ ì¥ì• **

```bash
# 1ë‹¨ê³„: í—¬ìŠ¤ ì²´í¬
kubectl exec -it minio-0 -n cad-workers -- mc admin info local

# 2ë‹¨ê³„: ë²„í‚· ì ‘ê·¼ì„± í™•ì¸
kubectl exec -it minio-0 -n cad-workers -- mc ls local/cad-uploads

# 3ë‹¨ê³„: ê¸´ê¸‰ ì¡°ì¹˜ (ì½ê¸° ì „ìš© ëª¨ë“œ)
# Workerì—ì„œ ì—…ë¡œë“œ ë¹„í™œì„±í™” í›„ ë³µêµ¬ ëŒ€ê¸°
kubectl set env deployment/dxf-worker -n cad-workers MINIO_READONLY=true
```

#### ì¥ì•  ëŒ€ì‘ ì²´í¬ë¦¬ìŠ¤íŠ¸

| ë‹¨ê³„    | ë‹´ë‹¹     | ì¡°ì¹˜                           | ì™„ë£Œ í™•ì¸ |
| ------- | -------- | ------------------------------ | --------- |
| 1. íƒì§€ | ëª¨ë‹ˆí„°ë§ | AlertManager ì•Œë¦¼ ìˆ˜ì‹          | â–¡         |
| 2. ë¶„ë¥˜ | ì˜¨ì½œ     | ì‹¬ê°ë„ ë¶„ë¥˜ (P1-P4)            | â–¡         |
| 3. ëŒ€ì‘ | ì˜¨ì½œ     | ìœ„ ì‹œë‚˜ë¦¬ì˜¤ë³„ ì ˆì°¨ ìˆ˜í–‰        | â–¡         |
| 4. ì†Œí†µ | ì˜¨ì½œ     | Slack #incidents ì±„ë„ ì—…ë°ì´íŠ¸ | â–¡         |
| 5. ë³µêµ¬ | íŒ€       | ì„œë¹„ìŠ¤ ì •ìƒí™” í™•ì¸             | â–¡         |
| 6. ì‚¬í›„ | íŒ€       | Postmortem ì‘ì„± (P1/P2ë§Œ)      | â–¡         |

#### ì—°ë½ì²˜ ë° ì—ìŠ¤ì»¬ë ˆì´ì…˜

```yaml
on_call_schedule:
    primary: 'PagerDuty ì—°ë™ (ìë™ ë¡œí…Œì´ì…˜)'
    backup: 'Slack #cad-oncall ì±„ë„'

escalation_path:
    P1_immediate:
        - 'ì˜¨ì½œ ë‹´ë‹¹ì (5ë¶„ ë‚´ ì‘ë‹µ)'
        - 'ë°±ì—… ë‹´ë‹¹ì (10ë¶„ í›„)'
        - 'ê¸°ìˆ  ë¦¬ë“œ (15ë¶„ í›„)'
    P2_30min:
        - 'ì˜¨ì½œ ë‹´ë‹¹ì'
        - 'ê¸°ìˆ  ë¦¬ë“œ (30ë¶„ í›„)'
```

### 9.3 HA(High Availability) ì „ëµ (8ì°¨ ê²€í†  ë³´ì™„)

> âš ï¸ **Phase 3C ë°°í¬ ì „ í•„ìˆ˜ êµ¬í˜„ í•­ëª©** - 99.5% SLA ë‹¬ì„±ì„ ìœ„í•œ í•µì‹¬ ìš”ì†Œ

#### 9.3.1 PostgreSQL HA êµ¬ì„± (Patroni)

**ì•„í‚¤í…ì²˜**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HAProxy (L4 Load Balancer)               â”‚
â”‚                    VIP: postgres.svc.cluster.local          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                   â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   PostgreSQL #1   â”‚   â”‚  PostgreSQL #2  â”‚   â”‚  PostgreSQL #3   â”‚
    â”‚   (Primary)       â”‚â—„â”€â”€â”‚  (Sync Standby) â”‚â—„â”€â”€â”‚  (Async Standby) â”‚
    â”‚   patroni-0       â”‚   â”‚  patroni-1      â”‚   â”‚  patroni-2       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                   â”‚                    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Etcd Cluster    â”‚
                    â”‚   (Leader ì„ ì¶œ)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**êµ¬ì„± ìš”ì•½**:
| í•­ëª© | ì„¤ì • | ì„¤ëª… |
|------|------|------|
| ë…¸ë“œ ìˆ˜ | 3 (1 Primary + 2 Standby) | ì¿¼ëŸ¼ ê¸°ë°˜ ì¥ì•  ê°ì§€ |
| ë³µì œ ëª¨ë“œ | ë™ê¸° (Sync Standby 1ê°œ) | RPO = 0 (ë°ì´í„° ì†ì‹¤ ì—†ìŒ) |
| Failover ì‹œê°„ | < 30ì´ˆ | Patroni ìë™ ìŠ¹ê²© |
| Connection Pool | PgBouncer (ë…¸ë“œë³„) | max_client_conn: 1000 |

**Patroni ì„¤ì •**:

```yaml
# patroni.yml
scope: cad-worker-cluster
name: patroni-0

restapi:
    listen: 0.0.0.0:8008
    connect_address: patroni-0:8008

etcd:
    hosts: etcd-0:2379,etcd-1:2379,etcd-2:2379

bootstrap:
    dcs:
        ttl: 30
        loop_wait: 10
        retry_timeout: 10
        maximum_lag_on_failover: 1048576 # 1MB
        synchronous_mode: true
        synchronous_node_count: 1
        postgresql:
            use_pg_rewind: true
            parameters:
                max_connections: 500
                shared_buffers: 2GB
                wal_level: replica
                max_wal_senders: 10
                max_replication_slots: 10

postgresql:
    listen: 0.0.0.0:5432
    connect_address: patroni-0:5432
    authentication:
        superuser:
            username: postgres
            password: ${POSTGRES_PASSWORD}
        replication:
            username: replicator
            password: ${REPLICATION_PASSWORD}
```

**ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤ ë° ë³µêµ¬**:
| ì¥ì•  ìœ í˜• | RTO | RPO | ìë™ ë³µêµ¬ | ìˆ˜ë™ ê°œì… |
|----------|-----|-----|----------|----------|
| Primary ì¥ì•  | < 30ì´ˆ | 0 | âœ… Patroni ìë™ ìŠ¹ê²© | ë¶ˆí•„ìš” |
| Sync Standby ì¥ì•  | 0ì´ˆ | 0 | âœ… Async â†’ Sync ì „í™˜ | ë…¸ë“œ ë³µêµ¬ í›„ í´ëŸ¬ìŠ¤í„° ì¬ì°¸ì—¬ |
| Split-brain | ë°©ì§€ë¨ | - | âœ… Etcd ì¿¼ëŸ¼ | ë¶ˆí•„ìš” |
| ì „ì²´ í´ëŸ¬ìŠ¤í„° ì¥ì•  | ìˆ˜ë™ | ë°±ì—… ê¸°ì¤€ | âŒ | WAL ì•„ì¹´ì´ë¸Œì—ì„œ ë³µêµ¬ |

#### 9.3.2 MinIO Distributed êµ¬ì„±

**ì•„í‚¤í…ì²˜**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 MinIO Load Balancer (nginx)                   â”‚
â”‚                 minio.svc.cluster.local:9000                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚             â”‚             â”‚             â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚ MinIO #1  â”‚ â”‚ MinIO #2  â”‚ â”‚ MinIO #3  â”‚ â”‚ MinIO #4  â”‚
    â”‚ minio-0   â”‚ â”‚ minio-1   â”‚ â”‚ minio-2   â”‚ â”‚ minio-3   â”‚
    â”‚ [Disk 1]  â”‚ â”‚ [Disk 2]  â”‚ â”‚ [Disk 3]  â”‚ â”‚ [Disk 4]  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚             â”‚             â”‚             â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                    Erasure Coding (2+2)
                    2ê°œ ë…¸ë“œ ì¥ì•  í—ˆìš©
```

**êµ¬ì„± ìš”ì•½**:
| í•­ëª© | ì„¤ì • | ì„¤ëª… |
|------|------|------|
| ë…¸ë“œ ìˆ˜ | 4 (ìµœì†Œ êµ¬ì„±) | Erasure Coding 2+2 |
| ì¥ì•  í—ˆìš© | 2ë…¸ë“œ | ë™ì‹œ 2ê°œ ë…¸ë“œ ì¥ì•  í—ˆìš© |
| ì €ì¥ì†Œ | StatefulSet + PVC | ê° 100Gi NVMe SSD |
| ì•”í˜¸í™” | SSE-S3 (AES-256-GCM) | At-rest ì•”í˜¸í™” |

**StatefulSet ì„¤ì •**:

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
    name: minio
    namespace: cad-worker
spec:
    serviceName: minio-headless
    replicas: 4
    selector:
        matchLabels:
            app: minio
    template:
        metadata:
            labels:
                app: minio
        spec:
            affinity:
                podAntiAffinity:
                    requiredDuringSchedulingIgnoredDuringExecution:
                        - labelSelector:
                              matchLabels:
                                  app: minio
                          topologyKey: topology.kubernetes.io/zone
            containers:
                - name: minio
                  image: minio/minio:RELEASE.2024-01-01T00-00-00Z
                  args:
                      - server
                      - http://minio-{0...3}.minio-headless.cad-worker.svc.cluster.local/data
                      - --console-address
                      - ':9001'
                  env:
                      - name: MINIO_ROOT_USER
                        valueFrom:
                            secretKeyRef:
                                name: minio-credentials
                                key: root-user
                      - name: MINIO_ROOT_PASSWORD
                        valueFrom:
                            secretKeyRef:
                                name: minio-credentials
                                key: root-password
                  ports:
                      - containerPort: 9000
                        name: api
                      - containerPort: 9001
                        name: console
                  volumeMounts:
                      - name: data
                        mountPath: /data
                  resources:
                      requests:
                          memory: '2Gi'
                          cpu: '500m'
                      limits:
                          memory: '4Gi'
                          cpu: '2'
    volumeClaimTemplates:
        - metadata:
              name: data
          spec:
              accessModes: ['ReadWriteOnce']
              storageClassName: fast-nvme
              resources:
                  requests:
                      storage: 100Gi
```

#### 9.3.3 ë‹¤ì¤‘ AZ ë°°í¬ ì „ëµ

**í† í´ë¡œì§€ ë¶„ì‚° ì„¤ì •**:

```yaml
# ëª¨ë“  Critical ì›Œí¬ë¡œë“œì— ì ìš©
spec:
    topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: topology.kubernetes.io/zone
          whenUnsatisfiable: DoNotSchedule
          labelSelector:
              matchLabels:
                  app: dxf-worker

    affinity:
        podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
                - weight: 100
                  podAffinityTerm:
                      labelSelector:
                          matchLabels:
                              app: dxf-worker
                      topologyKey: kubernetes.io/hostname
```

**AZë³„ ë°°í¬ í˜„í™©**:
| ì»´í¬ë„ŒíŠ¸ | AZ-A | AZ-B | AZ-C | ì¥ì•  í—ˆìš© |
|----------|------|------|------|----------|
| PostgreSQL Patroni | patroni-0 (Primary) | patroni-1 (Sync) | patroni-2 (Async) | 1 AZ |
| MinIO | minio-0, minio-1 | minio-2 | minio-3 | 1 AZ (2ë…¸ë“œ) |
| RabbitMQ | rabbit-0 | rabbit-1 | rabbit-2 | 1 AZ |
| DXF Worker | 1-2 pods | 1-2 pods | 1-2 pods | 2 AZ |
| PDF Worker | 1 pod (GPU) | - | - | GPU ê°€ìš© ì‹œ ì „í™˜ |

**ê°€ìš©ì„± ê³„ì‚°**:

```
í˜„ì¬ (ë‹¨ì¼ ë…¸ë“œ):
  PostgreSQL: 99.0% Ã— MinIO: 99.0% Ã— RabbitMQ: 99.0% = 97.0%

HA êµ¬ì„± í›„:
  PostgreSQL (Patroni 3ë…¸ë“œ): 99.99%
  MinIO (4ë…¸ë“œ Erasure): 99.95%
  RabbitMQ (Quorum Queue): 99.95%

  ì‹œìŠ¤í…œ ê°€ìš©ì„±: min(99.99%, 99.95%, 99.95%) = 99.95% âœ… (ëª©í‘œ 99.5% ì´ˆê³¼)
```

---

## 10. ì¬ê²€í†  ì¡°ê±´

ë‹¤ìŒ ì¡°ê±´ ë°œìƒ ì‹œ ì´ ADRì„ ì¬ê²€í† í•©ë‹ˆë‹¤:

### ê¸°ìˆ ì  íŠ¸ë¦¬ê±°

- [ ] Python 3.13 ì •ì‹ ì¶œì‹œ ë° ìƒíƒœê³„ ì„±ìˆ™ â†’ Python ë²„ì „ ì—…ê·¸ë ˆì´ë“œ ê²€í† 
- [ ] PyTorch 3.x ì¶œì‹œ â†’ ML ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—…ê·¸ë ˆì´ë“œ ê²€í† 
- [ ] Dramatiq 2.0 ì•ˆì •í™” â†’ Celery ëŒ€ì•ˆ ì¬í‰ê°€
- [ ] ì²˜ë¦¬ëŸ‰ 100ë°° ì¦ê°€ â†’ Worker ì•„í‚¤í…ì²˜ ì¬ì„¤ê³„

### ë¹„ì¦ˆë‹ˆìŠ¤ íŠ¸ë¦¬ê±°

- [ ] í‚¤ì˜¤ìŠ¤í¬ 30ëŒ€ ì´ˆê³¼ â†’ Kubernetes ì „í™˜ ê²€í† 
- [ ] ìƒˆë¡œìš´ íŒŒì¼ í˜•ì‹ ì¶”ê°€ â†’ íŒŒì´í”„ë¼ì¸ í™•ì¥
- [ ] ì‹¤ì‹œê°„ ì²˜ë¦¬ ìš”êµ¬ â†’ ìŠ¤íŠ¸ë¦¬ë° ì•„í‚¤í…ì²˜ ê²€í† 

### ìš´ì˜ íŠ¸ë¦¬ê±°

- [ ] DXF ì²˜ë¦¬ ì‹œê°„ 7ì¼ í‰ê·  > 5ì´ˆ (SLA ìœ„ë°˜)
- [ ] PDF ì²˜ë¦¬ ì‹œê°„ 7ì¼ í‰ê·  > 30ì´ˆ (SLA ìœ„ë°˜)
- [ ] Worker í¬ë˜ì‹œìœ¨ > 5íšŒ/ì¼ ì—°ì† 3ì¼

### ë³´ì•ˆ íŠ¸ë¦¬ê±°

- [ ] Python/Celery/PyTorch CVE ë°œí‘œ (CVSS â‰¥ 7.0)
- [ ] í•µì‹¬ ì˜ì¡´ì„± deprecation ê³µì§€

### ì •ê¸° ê²€í† 

- [ ] 6ê°œì›” ì •ê¸° ê²€í†  (ë‹¤ìŒ ê²€í† : 2026-06-05)

---

## 11. ì°¸ì¡°

### ê´€ë ¨ ë¬¸ì„œ

| ë¬¸ì„œ                                                                           | ì„¤ëª…                      |
| ------------------------------------------------------------------------------ | ------------------------- |
| [001_BACKEND_STACK.md](./001_BACKEND_STACK.md)                                 | Backend ê¸°ìˆ  ìŠ¤íƒ (ìƒìœ„)  |
| [002_API_LAYER_STACK.md](./002_API_LAYER_STACK.md)                             | API Layer í”„ë ˆì„ì›Œí¬ ì„ íƒ |
| [003_QUEUE_ALTERNATIVES_COMPARISON.md](./003_QUEUE_ALTERNATIVES_COMPARISON.md) | RabbitMQ ì„ íƒ ê·¼ê±°        |
| [FILE_UPLOAD_ARCHITECTURE.md](../fileUpload/FILE_UPLOAD_ARCHITECTURE.md)       | ì‹œìŠ¤í…œ ë‹¤ì´ì–´ê·¸ë¨         |
| [ROADMAP.md](../ROADMAP.md)                                                    | ì „ì²´ í”„ë¡œì íŠ¸ ë¡œë“œë§µ      |
| [GLOSSARY.md](../GLOSSARY.md)                                                  | ìš©ì–´ ë° ì•½ì–´ ì •ì˜         |

### ì™¸ë¶€ ì°¸ì¡°

- [Python ë²„ì „ ì§€ì› ì •ì±…](https://devguide.python.org/versions/)
- [Celery ê³µì‹ ë¬¸ì„œ](https://docs.celeryq.dev/)
- [uv íŒ¨í‚¤ì§€ ê´€ë¦¬ì](https://github.com/astral-sh/uv)
- [Ruff Linter](https://github.com/astral-sh/ruff)
- [Flower Celery ëª¨ë‹ˆí„°ë§](https://flower.readthedocs.io/)
- [PyTorch ê³µì‹ ë¬¸ì„œ](https://pytorch.org/docs/stable/)
- [Docker Python ì´ë¯¸ì§€ ê°€ì´ë“œ](https://hub.docker.com/_/python)
- [Prometheus ê³µì‹ ë¬¸ì„œ](https://prometheus.io/docs/)

---

## 12. Changelog (ë³€ê²½ ì´ë ¥)

| ë²„ì „  | ë‚ ì§œ       | ë³€ê²½ ë‚´ìš©                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ----- | ---------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0.0.4 | 2025-12-12 | ê´€ë ¨ ADR ì°¸ì¡° í…Œì´ë¸”ì— ADR-002 ì¶”ê°€, ë¬¸ì„œ ê°„ ì–‘ë°©í–¥ ì°¸ì¡° ì™„ì„±                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| 0.0.3 | 2025-12-10 | **[8~9ì°¨ ì „ë¬¸ê°€ ê²€í†  í†µí•©]** [9ì°¨ ì™„ë£Œ] ì¢…í•© 93.6ì , ì „ì› ìŠ¹ì¸ (Backend 94âœ…, DevOps 93âœ…, Quality 92âœ…, Security 93âœ…, System 96âœ…). [8ì°¨] Backend(94), DevOps(65â†’93), Quality(92), Security(92), System(94â†’96). [CRITICAL í•´ê²°] CI/CD ì´ì¤‘ ë¹Œë“œâ†’tarball ë°©ì‹, Kustomize newName ì¶”ê°€, ArgoCD ë¬¸ë²• ìˆ˜ì •. [ì‹ ê·œ ì„¹ì…˜] 5.12 GitOps ì›Œí¬í”Œë¡œìš°, 5.13 Service Mesh, 5.8.6 Secret ë¡œí…Œì´ì…˜, 9.3 HA ì „ëµ. [ê°œì„ ] Control/Data Plane ë¶„ë¦¬, ì„±ëŠ¥ ë² ì´ìŠ¤ë¼ì¸ í…œí”Œë¦¿, E2E 8ê°œ ì‹œë‚˜ë¦¬ì˜¤. í”„ë¡œë•ì…˜ ë°°í¬ ìŠ¹ì¸ ê¸°ì¤€ ì¶©ì¡±. **[ìŠ¹ì¸]** ìƒíƒœ Draftâ†’Approved ë³€ê²½, ìŠ¹ì¸ì(í”„ë¡œì íŠ¸ Owner)/ê²°ì •ì¼(2025-12-10) í™•ì •. **[ì •ë¦¬]** ADR ìˆœìˆ˜í™” - 9.1 Known Gaps, 11. Getting Started, Appendix A-D ì‚­ì œ (~1,600 ë¼ì¸ ì œê±°). TOC 3.1 ì¶”ê°€, ì„¹ì…˜ í—¤ë” ë¶€ê¸° ì •ë¦¬, Changelog ë²ˆí˜¸ ìˆ˜ì •. "ê¶Œì¥ ê¸°ìˆ  ìŠ¤íƒ"â†’"ìµœì¢… ê²°ì • (ìŠ¹ì¸ë¨)" ë³€ê²½ (ADR-002 í˜•ì‹ ì¤€ìˆ˜). |
| 0.0.2 | 2025-12-08 | **[4~7ì°¨ ì „ë¬¸ê°€ ê²€í†  í†µí•©]** [4ì°¨] ë³´ì•ˆì„¤ê³„, ë°°í¬ì „ëµ, CI/CD, ë¡œê·¸ì§‘ê³„ ì„¹ì…˜ ì¶”ê°€ (69â†’86.2ì ). [5ì°¨] MinIO ë©±ë“±ì„±, TLS Downgrade ë°©ì§€, seccomp ë³´ê°•, NetworkPolicy DNS ì œí•œ. [6ì°¨] Incident Runbook, GitOps/ArgoCD, PDB ê°•í™”, HMAC ì¸ì¦ (92ì , ì¡°ê±´ë¶€). [7ì°¨] ë¦¬í”Œë ˆì´ ê³µê²© ë°©ì–´, Python 3.12 ì „í™˜, Celery 5.5 (94.8ì , ì „ì› ìŠ¹ì¸).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| 0.0.1 | 2025-12-05 | í…œí”Œë¦¿ êµ¬ì¡° ì •ë ¬ ë° í’ˆì§ˆ ê°œì„ : ìƒíƒœ/í‰ê°€ê¸°ì¤€/ì „ë¬¸ê°€ë¶„ì„/ë¦¬ìŠ¤í¬/ì™¸ë¶€ì°¸ì¡° ì„¹ì…˜ ì¶”ê°€, ëª¨ë‹ˆí„°ë§ ë„êµ¬ ë¹„êµ, Review Triggers, ë§ˆì´ê·¸ë ˆì´ì…˜ ê²½ë¡œ, Python 3.13 ì°¸ì¡°, ë¦¬ìŠ¤í¬ í…Œì´ë¸” ì¼ê´€ì„± ìˆ˜ì •                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| 0.0.0 | 2025-12-04 | ì´ˆê¸° ë²„ì „ - Python Worker ê¸°ìˆ  ìŠ¤íƒ ì •ì˜, ì „ë¬¸ê°€ ê²€í†  ê²°ê³¼ ë°˜ì˜, ìš©ì–´ì§‘ í†µí•©, Python LTS ì •ì±… ëª…ì‹œ, IDE ë„êµ¬ ë¹„êµ, uv íŒ¨í‚¤ì§€ ê´€ë¦¬ì ì¶”ê°€                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
